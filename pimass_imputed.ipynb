{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import dill\n",
    "import random\n",
    "import cyvcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%load_ext rpy2.ipython\n",
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/\"\n",
    "snp_file_gz = \"isect.vcf.gz.sorted.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = HDFStoreHelper(os.path.join(analysis_dir, \"isect.hd5\"))\n",
    "hdf_all = HDFStoreHelper(os.path.join(analysis_dir, \"gypsy_samtools12_imputed40.vcf.gz.hd5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write piMASS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno = hdf_all[\"pca_std_pheno\"][[\"Population\",\n",
    "                                             \"Number\",\n",
    "                                             \"Mass\",\"Pupual Duration\", \"Total Dev Time\"]]\n",
    "pimass_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf['pimass_pheno'] = pimass_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = hdf['pca_x']\n",
    "pca_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = pimass_pheno.join(pca_x, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno_pca = pca_std_pheno[[x for x in pca_std_pheno if \"PC\" in x or 'Mass' in x or 'Pupual' in x or 'Total Dev' in x]]\n",
    "pimass_pheno_pca.columns = [x.replace(\" \", \"_\") for x in pimass_pheno_pca.columns]\n",
    "pimass_pheno_pca.index = [x for x in pimass_pheno_pca.index]\n",
    "phenos = [\"Mass\", \"Pupual_Duration\", \"Total_Dev_Time\"]\n",
    "for p in phenos:\n",
    "    mod = smf.ols(formula=\"%s~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8\" % p, data=pimass_pheno_pca)\n",
    "    res = mod.fit()\n",
    "    col = \"%s_resid\" % p\n",
    "    col = col.lower()\n",
    "    pimass_pheno[col] = res.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = hdf[\"z12_swapped\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "def get_correct_name(row, trans):\n",
    "    trans[row.name] = \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "\n",
    "name_translation = {}\n",
    "translation_df.apply(get_correct_name, args=(name_translation,), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readvcf = open(os.path.join(analysis_dir, snp_file_gz))\n",
    "reader = cyvcf.VCFReader(readvcf)\n",
    "gt_base_data = {}\n",
    "gt_ref_alt = {}\n",
    "at = 0\n",
    "for snp in reader:\n",
    "    snp_id = \"%s_%d\" % (snp.CHROM, snp.POS)\n",
    "    gt_ref_alt[snp_id] = {'ref': snp.REF, 'alt': snp.ALT[0]}\n",
    "    for sample in snp.samples:\n",
    "        if not snp_id in gt_base_data:\n",
    "            gt_base_data[snp_id] = {}\n",
    "        sample_name = name_translation[sample.sample]\n",
    "        bases = sample.gt_bases\n",
    "        gt_base_data[snp_id][sample_name] = bases\n",
    "    at += 1\n",
    "    if at % 1000 == 0:\n",
    "        print(at)\n",
    "gt_base_df = pd.DataFrame(gt_base_data)\n",
    "readvcf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_gt_alleles(gt, het):   \n",
    "    if isinstance(gt, float): #NaN\n",
    "        return np.NaN\n",
    "    if gt is None:\n",
    "        return np.NaN\n",
    "    if gt[0] == gt[-1]:\n",
    "        return gt.replace(\"|\", \"/\")\n",
    "    else:\n",
    "        return het # already in minor/major\n",
    "    \n",
    "def swap_gt(snp):\n",
    "    vc = snp.value_counts()\n",
    "    counts = {}\n",
    "    for v in vc.index:\n",
    "        if not v[0] in counts:\n",
    "            counts[v[0]] = 0.0\n",
    "        if not v[-1] in counts:\n",
    "            counts[v[-1]] = 0.0\n",
    "        counts[v[0]] += vc[v]\n",
    "        counts[v[-1]] += vc[v]\n",
    "    counts2 = sorted(list(counts.items()), key=operator.itemgetter(1)) #e.g., [('A', 110.0), ('G', 236.0)]\n",
    "    minor = counts2[0][0]\n",
    "    major = counts2[1][0]\n",
    "    het = \"%s/%s\" % (minor, major)\n",
    "    gt_ref_alt[snp.name]['minor'] = minor\n",
    "    gt_ref_alt[snp.name]['major'] = major\n",
    "    return snp.apply(swap_gt_alleles, args=(het,))\n",
    "gt_base_df_swapped = gt_base_df.apply(swap_gt)\n",
    "gt_base_df_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_GP_to_L(q):\n",
    "    return pow(10,(-q/10.0))\n",
    "\n",
    "def get_dosage(gp, index):\n",
    "    if not gp:\n",
    "        return [\"NA\"]\n",
    "    gp2 = [x for x in gp]\n",
    "    dosage = (gp2[1] + 2*gp2[index])\n",
    "    assert dosage >=0 and dosage <=2\n",
    "    return gp, gp2, dosage\n",
    "\n",
    "def get_GP(sample):\n",
    "    if sample['GT'] is None:\n",
    "        return None, None\n",
    "    return sample['GT'], sample['GP']\n",
    "\n",
    "def get_major_minor(snp, reader):\n",
    "    d = snp.name.split(\"_\")\n",
    "    loc = int(d[-1])\n",
    "    contig = \"_\".join(d[0:-1])\n",
    "    minor = gt_ref_alt[snp.name]['minor']\n",
    "    major = gt_ref_alt[snp.name]['major']\n",
    "    ref = gt_ref_alt[snp.name]['ref']\n",
    "    alt = gt_ref_alt[snp.name]['alt']\n",
    "    minor_index = 0 #assume minor is reference\n",
    "    if minor == alt:\n",
    "        minor_index = 2\n",
    "    dosages = []\n",
    "    samples = []\n",
    "    thesnp = list(reader.fetch(contig, loc, loc))[0]\n",
    "    for sample in thesnp.samples:\n",
    "        gt, gp = get_GP(sample)\n",
    "        dosages.append(get_dosage(gp, minor_index)[-1])\n",
    "        samples.append(sample.sample)\n",
    "    data = [minor, major]\n",
    "    index = [\"minor\", \"major\"]\n",
    "    index.extend(samples)\n",
    "    data.extend(dosages)\n",
    "    ret = pd.Series(data, index=index)\n",
    "    return ret\n",
    "h = open(os.path.join(analysis_dir, snp_file_gz))\n",
    "reader = cyvcf.VCFReader(h)\n",
    "pimass_gt = gt_base_df_swapped.apply(get_major_minor, args=(reader,)).T\n",
    "pimass_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno = pimass_pheno.reindex(index=gt_base_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i pimass_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "massx = qqnorm(pimass_pheno$mass_resid, plot.it=F)$x\n",
    "tdtx = qqnorm(pimass_pheno$total_dev_time_resid, plot.it=F)$x\n",
    "pdx = qqnorm(pimass_pheno$pupual_duration_resid, plot.it=F)$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno['massx'] = r('massx')\n",
    "pimass_pheno['tdtx'] = r('tdtx')\n",
    "pimass_pheno['pdx'] = r('pdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno.massx.to_csv(os.path.join(analysis_dir, \"pimass_mass.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.tdtx.to_csv(os.path.join(analysis_dir, \"pimass_tdt.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.pdx.to_csv(os.path.join(analysis_dir, \"pimass_pd.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.to_csv(os.path.join(analysis_dir, \"pimass_pheno.txt\"),\n",
    "                                     index=True,\n",
    "                                     header=True)\n",
    "pimass_gt.to_csv(os.path.join(analysis_dir, \"pimass_gt.txt\"),\n",
    "                index=True,\n",
    "                header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_contigs = {}\n",
    "with open(os.path.join(analysis_dir, \"pimass_loc.txt\"), \"w\") as o:    \n",
    "    for x in pimass_gt.index:\n",
    "        data = x.split(\"_\")\n",
    "        contig = \"_\".join(data[0:-1])\n",
    "        pos = data[-1]\n",
    "        if not contig in pimass_contigs:\n",
    "            pimass_contigs[contig] = []\n",
    "        pimass_contigs[contig].append(pos)\n",
    "    \n",
    "    chrom_id = 1\n",
    "    for contig, positions in list(pimass_contigs.items()):\n",
    "        for p in positions:\n",
    "            o.write(\"%s_%s\\t%s\\t%d\\n\" % (contig, p, p, chrom_id))\n",
    "        chrom_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def create_pimass_run_files(num_runs):\n",
    "    phenos = [\"mass\", 'tdt', 'pd']\n",
    "    for p in phenos:\n",
    "        with open(os.path.join(analysis_dir, \"pimass_%s_run.txt\" % p), \"w\") as o:\n",
    "            for i in xrange(num_runs):\n",
    "                cmd = \"~/g/src/pimass/pimass-lin \\\n",
    "-g pimass_gt.txt \\\n",
    "-p pimass_%s.txt -pos pimass_loc.txt \\\n",
    "-o pimass_%s_out_%d \\\n",
    "-w 1000000 \\\n",
    "-s 10000000 \\\n",
    "-num 500 \\\n",
    "-smin 1 \\\n",
    "-smax 100 \\\n",
    "-hmin 0.01 \\\n",
    "-hmax 0.9 \\\n",
    "-pmin 1 \\\n",
    "-pmax 1000 \\\n",
    "-r %.0f\" % (p, p, i, int(random.getrandbits(32)))\n",
    "                o.write(\"%s\\n\" % cmd) \n",
    "                \n",
    "\n",
    "\n",
    "def create_qsub_files():\n",
    "    files = !ls {analysis_dir}*run.txt\n",
    "    for f in files:\n",
    "        with open(\"%s_qsub.sh\" % f, \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N pimass_%s\n",
    "#$ -cwd\n",
    "parallel -a %s\n",
    "\"\"\" % (os.path.basename(f).split(\"_\")[1], f))\n",
    "            \n",
    "create_pimass_run_files(10)\n",
    "create_qsub_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf['pimass_gt'] = pimass_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## run piMASS\n",
    "\n",
    "```bash\n",
    "./run_pimass.sh\n",
    "mv output output_comeault_isect\n",
    "mv pimass*.txt output_comeault_isect_infiles\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze and process piMASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "assembly = \"/home/cfriedline/gpfs/assemblies/gypsy/masurca_new/CA/10-gapclose/genome.ctg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "filedir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/output_comeault_isect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "hide_input": false,
    "init_cell": true,
    "locked": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def dump_session():\n",
    "    dill.settings['recurse'] = True\n",
    "    dill.settings['fmode'] = dill.HANDLE_FMODE\n",
    "    dill.dump_session(filename=os.path.join(filedir, \"pimass.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_files = {}\n",
    "mcmc_files = {}\n",
    "gamma_files = {}\n",
    "snp_files = {}\n",
    "for root, dirs, files in scandir.walk(filedir):\n",
    "    for f in files:\n",
    "        d = f.split(\"_\")\n",
    "        pheno = d[1]\n",
    "        if not pheno in path_files:\n",
    "            path_files[pheno] = []\n",
    "            mcmc_files[pheno]= []\n",
    "            gamma_files[pheno] = []\n",
    "            snp_files[pheno] = []\n",
    "        if 'path' in f:\n",
    "            path_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'mcmc' in f:\n",
    "            mcmc_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'gamma' in f:\n",
    "            gamma_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'snp' in f:\n",
    "            snp_files[pheno].append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(coda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = r('mcmc')\n",
    "mcmc_list = r('mcmc.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "phenos = [\"mass\", \"pd\", \"tdt\"]\n",
    "for pheno in phenos:\n",
    "    frames = [pd.read_csv(x,sep=\"\\t\") for x in path_files[pheno]]\n",
    "    frames = [x.ix[:,:-1] for x in frames]\n",
    "    for df in frames:\n",
    "        df.columns = [x.strip() for x in df.columns]\n",
    "    dfs[pheno] = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs['mass'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_mcmc_r = {}\n",
    "path_mcmc = {}\n",
    "thin = 1\n",
    "for key, dflist in list(dfs.items()):\n",
    "    path_mcmc_r[key] = [mcmc(pandas2ri.DataFrame(x.sample(frac=thin).sort_index())) for x in dflist]\n",
    "    path_mcmc[key] = [x.sample(frac=thin).sort_index() for x in dflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_mcmc_list_mass = mcmc_list(path_mcmc_r['mass'])\n",
    "path_mcmc_list_pd = mcmc_list(path_mcmc_r['pd'])\n",
    "path_mcmc_list_tdt = mcmc_list(path_mcmc_r['tdt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%R -i path_mcmc_list_mass -i path_mcmc_list_pd -i path_mcmc_list_tdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "effective_sizes_mass = lapply(path_mcmc_list_mass,effectiveSize)\n",
    "effective_sizes_pd = lapply(path_mcmc_list_pd,effectiveSize)\n",
    "effective_sizes_tdt = lapply(path_mcmc_list_tdt,effectiveSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_effective_sizes(r_name):\n",
    "    df = pd.DataFrame([pandas2ri.ri2py(x) for x in r[r_name]])\n",
    "    test = r[r_name].rx2(1)\n",
    "    df.columns = r('names')(test)\n",
    "    return df\n",
    "ne_tdt = get_effective_sizes('effective_sizes_tdt')\n",
    "ne_pd= get_effective_sizes('effective_sizes_pd')\n",
    "ne_mass= get_effective_sizes('effective_sizes_mass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(ne_tdt.mean())\n",
    "print(ne_tdt.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_pd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_mass.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"MASS\", r(\"summary\")(path_mcmc_list_mass))\n",
    "print(\"PD\", r(\"summary\")(path_mcmc_list_pd))\n",
    "print(\"TDT\", r(\"summary\")(path_mcmc_list_tdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(path_mcmc_list_mass)\n",
    "plot(path_mcmc_list_pd)\n",
    "plot(path_mcmc_list_tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = {}\n",
    "for pheno, files in list(mcmc_files.items()):\n",
    "    if not pheno in mcmc:\n",
    "        mcmc[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        testdf = pd.read_csv(f, sep=\"\\t\")\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        mcmc[pheno] = pd.concat([mcmc[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc_mass = mcmc['mass']\n",
    "mcmc_pd = mcmc['pd']\n",
    "mcmc_tdt = mcmc['tdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hmean_row(row):\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan\n",
    "    \n",
    "def get_hmean(df, col_pattern):\n",
    "    cols = ['rs','chr']\n",
    "    cols.extend([\"%s_hmean\" % x for x in col_pattern])\n",
    "    d = pd.DataFrame(columns=cols, index=df.index)\n",
    "    d['rs'] = df.rs_1.values\n",
    "    d[\"chr\"] = df.chr_1.values\n",
    "    for cp in col_pattern:\n",
    "        d[\"%s_hmean\" % cp] = np.abs(df[[x for x in df if cp in x]]).apply(get_hmean_row, axis=1).values\n",
    "    return d\n",
    "mcmc_mass_hmean = get_hmean(mcmc_mass, [\"postrb\", \"betarb\"])\n",
    "mcmc_tdt_hmean = get_hmean(mcmc_tdt, [\"postrb\", \"betarb\"])\n",
    "mcmc_pd_hmean = get_hmean(mcmc_pd, [\"postrb\", \"betarb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf['mcmc_mass_hmean'] = mcmc_mass_hmean\n",
    "hdf['mcmc_tdt_hmean'] = mcmc_tdt_hmean\n",
    "hdf['mcmc_pd_hmean'] = mcmc_pd_hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcmc_hmean = {'mass': mcmc_mass_hmean,\n",
    "             'tdt': mcmc_tdt_hmean,\n",
    "             'pd': mcmc_pd_hmean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?sp.stats.distributions.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot(mcmc_mass_hmean.postrb_hmean, dist=sp.stats.distributions.norm, line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_dist(data, title):\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.hist(data, bins=100, alpha=0.2)\n",
    "    dists = ['norm', 'rayleigh', 'maxwell', 'logistic','laplace', 'cauchy']\n",
    "    for d in dists:\n",
    "        dist = getattr(sp.stats, d)\n",
    "        param = dist.fit(data)\n",
    "        x = np.linspace(min(data), max(data), 10000)\n",
    "        pdf_fitted = dist.pdf(x,loc=param[0],scale=param[1])\n",
    "        plt.plot(x, pdf_fitted, label=d)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "plot_dist(mcmc_mass_hmean.postrb_hmean, \"mass\")\n",
    "plot_dist(mcmc_pd_hmean.postrb_hmean, \"pd\")\n",
    "plot_dist(mcmc_tdt_hmean.postrb_hmean, \"tdt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percent_difference(x, y):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    return (np.abs(x-y)/np.mean([x, y]))*100\n",
    "\n",
    "def get_quantile_max(name, data, q):\n",
    "    d = data.quantile(q)\n",
    "    d.index = [str(x) for x in d.index]\n",
    "    d['median_val'] = data.median()\n",
    "    d['mean_val'] = data.mean()\n",
    "    d['mad_norm'] = sm.robust.mad(data)\n",
    "    d['mad_norm_cutoff'] = 3*d['mad_norm'] + d['median_val']\n",
    "    d['mad_cauchy'] = sm.robust.mad(data, c=sp.stats.cauchy.ppf(0.75))\n",
    "    d['mad_cauchy_cutoff'] = 3*d['mad_cauchy'] + d['median_val']\n",
    "    d['cutoff'] = 0.01\n",
    "    d[\"x99_cutoff\"] = percent_difference(d['0.99'], d['cutoff'])\n",
    "    d[\"x99_median\"] =  percent_difference(d['0.99'], d['median_val'])\n",
    "    d[\"x95_cutoff\"] = percent_difference(d['0.95'], d['cutoff'])\n",
    "    d[\"x95_median\"] =  percent_difference(d['0.95'], d['median_val'])\n",
    "    d['relaxed_cutoff'] = d['0.99']\n",
    "    d['min'] = data.min()\n",
    "    d['max'] = data.max()\n",
    "    d.name = name\n",
    "    return d\n",
    "\n",
    "mass_quant = get_quantile_max(\"mass\", mcmc_mass_hmean.postrb_hmean, [0.95,0.99])\n",
    "pd_quant = get_quantile_max(\"pd\", mcmc_pd_hmean.postrb_hmean, [0.95,0.99])\n",
    "tdt_quant =get_quantile_max(\"tdt\", mcmc_tdt_hmean.postrb_hmean, [0.95,0.99]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"%s\\n\\n%s\\n\\n%s\\n\" % (mass_quant, pd_quant, tdt_quant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf['mass_quant'] = mass_quant\n",
    "hdf['pd_quant'] = pd_quant\n",
    "hdf['tdt_quant'] = tdt_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_snps_mass = mcmc_mass_hmean[mcmc_mass_hmean.postrb_hmean > mass_quant.cutoff]\n",
    "sig_snps_tdt = mcmc_tdt_hmean[mcmc_tdt_hmean.postrb_hmean > tdt_quant.cutoff]\n",
    "sig_snps_pd = mcmc_pd_hmean[mcmc_pd_hmean.postrb_hmean > pd_quant.cutoff]\n",
    "\n",
    "relaxed_sig_snps_mass = mcmc_mass_hmean[mcmc_mass_hmean.postrb_hmean > mass_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_tdt = mcmc_tdt_hmean[mcmc_tdt_hmean.postrb_hmean > tdt_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_pd = mcmc_pd_hmean[mcmc_pd_hmean.postrb_hmean > pd_quant.relaxed_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps_mass.shape, sig_snps_tdt.shape, sig_snps_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_mass.shape, relaxed_sig_snps_tdt.shape, relaxed_sig_snps_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_tdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pips = {}\n",
    "def get_contig_pip(row, pheno):\n",
    "    if not pheno in contig_pips:\n",
    "        contig_pips[pheno] = {}\n",
    "        \n",
    "    d = row.rs.split(\"_\")\n",
    "    contig = \"_\".join(d[:-1])\n",
    "    if not contig in contig_pips[pheno]:\n",
    "        contig_pips[pheno][contig] = {'betarb':0,'postrb':0}\n",
    "    contig_pips[pheno][contig]['postrb'] += row.postrb_hmean\n",
    "    contig_pips[pheno][contig]['betarb'] += row.betarb_hmean\n",
    "\n",
    "for pheno, df in list(mcmc_hmean.items()):\n",
    "    print(pheno)\n",
    "    df.apply(get_contig_pip, args=(pheno,), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_dfs = {}\n",
    "for pheno, data in list(contig_pips.items()):\n",
    "    contig_pip_dfs[pheno] = pd.DataFrame(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "contig_lengths = {}\n",
    "for rec in SeqIO.parse(assembly,\"fasta\"):\n",
    "    contig_lengths[rec.name] = {\"length\":len(rec)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df = pd.DataFrame(contig_lengths).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_mass = contig_pip_dfs['mass'].join(contig_length_df)\n",
    "contig_pip_tdt = contig_pip_dfs['tdt'].join(contig_length_df)\n",
    "contig_pip_pd = contig_pip_dfs['pd'].join(contig_length_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf['contig_pip_mass'] = contig_pip_mass\n",
    "hdf['contig_pip_tdt'] = contig_pip_tdt\n",
    "hdf['contig_pip_pd'] = contig_pip_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_contig_length_vs_pip(df, title):\n",
    "    plt.scatter(df.length, df.postrb)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"length of contig\")\n",
    "    plt.ylabel(\"postrb\")\n",
    "    plt.show()\n",
    "for key, df in list({'mass':contig_pip_mass, \n",
    "                'tdt': contig_pip_tdt, \n",
    "                'pd': contig_pip_pd}.items()):\n",
    "    plot_contig_length_vs_pip(df, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(contig_pip_dfs['tdt'].postrb, label=\"PIP\")\n",
    "plt.title(\"tdt contigs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(contig_pip_dfs['mass'].postrb, label=\"PIP\")\n",
    "plt.title(\"mass contigs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(contig_pip_dfs['pd'].postrb, label=\"PIP\")\n",
    "plt.title(\"pd contigs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_mass))\n",
    "plt.plot(mcmc_mass_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_mass_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"Mass\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_pd))\n",
    "plt.plot(mcmc_pd_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_pd_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"PD\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_tdt))\n",
    "plt.plot(mcmc_tdt_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_tdt_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"TDT\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps = {}\n",
    "for pheno, files in list(snp_files.items()):\n",
    "    if not pheno in snps:\n",
    "        snps[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        h = open(f)\n",
    "        h.readline() ##skip header\n",
    "        header = h.readline().strip().split()\n",
    "        data = []\n",
    "        for line in h:\n",
    "            line = line.strip().split()\n",
    "            data.append(line)\n",
    "            \n",
    "        testdf = pd.DataFrame(data, columns=header)\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        snps[pheno] = pd.concat([snps[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass = snps['mass'][[x for x in snps['mass'] if '_1' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def read_gamma(f):\n",
    "    d = []\n",
    "    h = open(f)\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        line = line.strip().split()\n",
    "        d.append(line)\n",
    "    df = pd.DataFrame(d, columns=header)\n",
    "    return df.replace('NA', np.nan).astype(float)\n",
    "gamma_mass = read_gamma(gamma_files['mass'][0])\n",
    "gamma_pd = read_gamma(gamma_files['pd'][0])\n",
    "gamma_tdt = read_gamma(gamma_files['tdt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf[\"sig_snps_mass\"] = sig_snps_mass\n",
    "hdf[\"sig_snps_tdt\"] = sig_snps_tdt\n",
    "hdf[\"sig_snps_pd\"] = sig_snps_pd\n",
    "hdf[\"relaxed_sig_snps_mass\"] = relaxed_sig_snps_mass\n",
    "hdf[\"relaxed_sig_snps_tdt\"] = relaxed_sig_snps_tdt\n",
    "hdf[\"relaxed_sig_snps_pd\"] = relaxed_sig_snps_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_mass.betarb_hmean.values))\n",
    "plt.text(0.007, 1.5, r\"$n = %d$\" % len(sig_snps_mass))\n",
    "plt.title(r\"Mass ($> %.2f$)\" % mass_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_mass.betarb_hmean.values))\n",
    "plt.text(0.007, 70, r\"$n = %d$\" % len(relaxed_sig_snps_mass))\n",
    "plt.title(r\"Mass 99th($> %.5f$)\" % mass_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_tdt.betarb_hmean.values))\n",
    "plt.text(0.010, 2.5, r\"$n = %d$\" % len(sig_snps_tdt))\n",
    "plt.title(r\"TDT ($> %.2f$)\" % tdt_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_tdt.betarb_hmean.values))\n",
    "plt.text(0.010, 100, r\"$n = %d$\" % len(relaxed_sig_snps_tdt))\n",
    "plt.title(r\"TDT 99th ($> %.5f$)\" % tdt_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_pd.betarb_hmean.values))\n",
    "plt.text(0.008, 6, r\"$n = %d$\" % len(sig_snps_pd))\n",
    "plt.title(r\"PD ($> %.2f$)\" % pd_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_pd.betarb_hmean.values))\n",
    "plt.text(0.008, 70, r\"$n = %d$\" % len(relaxed_sig_snps_pd))\n",
    "plt.title(r\"PD 99th ($> %.5f$)\" % pd_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
