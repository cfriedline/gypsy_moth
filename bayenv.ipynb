{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/ipynb/gypsy_moth/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp\n",
    "import shutil\n",
    "import pickle\n",
    "from utils import read_df, save_df\n",
    "import iterlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir_notimp = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni/\"\n",
    "analysis_dir_imp = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = [analysis_dir_notimp, analysis_dir_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(sp)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raster = r(\"raster\")\n",
    "extract = r(\"extract\")\n",
    "\n",
    "gps = {'QC32':[47.2509807, -79.4060515],\n",
    "      'QC93': [46.90826, -70.8061075],\n",
    "      'NC': [36.449125, -76.024672],\n",
    "      'NY': [42.897768, -74.094761],\n",
    "      'VA1': [38.657615, -77.463603],\n",
    "      'VA2': [38.857470, -77.695003]}\n",
    "gps_df = pd.DataFrame(gps).T\n",
    "gps_df.columns = ['lat','lon']\n",
    "\n",
    "latlon = pandas2ri.py2ri(gps_df[['lon', 'lat']])\n",
    "\n",
    "bioclim_dir = \"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/bioclim_13\"\n",
    "bioclim = !ls {bioclim_dir}/*.bil\n",
    "bioclim = sorted(bioclim)\n",
    "bioclim_df = pd.DataFrame(gps_df)\n",
    "for b in bioclim:\n",
    "    rast = raster(b)\n",
    "    bio = os.path.basename(b).split(\"_\")[0].upper()\n",
    "    vals = pd.DataFrame(pandas2ri.ri2py(extract(rast, latlon)))\n",
    "    vals.index = bioclim_df.index\n",
    "    vals.columns = [bio]\n",
    "    bioclim_df = bioclim_df.join(vals)\n",
    "bioclim_df = bioclim_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in analysis_dir:\n",
    "    save_df(d, \"bioclim_df\", bioclim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = []\n",
    "for d in analysis_dir:\n",
    "    z12_swapped.append(read_df(d, \"z12_swapped\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = []\n",
    "for d in analysis_dir:\n",
    "    infile = os.path.join(d, \"pop_allele_data.pkl\")\n",
    "    paf = pickle.load(open(infile, \"rb\"))\n",
    "    pop_allele_freqs.append(paf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsfile_df = []\n",
    "for i, paf in enumerate(pop_allele_freqs):\n",
    "    pops = sorted(paf)\n",
    "    paf_data = defaultdict(defaultdict)\n",
    "    for popn in pops:\n",
    "        af = pd.DataFrame(paf[popn])        \n",
    "        for snp in af:\n",
    "            paf_data[\"%s_1\" % snp][popn] = af.ix[\"P\",snp]\n",
    "            paf_data[\"%s_2\" % snp][popn] = af.ix[\"Q\",snp]  \n",
    "    df = pd.DataFrame(paf_data).T\n",
    "    df['blank'] = \"\"\n",
    "    snpsfile_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environ_cols = snpsfile_df[0].columns.drop(\"blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environ_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [read_df(x, \"bioclim_df\") for x in analysis_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bioclim[1].to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [bioclim[1]]\n",
    "bioclim = [x[[y for y in x if 'BIO' in y]] for x in bioclim]\n",
    "bioclim = [x.T for x in bioclim]\n",
    "bioclim = [x[environ_cols] for x in bioclim]\n",
    "bioclim = [x.astype(float) for x in bioclim]\n",
    "bioclim = [x.apply(preprocessing.scale, axis=1) for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [x.assign(blank=lambda x: \"\") for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim.append(bioclim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,snps in enumerate(snpsfile_df):\n",
    "    snp_outfile = os.path.join(analysis_dir[i], \"snpsfile\")\n",
    "    env_outfile = os.path.join(analysis_dir[i], \"environfile\")\n",
    "    snps.to_csv(snp_outfile, sep=\"\\t\", header=False, index=False)\n",
    "    envs = bioclim[i]\n",
    "    envs.to_csv(env_outfile, sep=\"\\t\", header=False, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bayenv to create covariance matrix\n",
    "\n",
    "```bash\n",
    "~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 100000 -r 187564 > matrix.out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcov = []\n",
    "for d in analysis_dir[1:]:    \n",
    "    vcovs = []\n",
    "    current = None\n",
    "    for line in open(os.path.join(d, \"matrix.out\")):\n",
    "        if \"VAR-COVAR\" in line:\n",
    "            current = []\n",
    "            vcovs.append(current)\n",
    "        if isinstance(current, list):\n",
    "            current.append(line.strip().split(\"\\t\"))\n",
    "    vcov.append(vcovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcov_dfs = []\n",
    "for v in vcov:\n",
    "    vcov_dfs_temp = []\n",
    "    for i, elem in enumerate(v):\n",
    "        vcov_dfs_temp.append(pd.DataFrame(elem[1:]).T)\n",
    "    vcov_dfs.append(vcov_dfs_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_correlations = []\n",
    "for vcov_df in vcov_dfs:\n",
    "    temp = []\n",
    "    for i in range(len(vcov_df)):\n",
    "        for j in range(len(vcov_df)):\n",
    "            if j == (i + 1):\n",
    "                idf = vcov_df[i]\n",
    "                jdf = vcov_df[j]\n",
    "                idf = idf.ix[:,:len(idf)-1]\n",
    "                jdf = jdf.ix[:,:len(jdf)-1]\n",
    "                idf = [float(x) for x in idf.values.flatten()]\n",
    "                jdf = [float(x) for x in jdf.values.flatten()]\n",
    "                assert len(idf) == len(jdf)\n",
    "                temp.append(sp.stats.pearsonr(idf, jdf)[0])\n",
    "    matrix_correlations.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for matrix_correlation in matrix_correlations:\n",
    "    plt.plot(list(range(len(matrix_correlation))),matrix_correlation)\n",
    "    plt.title(\"Pearson correlations among %d adjacent VCOV matrices\" % len(matrix_correlation))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate(analysis_dir[1:]):\n",
    "    out_matrix = os.path.join(d, \"matrix_last.out\")\n",
    "    matrix = vcov_dfs[i][-1]\n",
    "    matrix.to_csv(out_matrix, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_indv = [x.drop(\"blank\", axis=1) for x in snpsfile_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in snp_indv:\n",
    "    s['snp_name'] = s.apply(lambda x: \"_\".join(x.name.split(\"_\")[0:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_bayenv_files():\n",
    "    bayenv = []\n",
    "    for i, s in enumerate(snp_indv):\n",
    "        temp = []\n",
    "        bayenv.append(temp)\n",
    "        outdir = os.path.join(analysis_dir[i], \"bayenv\")\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        for group, data in s.groupby(\"snp_name\"):\n",
    "            bayenv_file = os.path.join(outdir, \"%s.txt\" % group)\n",
    "            temp.append(bayenv_file)\n",
    "            data = pd.DataFrame(data)\n",
    "            data['blank'] = \"\"\n",
    "            data = data.drop(\"snp_name\", axis=1)\n",
    "            data.to_csv(bayenv_file, index=False, header=False, sep=\"\\t\")\n",
    "    return bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayenv = write_bayenv_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = !find {os.path.join(analysis_dir[1], \"bayenv\")} | grep tg | grep 'txt$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = [[], sorted(bayenv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bayenv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_jobs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks = int(np.round(len(bayenv[1])/bayenv_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_exe = \"/home/cfriedline/g/src/bayenv2_public/bayenv2\"\n",
    "bayenv_opt = \"-i snpfile -m matrixfile -e environfile -p 6 -k 100000 -n 19 -t -X -c -f -r rand\"\n",
    "\n",
    "total = 0\n",
    "for i, bayenv_files in enumerate(bayenv):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    cpu = 0\n",
    "    max_cpu = 30\n",
    "    thedir = analysis_dir[i]\n",
    "    shutil.copy(os.path.join(thedir, \"matrix_last.out\"), os.path.dirname(bayenv_files[0]))\n",
    "    shutil.copy(os.path.join(thedir, \"environfile\"), os.path.dirname(bayenv_files[0]))\n",
    "    chunks=[bayenv_files[x:x+num_chunks] for x in range(0, len(bayenv_files), num_chunks)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(os.path.dirname(bayenv_files[0]), \"bayenv_parallel_%d\" % i), \"w\") as o:\n",
    "            for bayenv_file in chunk:\n",
    "                bayenv_cmd = \" \".join([bayenv_exe, bayenv_opt]).split()\n",
    "                if cpu == max_cpu:\n",
    "                    cpu = 0\n",
    "\n",
    "                bayenv_cmd[2] = os.path.basename(bayenv_file)\n",
    "                bayenv_cmd[4] = \"matrix_last.out\"\n",
    "                bayenv_cmd[6] = \"environfile\"\n",
    "                bayenv_cmd[-1] = int(random.getrandbits(16))\n",
    "                bayenv_cmd.insert(0, \"taskset -c %d\" % cpu)\n",
    "                #bayenv_cmd.append(\"-o bayenv_%d\" % i)\n",
    "                bayenv_cmd.append(\"-o %s\" % os.path.basename(bayenv_file).replace(\".txt\",\"\"))\n",
    "                o.write(\"%s\\n\" % \" \".join([str(x) for x in bayenv_cmd]))\n",
    "                total += 1\n",
    "                cpu += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile='sge')\n",
    "dv = rc[:]\n",
    "lv = rc.load_balanced_view()\n",
    "len(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_count(f):\n",
    "    res = !wc -l {f}\n",
    "    return int(res[0].split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv['get_line_count'] = get_line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_parallel = !find {os.path.join(analysis_dir[1], \"bayenv\")} | grep bayenv_parallel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for f in bayenv_parallel:\n",
    "    print(f)\n",
    "    total += get_line_count(f)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_parallel = sorted(bayenv_parallel)\n",
    "len(bayenv_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_parallel[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n1 {bayenv_parallel[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_qsub_files(bayenv_parallel):\n",
    "    files = []\n",
    "    for i, f in enumerate(bayenv_parallel):\n",
    "        d = os.path.join(analysis_dir[1], \"bayenv\")\n",
    "        qsub_file = os.path.join(d, \"qsub_%d.sh\" % i)\n",
    "        files.append(qsub_file)\n",
    "        with open(qsub_file, \"w\") as o:\n",
    "            os.chmod(o.name, 0o744)\n",
    "            print(o.name)\n",
    "            o.write(\"%s\\n\" % \"\\n\".join([\"#!/bin/bash\", \n",
    "                                        \"#$ -N bayenv%d\" % i,\n",
    "                                        \"#$ -V\",\n",
    "                                        \"#$ -cwd\",\n",
    "                                       \"#$ -pe smp 30\",\n",
    "                                       \"#$ -j y\",\n",
    "                                        \"#$ -q all.q\",\n",
    "                                        \"unset module\",\n",
    "                                        \"echo \\\"Running on $HOSTNAME\\\"\",\n",
    "                                       \"cat %s | ~/bin/parallel -j 30 --progress --\" % f]))\n",
    "    return files\n",
    "qsub_files = write_qsub_files(bayenv_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat /home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/bayenv/qsub_0.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, ad in enumerate(analysis_dir):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    d = os.path.join(ad, \"bayenv\")\n",
    "    with open(os.path.join(d, \"qsub_runner.sh\"), \"w\") as o:\n",
    "        os.chmod(o.name, 0o744)\n",
    "        o.write(\"#!/bin/bash\\n\")\n",
    "        o.write(\"unset module\\n\")\n",
    "        for q in qsub_files:\n",
    "            o.write(\"qsub %s\\n\" % q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n5 {os.path.join(d, \"qsub_runner.sh\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qhost = !qhost | grep godel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for elem in qhost:\n",
    "    host = elem.split()[0]\n",
    "    if not host in ['godel200',\n",
    "                   'godel21',\n",
    "                   'godel37']:\n",
    "        !ssh {host} pkill -9 bayenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bayenv jobs\n",
    "\n",
    "```bash\n",
    "cd ~/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/bayenv\n",
    "\n",
    "rm -f XtX_out.environfile\n",
    "rm -f bf_environ.environfile\n",
    "rm -f bayenv*.o*\n",
    "rm -f bayenv*.po*\n",
    "rm -f *.xtx\n",
    "rm -f *.bf\n",
    "rm -f *.txt.freqs\n",
    "\n",
    "./qsub_runner.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vartypes = ['bf', 'r', 'p']\n",
    "bf_cols = []\n",
    "for b in bioclim[0].index:\n",
    "    for v in vartypes:\n",
    "        bf_cols.append(\"%s_%s\" % (b, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtxs = !ls {analysis_dir[1]}/bayenv | grep '.xtx'\n",
    "xtxs = sorted([os.path.join(analysis_dir[1] + \"bayenv\", x) for x in xtxs])\n",
    "len(xtxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bfs = !ls {analysis_dir[1]}/bayenv | grep '.bf'\n",
    "bfs = sorted([os.path.join(analysis_dir[1] + \"bayenv\", x) for x in bfs])\n",
    "len(bfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bfs), len(xtxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_bayenv(args):\n",
    "    f, key, cols = args\n",
    "    import pandas as pd\n",
    "    key = key.lower()\n",
    "    df = pd.read_csv(f, sep=\"\\t\", header=None, index_col=0)\n",
    "    if key == 'xtx':\n",
    "        df.columns = ['xtx']\n",
    "    elif key == \"bf\":\n",
    "        df = df.drop(df.columns[-1], axis=1)\n",
    "    df.index = [x.replace(\".txt\", \"\") for x in df.index]\n",
    "    df.index.name = \"SNP\"\n",
    "    if cols:\n",
    "        df.columns=cols\n",
    "    return df.ix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv['read_bayenv'] = read_bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtx_args = [(x, 'xtx', None) for x in xtxs]\n",
    "bf_args = [(x, 'bf', bf_cols) for x in bfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xtx_dfs = [read_bayenv(x, \"xtx\") for x in xtxs]\n",
    "xtx_dfs = dv.map_async(read_bayenv, xtx_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtx_dfs = xtx_dfs.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs = dv.map_async(read_bayenv, bf_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs.progressgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs = bf_dfs.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf = pd.concat(bf_dfs)\n",
    "xtx = pd.concat(xtx_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtx.shape, bf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_makeup_bayenv(f):\n",
    "    import os\n",
    "    cmd = \"cd %s && /home/cfriedline/g/src/bayenv2_public/bayenv2 -i %s \\\n",
    "-m %s -e %s -p 6 -k 100000 \\\n",
    "-n 19 -t -X -c -f -r 2573 \\\n",
    "-o %s\" % (os.path.dirname(f),\n",
    "          os.path.basename(f),\n",
    "          \"matrix_last.out\", \n",
    "          \"environfile\",\n",
    "          os.path.basename(f).replace(\".txt\", \"\"))\n",
    "    !$cmd\n",
    "    return f, cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_makeup = []\n",
    "for f in bayenv[1]:\n",
    "    name = os.path.basename(f).split(\".\")[0]\n",
    "    if not name in xtx.index:\n",
    "        bayenv_makeup.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv['run_makeup_bayenv'] = run_makeup_bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_makeup_bayenv(bayenv_makeup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(makeup), len(bayenv_makeup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "makeup = dv.map_async(run_makeup_bayenv, bayenv_makeup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makeup.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for snp in xtx.index:\n",
    "    d = os.path.join(analysis_dir[1], \"bayenv\")\n",
    "    f = os.path.join(d, \"%s.txt\" % snp)\n",
    "    if not os.path.exists(f):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(xtx)\n",
    "ax.set_xlabel(\"XtX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = xtx.join(bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bf_vs_xtx(df, imputed, dir_name):\n",
    "    num_figs = len(df.columns)-1\n",
    "    print(num_figs)\n",
    "    plt.gcf().set_size_inches(20,20)\n",
    "    for i in range(num_figs):\n",
    "        if i > 0:\n",
    "            plt.subplot(5,4,i)\n",
    "            plt.title(\"%s (%s)\" % (df.columns[i].split(\"_\")[0], imputed))\n",
    "            plt.xlabel(\"BF\")\n",
    "            plt.ylabel(df.columns[0])\n",
    "            plt.scatter(df.ix[:,i],df.ix[:,0])\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "                    wspace=.5, hspace=.5)\n",
    "    plt.savefig(\"%s.pdf\" % os.path.join(dir_name, \"bf_vs_xtx_%s\" % imputed))\n",
    "    plt.show()\n",
    "plot_bf_vs_xtx(pd.DataFrame(xtx).join(bf[[x for x in bf if 'bf' in x]]), \"imputed\", analysis_dir[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtx_outliers = []\n",
    "impute_status = [\"imputed\"]\n",
    "for i, res in enumerate([joined]):\n",
    "    XtX = res.xtx\n",
    "    M = np.median(XtX)    \n",
    "    MAD = sm.robust.mad(XtX)\n",
    "    lower_cutoff = M-(3*MAD)\n",
    "    upper_cutoff = M+(3*MAD)\n",
    "    lower_snps = sorted(XtX[XtX<lower_cutoff].index.tolist())\n",
    "    upper_snps = sorted(XtX[XtX>upper_cutoff].index.tolist())\n",
    "    percent_cutoff = np.percentile(XtX, 99)\n",
    "    percent_cutoff_outliers = sorted(XtX[XtX > percent_cutoff].index.tolist())\n",
    "    o = pd.DataFrame([impute_status[i], \n",
    "                      M,\n",
    "                      MAD,\n",
    "                      lower_cutoff, \n",
    "                      upper_cutoff, \n",
    "                      len(lower_snps), \n",
    "                      len(upper_snps), \n",
    "                      lower_snps, \n",
    "                      upper_snps,\n",
    "                     percent_cutoff, \n",
    "                      len(percent_cutoff_outliers),\n",
    "                      percent_cutoff_outliers]).T\n",
    "    o.columns = ['state', 'median_XtX', 'MAD', 'lower_cutoff', 'upper_cutoff', 'n_lower', 'n_upper', \n",
    "                'lower_snps', 'upper_snps', 'percent_cutoff_XtX', 'n_percent_cutoff', '99th_snps']\n",
    "    xtx_outliers.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(xtx_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtx.sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
