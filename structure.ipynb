{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils/\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib.request as urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import dill\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.3/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_92/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.18/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40\"\n",
    "imputed_vcf_gz = os.path.join(imp_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "imputed_vcf = os.path.join(imp_dir, \"isect_snps.recode.vcf.gz_sorted.vcf\")\n",
    "vcf_files = [imputed_vcf_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "def get_translated_name(n):\n",
    "    row = translation_df.ix[n.strip()]\n",
    "    return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "\n",
    "names = [get_translated_name(x.strip()) for x in open(\"{}.012.indv\".format(imputed_vcf_gz)).readlines()]\n",
    "names = pd.DataFrame(names, columns=[\"s\"])\n",
    "names[\"p\"] = names.s.apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names.to_csv(os.path.join(imp_dir, \"structure_pops.txt\"), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgd = \"/home/cfriedline/g/src/PGDSpider_2.1.0.3/PGDSpider2-cli.jar\"\n",
    "spid = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/vcf_to_structure.spid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$java -Xmx1024m -Xms512m -jar $pgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {}
   },
   "source": [
    "## spid file\n",
    "\n",
    "```\n",
    "# spid-file generated: Wed Aug 03 13:31:31 EDT 2016\n",
    "\n",
    "# VCF Parser questions\n",
    "PARSER_FORMAT=VCF\n",
    "\n",
    "# Only output SNPs with a phred-scaled quality of at least:\n",
    "VCF_PARSER_QUAL_QUESTION=\n",
    "# Select population definition file:\n",
    "VCF_PARSER_POP_FILE_QUESTION=/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/structure_pops.txt\n",
    "# What is the ploidy of the data?\n",
    "VCF_PARSER_PLOIDY_QUESTION=DIPLOID\n",
    "# Do you want to include a file with population definitions?\n",
    "VCF_PARSER_POP_QUESTION=true\n",
    "# Output genotypes as missing if the phred-scale genotype quality is below:\n",
    "VCF_PARSER_GTQUAL_QUESTION=\n",
    "# Do you want to include non-polymorphic SNPs?\n",
    "VCF_PARSER_MONOMORPHIC_QUESTION=false\n",
    "# Only output following individuals (ind1, ind2, ind4, ...):\n",
    "VCF_PARSER_IND_QUESTION=\n",
    "# Only input following regions (refSeqName:start:end, multiple regions: whitespace separated):\n",
    "VCF_PARSER_REGION_QUESTION=\n",
    "# Output genotypes as missing if the read depth of a position for the sample is below:\n",
    "VCF_PARSER_READ_QUESTION=\n",
    "# Take most likely genotype if \"PL\" or \"GL\" is given in the genotype field?\n",
    "VCF_PARSER_PL_QUESTION=true\n",
    "# Do you want to exclude loci with only missing data?\n",
    "VCF_PARSER_EXC_MISSING_LOCI_QUESTION=false\n",
    "\n",
    "# STRUCTURE Writer questions\n",
    "WRITER_FORMAT=STRUCTURE\n",
    "\n",
    "# Specify the locus/locus combination you want to write to the STRUCTURE file:\n",
    "STRUCTURE_WRITER_LOCUS_COMBINATION_QUESTION=\n",
    "# Do you want to include inter-marker distances?\n",
    "STRUCTURE_WRITER_LOCI_DISTANCE_QUESTION=false\n",
    "# Specify which data type should be included in the STRUCTURE file  (STRUCTURE can only analyze one data type per file):\n",
    "STRUCTURE_WRITER_DATA_TYPE_QUESTION=SNP\n",
    "# Save more specific fastSTRUCTURE format?\n",
    "STRUCTURE_WRITER_FAST_FORMAT_QUESTION=true\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!{java} -Xmx4096m -Xms4096m -jar {pgd} -inputfile {imputed_vcf} -outputfile {imp_dir}/structure.str -spid {spid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf = pd.read_csv(os.path.join(imp_dir, \"structure.str\"), sep=\"\\t\", header=None)\n",
    "strdf = strdf.sort_values(0)\n",
    "strdf[0] = [get_translated_name(x) for x in strdf[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf['p'] = strdf[0].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poporder = {'NC':1, 'NY':4, 'QC32':5, 'QC93':6, 'VA1':2, 'VA2':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf['porder'] = strdf['p'].apply(lambda x: poporder[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf = strdf.sort_values(['porder', 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf.ix[:,0:7].to_csv(os.path.join(imp_dir, \"structure_sorted.str\"),\n",
    "            sep=\"\\t\", \n",
    "            header=False,\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(imp_dir, \"poplabels.txt\"), \"w\") as o:\n",
    "    for sample, data in strdf.groupby(0):\n",
    "        o.write(\"{}\\n\".format(data['p'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup jobs from 4-8\n",
    "\n",
    "`conda create -n faststructure python=2.7 numpy scipy cython`\n",
    "\n",
    "`$ cat faststructure.q`\n",
    "\n",
    "```\n",
    "#$ -S /bin/sh\n",
    "#$ -N fS\n",
    "#$ -cwd\n",
    "#$ -V\n",
    "source activate faststructure\n",
    "python $HOME/g/src/fastStructure/structure.py -K $1 \\\n",
    "--input=structure_sorted \\\n",
    "--output=faststructure.$1.$SGE_TASK_ID \\\n",
    "--format=str \\\n",
    "--full\n",
    "```\n",
    "\n",
    "## Run jobs\n",
    "```\n",
    "qsub -t 1-5 faststructure.q \"2\"\n",
    "qsub -t 1-5 faststructure.q \"3\"\n",
    "qsub -t 1-5 faststructure.q \"4\"\n",
    "qsub -t 1-5 faststructure.q \"5\"\n",
    "qsub -t 1-5 faststructure.q \"6\"\n",
    "qsub -t 1-5 faststructure.q \"7\"\n",
    "qsub -t 1-5 faststructure.q \"8\"\n",
    "#qsub -t 1-5 faststructure.q \"9\"\n",
    "#qsub -t 1-5 faststructure.q \"10\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "source": [
    "## Summarize with PopHelper (https://github.com/royfrancis/pophelper)\n",
    "\n",
    "```R\n",
    "install.packages('devtools',dependencies=T)\n",
    "library(devtools)\n",
    "install_github('royfrancis/pophelper')\n",
    "```\n",
    "\n",
    "```R\n",
    "library(pophelper)\n",
    "files = list.files(path=\".\", pattern=glob2rx(\"*.meanQ\"))\n",
    "tr = tabulateRunsMatrix(files)\n",
    "sr = summariseRunsMatrix(tr)\n",
    "clumppExportMatrix(files, useexe=T)\n",
    "poplabels = read.delim(\"poplabels.txt\", header=F, stringsAsFactors=F)\n",
    "collectClumppOutput(prefix=\"MATRIXpop\", filetype=\"merged\")\n",
    "merged_files=list.files(path=\"MATRIXpop-merged\", full.names=T)\n",
    "plotRuns(merged_files, imgoutput=\"tab\", poplab=poplabels$V1, subsetpops=c(\"NC\", \"VA1\", \"VA2\", \"NY\", \"QC32\", \"QC93\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## separate out into run1, run2 to run chooseK.py\n",
    "\n",
    "outprefix = os.path.join(imp_dir, \"faststructure*.log\")\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "logfiles = glob.glob(outprefix)\n",
    "\n",
    "for l in logfiles:\n",
    "    chain = os.path.basename(l).split(\".\")[-3]\n",
    "    rundir = \"{}/run{}\".format(os.path.join(os.path.dirname(l)), chain)\n",
    "    if not os.path.exists(rundir):\n",
    "        os.mkdir(rundir)\n",
    "    shutil.copy(l, rundir)\n",
    "    shutil.copy(l.replace(\".log\", \".meanQ\"), rundir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poplabels = pd.read_csv(os.path.join(imp_dir, \"poplabels.txt\"), header=None, names=[\"poplabel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sed 's/^[ ]*//g' MATRIXpop_K7-combined-merged.txt | sed 's/: \\+/ /g' | sed 's/ \\+/ /g' > MATRIXpop_K7-combined-merged.txt.fixed\n",
    "merged_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/MATRIXpop-merged\"\n",
    "merged_file= \"MATRIXpop_K7-combined-merged.txt.fixed\"\n",
    "merged = pd.read_csv(os.path.join(merged_dir, merged_file), sep=\" \", header=None)\n",
    "merged = merged.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled = merged.join(poplabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newcols = [\"Cluster{}\".format(x) for x in labeled.columns[0:7]]\n",
    "newcols.append(\"summ\")\n",
    "newcols.append(\"poplabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled.columns = newcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.to_csv(\"labeled.csv\", sep=\"\\t\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted = pd.melt(labeled.drop(\"summ\", axis=1), \n",
    "                 id_vars=['poplabel'],\n",
    "                var_name=[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = 1\n",
    "sns.set_context(\"talk\")\n",
    "for label, data in labeled.groupby(\"poplabel\"):\n",
    "    d = data.iloc[:,0:7].apply(np.mean)\n",
    "    plt.subplot(2,3,num)\n",
    "    patches, texts = plt.pie(d, shadow=False, startangle=0)\n",
    "    plt.title(label)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    num+=1\n",
    "\n",
    "    plt.legend(patches, list(d.index), \n",
    "           loc = 'upper right', \n",
    "           bbox_to_anchor = (0,-0.35,1.1,1),\n",
    "           bbox_transform = plt.gcf().transFigure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps = {'QC32':[47.2509807, -79.4060515],\n",
    "      'QC93': [46.90826, -70.8061075],\n",
    "      'NC': [36.449125, -76.024672],\n",
    "      'NY': [42.897768, -74.094761],\n",
    "      'VA1': [38.657615, -77.463603],\n",
    "      'VA2': [38.857470, -77.695003]}\n",
    "gps_df = pd.DataFrame(gps).T\n",
    "gps_df.columns = ['lat','lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"latlon.txt\"):\n",
    "    gps_df.to_csv(\"laton.txt\", sep=\"\\t\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Basemap(projection='cyl', \n",
    "            llcrnrlon=-89.950078, \n",
    "            llcrnrlat=33.565319, \n",
    "            urcrnrlon=-69.977811, \n",
    "            urcrnrlat=47.912892, resolution=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.readshapefile(\"/home/cfriedline/g/src/tl_2014_us_state/tl_2014_us_state\", name=\"states\", drawbounds=False);\n",
    "m.readshapefile(\"/home/cfriedline/g/src/ca_province/PROVINCE\", name=\"ca\", drawbounds=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.drawcoastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p, t = plt.pie(d, shadow=False, startangle=0)\n",
    "ax = plt.gca()\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
