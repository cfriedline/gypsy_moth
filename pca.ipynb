{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils/\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import cyvcf\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import dill\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.2/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.2/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.16/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.2/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.2/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/samtools-1.2/htslib-1.2.1/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/samtools-1.2/htslib-1.2.1/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notimputed_vcf_gz = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/isect.vcf.gz.sorted.gz\"\n",
    "imputed_vcf_gz = '/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/isect.vcf.gz.sorted.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcfs = [notimputed_vcf_gz, imputed_vcf_gz]\n",
    "for v in vcfs:\n",
    "    !$vcftools --gzvcf $v --012 --out $v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12s = [\"%s.012\" % x for x in vcfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "def get_translated_name(n):\n",
    "    row = translation_df.ix[n.strip()]\n",
    "    return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_z12_df(z12_file):\n",
    "    indv_file = \"%s.indv\" % z12_file\n",
    "    pos_file = \"%s.pos\" % z12_file\n",
    "    z12_data = []\n",
    "    for i, line in enumerate(open(z12_file)):\n",
    "        line = line.strip()\n",
    "        line = [int(x) for x in line.split(\"\\t\")]\n",
    "        z12_data.append(np.array(line))\n",
    "    z12_data = np.array(z12_data)\n",
    "    p = pd.read_csv(pos_file, sep=\"\\t\", names=['contig', 'pos'])\n",
    "    i = pd.read_csv(indv_file, names=['sample_name'])\n",
    "    df = pd.DataFrame(z12_data)\n",
    "    df = df.drop(0, axis=1)\n",
    "    df.columns = p.apply(lambda x: \"%s_%s\" % (x.contig, x.pos), axis=1)\n",
    "    df.index = [get_translated_name(x) for x in i.sample_name]\n",
    "    return df\n",
    "z12_dfs = [get_z12_df(x) for x in z12s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_population(df):\n",
    "    df['population'] = df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "[assign_population(x) for x in z12_dfs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = [x.ix[:,:-1].apply(get_allele_freqs, args=(False,)) for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mafs = [x.apply(lambda x: min(x[\"p\"], x[\"q\"])) for x in allele_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mafs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(mafs[0], mafs[1])\n",
    "plt.title(\"MAF\")\n",
    "plt.xlabel(\"not imputed\")\n",
    "plt.ylabel(\"imputed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_alleles(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        if maf == freqs[\"p\"]:\n",
    "            return locus.replace({0:2,2:0})\n",
    "        return locus\n",
    "    else:\n",
    "        return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = []\n",
    "for i, z12 in enumerate(z12_dfs):\n",
    "    z12_swapped.append(z12.apply(swap_alleles, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(z12_dfs[0]['population'].unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1\n",
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_popid(series):\n",
    "    series['popid'] = pop_id[series['population']]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = [x.apply(assign_popid, axis=1) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        #locus_id = int(locus.name[1:])\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = []\n",
    "for i, df in enumerate(z12_swapped):\n",
    "    pca_std.append(df.apply(center_and_standardize, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = [x.ix[:,:-2] for x in pca_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp = r('prcomp')\n",
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prcomp_res = [prcomp(x, scale=False, center=False) for x in pca_std_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pca_x(res):\n",
    "    x = pd.DataFrame(pandas2ri.ri2py(res.rx2(\"x\")))\n",
    "    x.index = res.rx2(\"x\").names[0]\n",
    "    x.columns = res.rx2(\"x\").names[1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = [get_pca_x(x) for x in prcomp_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))\n",
    "def plot_pca(key, pca_std, pca_std_data, pca_x, prcomp_res):\n",
    "    joined = pca_std.join(pca_x)\n",
    "    legend = {}\n",
    "    for row in joined.iterrows():\n",
    "        pop = row[1]['population']\n",
    "        n = norm(pop_id[pop])\n",
    "        color = cm.rainbow(n)\n",
    "        legend[pop] = color\n",
    "        plt.scatter(row[1].PC1, \n",
    "                    row[1].PC2, \n",
    "                    s=50, \n",
    "                    c=color)\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    cmap = plt.get_cmap()\n",
    "    fig.set_size_inches(10,8)\n",
    "    plt.title(\"PCA of n=%d samples (%s) on %d loci\" % (len(joined), key, len(pca_std_data.columns)))\n",
    "    imp = summary(prcomp_res).rx(\"importance\")[0]\n",
    "    plt.xlabel(\"PC1 (%g)\" % imp.rx(2,1)[0])\n",
    "    plt.ylabel(\"PC2 (%g)\" % imp.rx(2,2)[0])\n",
    "\n",
    "    handles = []\n",
    "    for pop in sorted(legend):\n",
    "        handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "    plt.legend(handles=sorted(handles))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, key in enumerate([\"not imputed\", \"imputed\"]):\n",
    "    plot_pca(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, key in enumerate([\"not_imputed\", \"imputed\"]):\n",
    "    filedir = os.path.dirname(z12s[i])\n",
    "    hdffile = os.path.join(filedir, \"isect.hd5\")\n",
    "    print hdffile\n",
    "    !rm -f $hdffile\n",
    "    hdf = HDFStoreHelper(hdffile)\n",
    "    hdf['z12_df'] = z12_dfs[i]\n",
    "    hdf['z12_swapped'] = z12_swapped[i]\n",
    "    hdf['pca_std'] =  pca_std[i]\n",
    "    hdf['pca_std_data'] = pca_std_data[i]\n",
    "    hdf['mafs'] = mafs[i]\n",
    "    hdf['allele_freqs'] = allele_freqs[i]\n",
    "    hdf['pca_x'] = pca_x[i]\n",
    "    print hdf.get_group_names()\n",
    "    dill.dump(prcomp_res, open(os.path.join(filedir, \"isect_prcomp.dill\"), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWcalc = r('TWcalc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_notimputed = pca_std_data[0]\n",
    "pca_std_data_imputed = pca_std_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i pca_std_data_notimputed\n",
    "%R -i pca_std_data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "tw_notimputed = TWcalc(as.matrix(pca_std_data_notimputed),12)\n",
    "tw_imputed = TWcalc(as.matrix(pca_std_data_imputed),12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tws = [r(\"tw_notimputed[[2]]\"), r(\"tw_imputed[[2]]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sig_tracywidom(tw_p):\n",
    "    ps = []\n",
    "    for i, p in enumerate(tw_p):\n",
    "        if p > 0.05:\n",
    "            print(i, p)\n",
    "            break\n",
    "        else:\n",
    "            ps.append(p)\n",
    "    return len(ps), ps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[get_sig_tracywidom(x) for x in tws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.get_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
