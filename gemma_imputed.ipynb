{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import dill\n",
    "import random\n",
    "import vcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%load_ext rpy2.ipython\n",
    "r = ro.r\n",
    "%matplotlib inline\n",
    "from utils import save_df, read_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\"\n",
    "snp_file_gz = \"isect_snps.recode.vcf.gz_sorted.vcf.gz\"\n",
    "tabix = \"/home/cfriedline/g/src/htslib-1.3/tabix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write GEMMA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = read_df(analysis_dir, 'pca_std_pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno = pca_std_pheno[[\"Population\",\n",
    "                              \"Number\",\n",
    "                              \"Mass\",\n",
    "                              \"Pupual Duration\",\n",
    "                              \"Total Dev Time\"]]\n",
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'gemma_pheno', gemma_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_x = read_df(analysis_dir, 'pca_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = gemma_pheno.join(pca_x, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno_pca = pca_std_pheno[[x for x in pca_std_pheno if \"PC\" in x or 'Mass' in x or 'Pupual' in x or 'Total Dev' in x]]\n",
    "gemma_pheno_pca.columns = [x.replace(\" \", \"_\") for x in gemma_pheno_pca.columns]\n",
    "gemma_pheno_pca.index = [x for x in gemma_pheno_pca.index]\n",
    "phenos = [\"Mass\", \"Pupual_Duration\", \"Total_Dev_Time\"]\n",
    "for p in phenos:\n",
    "    mod = smf.ols(formula=\"%s~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13+PC14+PC15+PC16\" % p, data=gemma_pheno_pca)\n",
    "    res = mod.fit()\n",
    "    col = \"%s_resid\" % p\n",
    "    col = col.lower()\n",
    "    gemma_pheno[col] = res.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = read_df(analysis_dir, 'z12_swapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df = read_df(analysis_dir, 'z12_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "def get_correct_name(row, trans):\n",
    "    trans[row.name] = \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "\n",
    "name_translation = {}\n",
    "translation_df.apply(get_correct_name, args=(name_translation,), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readvcf = open(os.path.join(analysis_dir, snp_file_gz), \"rb\")\n",
    "reader = vcf.VCFReader(readvcf)\n",
    "gt_base_data = {}\n",
    "gt_ref_alt = {}\n",
    "at = 0\n",
    "for snp in reader:\n",
    "    snp_id = \"%s_%d\" % (snp.CHROM, snp.POS)\n",
    "    gt_ref_alt[snp_id] = {'ref': snp.REF, 'alt': snp.ALT[0]}\n",
    "    for sample in snp.samples:\n",
    "        if not snp_id in gt_base_data:\n",
    "            gt_base_data[snp_id] = {}\n",
    "        sample_name = name_translation[sample.sample]\n",
    "        bases = sample.gt_bases.replace(\"|\",\"/\")\n",
    "        gt_base_data[snp_id][sample_name] = bases\n",
    "    at += 1\n",
    "    if at % 1000 == 0:\n",
    "        print(at)\n",
    "gt_base_df = pd.DataFrame(gt_base_data)\n",
    "readvcf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_ref_alt_df = pd.DataFrame(gt_ref_alt)\n",
    "gt_ref_alt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'gt_base_df', gt_base_df)\n",
    "save_df(analysis_dir, 'gt_ref_alt_df', gt_ref_alt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swap_gt_alleles(gt, het):   \n",
    "    if isinstance(gt, float): #NaN\n",
    "        return np.NaN\n",
    "    if gt is None:\n",
    "        return np.NaN\n",
    "    if gt[0] == gt[-1]:\n",
    "        return gt\n",
    "    else:\n",
    "        return het # already in minor/major\n",
    "    \n",
    "def swap_gt(snp):\n",
    "    vc = snp.value_counts()\n",
    "    counts = {}\n",
    "    for v in vc.index:\n",
    "        if not v[0] in counts:\n",
    "            counts[v[0]] = 0.0\n",
    "        if not v[-1] in counts:\n",
    "            counts[v[-1]] = 0.0\n",
    "        counts[v[0]] += vc[v]\n",
    "        counts[v[-1]] += vc[v]\n",
    "    counts2 = sorted(list(counts.items()), key=operator.itemgetter(1)) #e.g., [('A', 110.0), ('G', 236.0)]\n",
    "    minor = counts2[0][0]\n",
    "    major = counts2[1][0]\n",
    "    het = \"%s/%s\" % (minor, major)\n",
    "    gt_ref_alt[snp.name]['minor'] = minor\n",
    "    gt_ref_alt[snp.name]['major'] = major\n",
    "    return snp.apply(swap_gt_alleles, args=(het,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_base_df_swapped = gt_base_df.apply(swap_gt)\n",
    "gt_base_df_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'gt_base_df_swapped', gt_base_df_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_GP_to_L(q):\n",
    "    return pow(10,(-q/10.0))\n",
    "\n",
    "def get_dosage(gp, index):\n",
    "    if not gp:\n",
    "        return [\"NA\"]\n",
    "    gp2 = [x for x in gp]\n",
    "    dosage = (gp2[1] + 2*gp2[index])\n",
    "    assert dosage >=0 and dosage <=2\n",
    "    return gp, gp2, dosage\n",
    "\n",
    "def get_GP(sample):\n",
    "    if sample['GT'] is None:\n",
    "        return None, None\n",
    "    return sample['GT'], sample['GP']\n",
    "\n",
    "def get_major_minor(snp, reader):\n",
    "    d = snp.name.split(\"_\")\n",
    "    loc = int(d[-1])\n",
    "    contig = \"_\".join(d[0:-1])\n",
    "    minor = gt_ref_alt[snp.name]['minor']\n",
    "    major = gt_ref_alt[snp.name]['major']\n",
    "    ref = gt_ref_alt[snp.name]['ref']\n",
    "    alt = gt_ref_alt[snp.name]['alt']\n",
    "    minor_index = 0 #assume minor is reference\n",
    "    if minor == alt:\n",
    "        minor_index = 2\n",
    "    dosages = []\n",
    "    samples = []\n",
    "    thesnp = list(reader.fetch(contig, loc-1, loc))[0]\n",
    "    for sample in thesnp.samples:\n",
    "        gt, gp = get_GP(sample)\n",
    "        dosages.append(get_dosage(gp, minor_index)[-1])\n",
    "        samples.append(sample.sample)\n",
    "    data = [minor, major]\n",
    "    index = [\"minor\", \"major\"]\n",
    "    index.extend(samples)\n",
    "    data.extend(dosages)\n",
    "    ret = pd.Series(data, index=index)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_ref_alt_minor_major = pd.DataFrame(gt_ref_alt)\n",
    "save_df(analysis_dir, 'gt_ref_alt_minor_major', gt_ref_alt_minor_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = open(os.path.join(analysis_dir, snp_file_gz), \"rb\")\n",
    "reader = vcf.VCFReader(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(x.CHROM,x.POS) for x in list(reader.fetch('ctg7180005039298', 121, 122))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt = gt_base_df_swapped.apply(get_major_minor, args=(reader,)).T\n",
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno = gemma_pheno.reindex(index=gt_base_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i gemma_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "massx = qqnorm(gemma_pheno$mass_resid, plot.it=F)$x\n",
    "tdtx = qqnorm(gemma_pheno$total_dev_time_resid, plot.it=F)$x\n",
    "pdx = qqnorm(gemma_pheno$pupual_duration_resid, plot.it=F)$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno['massx'] = r('massx')\n",
    "gemma_pheno['tdtx'] = r('tdtx')\n",
    "gemma_pheno['pdx'] = r('pdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"_gemma_gt\", gemma_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"_gemma_pheno\", gemma_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.massx.to_csv(os.path.join(analysis_dir, \"gemma_mass.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.tdtx.to_csv(os.path.join(analysis_dir, \"gemma_tdt.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.pdx.to_csv(os.path.join(analysis_dir, \"gemma_pd.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.to_csv(os.path.join(analysis_dir, \"gemma_pheno.txt\"),\n",
    "                                     index=True,\n",
    "                                     header=True)\n",
    "gemma_gt.to_csv(os.path.join(analysis_dir, \"gemma_gt.txt\"),\n",
    "                index=True,\n",
    "                header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_contigs = {}\n",
    "with open(os.path.join(analysis_dir, \"gemma_loc.txt\"), \"w\") as o:    \n",
    "    for x in gemma_gt.index:\n",
    "        data = x.split(\"_\")\n",
    "        contig = \"_\".join(data[0:-1])\n",
    "        pos = data[-1]\n",
    "        if not contig in gemma_contigs:\n",
    "            gemma_contigs[contig] = []\n",
    "        gemma_contigs[contig].append(pos)\n",
    "    \n",
    "    chrom_id = 1\n",
    "    for contig, positions in list(gemma_contigs.items()):\n",
    "        for p in positions:\n",
    "            o.write(\"%s_%s\\t%s\\t%d\\n\" % (contig, p, p, chrom_id))\n",
    "        chrom_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "gemma = \"/home/cfriedline/g/src/gemma-0.94.1/gemma\"\n",
    "\n",
    "def create_gemma_run_files(num_runs):\n",
    "    phenos = [\"mass\", 'tdt', 'pd']\n",
    "    for p in phenos:\n",
    "        with open(os.path.join(analysis_dir, \"gemma_%s_run.txt\" % p), \"w\") as o:\n",
    "            for i in range(num_runs):\n",
    "                cmd = \"%s \\\n",
    "-g gemma_gt.txt \\\n",
    "-p gemma_%s.txt -pos gemma_loc.txt \\\n",
    "-o gemma_%s_out_%d \\\n",
    "-w 1000000 \\\n",
    "-s 10000000 \\\n",
    "-num 500 \\\n",
    "-smin 1 \\\n",
    "-smax 100 \\\n",
    "-hmin 0.01 \\\n",
    "-hmax 0.9 \\\n",
    "-pmin 1 \\\n",
    "-pmax 1000 \\\n",
    "-r %.0f\" % (gemma, p, p, i, int(random.getrandbits(32)))\n",
    "                o.write(\"%s\\n\" % cmd) \n",
    "                \n",
    "\n",
    "\n",
    "def create_qsub_files():\n",
    "    files = !ls {analysis_dir}*run.txt\n",
    "    for f in files:\n",
    "        with open(\"%s_qsub.sh\" % f, \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N gemma_%s\n",
    "#$ -cwd\n",
    "unset module\n",
    "parallel -a %s\n",
    "\"\"\" % (os.path.basename(f).split(\"_\")[1], f))\n",
    "            \n",
    "create_pimass_run_files(10)\n",
    "create_qsub_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GEMMA commands for Gypsy Moth\n",
    "\n",
    "## Estimate Relatedness Matrix from Genotypes\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -gk [num] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_mass.txt \\\n",
    "-gk 1 -o mass\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_pd.txt \\\n",
    "-gk 1 -o pd\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_tdt.txt \\\n",
    "-gk 1 -o tdt\n",
    "```\n",
    "\n",
    "## Perform Eigen-Decomposition of the Relatedness Matrix\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -k [filename] -eigen -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_mass.txt \\\n",
    "-k output/mass.cXX.txt -eigen -o mass\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_pd.txt \\\n",
    "-k output/pd.cXX.txt -eigen -o pd\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_tdt.txt \\\n",
    "-k output/tdt.cXX.txt -eigen -o tdt\n",
    "```\n",
    "\n",
    "## Association Tests with Univariate Linear Mixed Models\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -lmm [num] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_mass.txt \\\n",
    "-a gemma_loc.txt -k output/mass.cXX.txt -lmm 4 -o mass_lmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_pd.txt \\\n",
    "-a gemma_loc.txt -k output/pd.cXX.txt -lmm 4 -o pd_lmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_tdt.txt \\\n",
    "-a gemma_loc.txt -k output/tdt.cXX.txt -lmm 4 -o tdt_lmm\n",
    "```\n",
    "\n",
    "## Association Tests with Multivariate Linear Mixed Models\n",
    "\n",
    "For this test, all three phenotype files were combined into a single file, with 3 columns in this order: mass, pd, tdt.\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -lmm [num] -n [num1] [num2] [num3] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_mass.txt \\\n",
    "-a gemma_loc.txt -k output/mass.cXX.txt -lmm 4 -n 1 2 3 -o mass_mlmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_pd.txt \\\n",
    "-a gemma_loc.txt -k output/pd.cXX.txt -lmm 4 -n 1 2 3 -o pd_mlmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_tdt.txt \\\n",
    "-a gemma_loc.txt -k output/tdt.cXX.txt -lmm 4 -n 1 2 3 -o tdt_mlmm\n",
    "```\n",
    "## Fit a Bayesian Sparse Linear Mixed Model\n",
    "\n",
    "First, set up a qsub script: `bslmm.sh` and `chmod +x` it\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#$ -N BSLMM\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "#$ -l mem_free=20G\n",
    "$HOME/g/src/gemma-0.94.1/gemma -g $1 -p $2 -a $3 -k $4 -bslmm $5 -o $6\n",
    "```\n",
    "\n",
    "Now, the scripts:\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -bslmm [num] -o [prefix]`\n",
    "\n",
    "### Standard BSLMM\n",
    "\n",
    "```bash \n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/mass.cXX.txt\" \"1\" \"mass_bslmm_std \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/pd.cXX.txt\" \"1\" \"pd_bslmm_std \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/tdt.cXX.txt\" \"1\" \"tdt_bslmm_std \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "```\n",
    "\n",
    "### Ridge regression/GBLUP\n",
    "\n",
    "```bash\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/mass.cXX.txt\" \"2\" \"mass_bslmm_ridge\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/pd.cXX.txt\" \"2\" \"pd_bslmm_ridge\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/tdt.cXX.txt\" \"2\" \"tdt_bslmm_ridge\"\n",
    "\n",
    "```\n",
    "\n",
    "### Probit BSLMM\n",
    "\n",
    "```bash\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/mass.cXX.txt\" \"3\" \"mass_bslmm_probit \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/pd.cXX.txt\" \"3\" \"pd_bslmm_probit \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/tdt.cXX.txt\" \"3\" \"tdt_bslmm_probit \\\n",
    "-w 1000000 -s 10000000 -smin 1 -smax 100 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0\"\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze and process GEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "assembly = \"/home/cfriedline/eckertlab/projects/gypsy_moth/assemblies/masurca3/CA/10-gapclose/genome.ctg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "filedir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/output_comeault_isect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "hide_input": false,
    "init_cell": true,
    "locked": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def dump_session():\n",
    "    dill.settings['recurse'] = True\n",
    "    dill.settings['fmode'] = dill.HANDLE_FMODE\n",
    "    dill.dump_session(filename=os.path.join(filedir, \"pimass.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_files = {}\n",
    "mcmc_files = {}\n",
    "gamma_files = {}\n",
    "snp_files = {}\n",
    "for root, dirs, files in scandir.walk(filedir):\n",
    "    for f in files:\n",
    "        d = f.split(\"_\")\n",
    "        pheno = d[1]\n",
    "        if not pheno in path_files:\n",
    "            path_files[pheno] = []\n",
    "            mcmc_files[pheno]= []\n",
    "            gamma_files[pheno] = []\n",
    "            snp_files[pheno] = []\n",
    "        if 'path' in f:\n",
    "            path_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'mcmc' in f:\n",
    "            mcmc_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'gamma' in f:\n",
    "            gamma_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'snp' in f:\n",
    "            snp_files[pheno].append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(coda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = r('mcmc')\n",
    "mcmc_list = r('mcmc.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "phenos = [\"mass\", \"pd\", \"tdt\"]\n",
    "for pheno in phenos:\n",
    "    frames = [pd.read_csv(x,sep=\"\\t\") for x in path_files[pheno]]\n",
    "    frames = [x.ix[:,:-1] for x in frames]\n",
    "    for df in frames:\n",
    "        df.columns = [x.strip() for x in df.columns]\n",
    "    dfs[pheno] = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs['mass'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_mcmc_r = {}\n",
    "path_mcmc = {}\n",
    "thin = 1\n",
    "for key, dflist in list(dfs.items()):\n",
    "    path_mcmc_r[key] = [mcmc(pandas2ri.DataFrame(x.sample(frac=thin).sort_index())) for x in dflist]\n",
    "    path_mcmc[key] = [x.sample(frac=thin).sort_index() for x in dflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_mcmc_list_mass = mcmc_list(path_mcmc_r['mass'])\n",
    "path_mcmc_list_pd = mcmc_list(path_mcmc_r['pd'])\n",
    "path_mcmc_list_tdt = mcmc_list(path_mcmc_r['tdt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%R -i path_mcmc_list_mass -i path_mcmc_list_pd -i path_mcmc_list_tdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "effective_sizes_mass = lapply(path_mcmc_list_mass,effectiveSize)\n",
    "effective_sizes_pd = lapply(path_mcmc_list_pd,effectiveSize)\n",
    "effective_sizes_tdt = lapply(path_mcmc_list_tdt,effectiveSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_effective_sizes(r_name):\n",
    "    df = pd.DataFrame([pandas2ri.ri2py(x) for x in r[r_name]])\n",
    "    test = r[r_name].rx2(1)\n",
    "    df.columns = r('names')(test)\n",
    "    return df\n",
    "ne_tdt = get_effective_sizes('effective_sizes_tdt')\n",
    "ne_pd= get_effective_sizes('effective_sizes_pd')\n",
    "ne_mass= get_effective_sizes('effective_sizes_mass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(ne_tdt.mean())\n",
    "print(ne_tdt.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_pd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_mass.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"MASS\", r(\"summary\")(path_mcmc_list_mass))\n",
    "print(\"PD\", r(\"summary\")(path_mcmc_list_pd))\n",
    "print(\"TDT\", r(\"summary\")(path_mcmc_list_tdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(path_mcmc_list_mass)\n",
    "plot(path_mcmc_list_pd)\n",
    "plot(path_mcmc_list_tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = {}\n",
    "for pheno, files in list(mcmc_files.items()):\n",
    "    if not pheno in mcmc:\n",
    "        mcmc[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        testdf = pd.read_csv(f, sep=\"\\t\")\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        mcmc[pheno] = pd.concat([mcmc[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc_mass = mcmc['mass']\n",
    "mcmc_pd = mcmc['pd']\n",
    "mcmc_tdt = mcmc['tdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hmean_row(row):\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan\n",
    "    \n",
    "def get_hmean(df, col_pattern):\n",
    "    cols = ['rs','chr']\n",
    "    cols.extend([\"%s_hmean\" % x for x in col_pattern])\n",
    "    d = pd.DataFrame(columns=cols, index=df.index)\n",
    "    d['rs'] = df.rs_1.values\n",
    "    d[\"chr\"] = df.chr_1.values\n",
    "    for cp in col_pattern:\n",
    "        d[\"%s_hmean\" % cp] = np.abs(df[[x for x in df if cp in x]]).apply(get_hmean_row, axis=1).values\n",
    "    return d\n",
    "mcmc_mass_hmean = get_hmean(mcmc_mass, [\"postrb\", \"betarb\"])\n",
    "mcmc_tdt_hmean = get_hmean(mcmc_tdt, [\"postrb\", \"betarb\"])\n",
    "mcmc_pd_hmean = get_hmean(mcmc_pd, [\"postrb\", \"betarb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'mcmc_mass_hmean', mcmc_mass_hmean)\n",
    "save_df(analysis_dir, 'mcmc_tdt_hmean', mcmc_tdt_hmean)\n",
    "save_df(analysis_dir, 'mcmc_pd_hmean', mcmc_pd_hmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcmc_hmean = {'mass': mcmc_mass_hmean,\n",
    "             'tdt': mcmc_tdt_hmean,\n",
    "             'pd': mcmc_pd_hmean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def percent_difference(x, y):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    return (np.abs(x-y)/np.mean([x, y]))*100\n",
    "\n",
    "def get_quant(name, data, q):\n",
    "    d = data.quantile(q)\n",
    "    d.index = [str(x) for x in d.index]\n",
    "    d['median_val'] = data.median()\n",
    "    d['mean_val'] = data.mean()\n",
    "    d['cutoff'] = 0.01\n",
    "    d[\"x99_cutoff\"] = percent_difference(d['0.99'], d['cutoff'])\n",
    "    d[\"x99_median\"] =  percent_difference(d['0.99'], d['median_val'])\n",
    "    d[\"x95_cutoff\"] = percent_difference(d['0.95'], d['cutoff'])\n",
    "    d[\"x95_median\"] =  percent_difference(d['0.95'], d['median_val'])\n",
    "    d['relaxed_cutoff'] = d['0.99']\n",
    "    d['min'] = data.min()\n",
    "    d['max'] = data.max()\n",
    "    d.name = name\n",
    "    return d\n",
    "\n",
    "mass_quant = get_quant(\"mass\", mcmc_mass_hmean.postrb_hmean, [0.1, 0.2, 0.6, 0.75, 0.90, 0.95,0.99])\n",
    "pd_quant = get_quant(\"pd\", mcmc_pd_hmean.postrb_hmean, [0.1, 0.2, 0.6, 0.75, 0.90, 0.95,0.99])\n",
    "tdt_quant =get_quant(\"tdt\", mcmc_tdt_hmean.postrb_hmean, [0.1, 0.2, 0.6, 0.75, 0.90, 0.95,0.99]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"%s\\n\\n%s\\n\\n%s\\n\" % (mass_quant, pd_quant, tdt_quant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "plt.hist(mcmc_mass_hmean.postrb_hmean, bins=100, alpha=0.3, label=\"mass\")\n",
    "plt.hist(mcmc_pd_hmean.postrb_hmean, bins=100, alpha=0.3, label=\"pd\")\n",
    "plt.hist(mcmc_tdt_hmean.postrb_hmean, bins=100, alpha=0.3, label=\"tdt\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'mass_quant', mass_quant)\n",
    "save_df(analysis_dir, 'pd_quant', pd_quant)\n",
    "save_df(analysis_dir, 'tdt_quant', tdt_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mass_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_quant_range(quant):\n",
    "    return pd.Series(np.linspace(quant['0.9'], quant['cutoff'], 10))\n",
    "\n",
    "mass_quant_range = get_quant_range(mass_quant)\n",
    "pd_quant_range = get_quant_range(pd_quant)\n",
    "tdt_quant_range = get_quant_range(tdt_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"mass_quant_range\", mass_quant_range)\n",
    "save_df(analysis_dir, \"pd_quant_range\", pd_quant_range)\n",
    "save_df(analysis_dir, \"tdt_quant_range\", tdt_quant_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_snps_mass = mcmc_mass_hmean[mcmc_mass_hmean.postrb_hmean > mass_quant.cutoff]\n",
    "sig_snps_tdt = mcmc_tdt_hmean[mcmc_tdt_hmean.postrb_hmean > tdt_quant.cutoff]\n",
    "sig_snps_pd = mcmc_pd_hmean[mcmc_pd_hmean.postrb_hmean > pd_quant.cutoff]\n",
    "\n",
    "relaxed_sig_snps_mass = mcmc_mass_hmean[mcmc_mass_hmean.postrb_hmean > mass_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_tdt = mcmc_tdt_hmean[mcmc_tdt_hmean.postrb_hmean > tdt_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_pd = mcmc_pd_hmean[mcmc_pd_hmean.postrb_hmean > pd_quant.relaxed_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_range_snps(ranges, hmean_df):\n",
    "    range_snps = []\n",
    "    for i, cutoff in enumerate(ranges):\n",
    "        range_snps.append(hmean_df[hmean_df.postrb_hmean > cutoff])\n",
    "    return range_snps\n",
    "\n",
    "range_snps_mass = get_range_snps(mass_quant_range, mcmc_mass_hmean)\n",
    "range_snps_pd = get_range_snps(pd_quant_range, mcmc_pd_hmean)\n",
    "range_snps_tdt = get_range_snps(tdt_quant_range, mcmc_tdt_hmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps_mass.shape, sig_snps_tdt.shape, sig_snps_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_mass.shape, relaxed_sig_snps_tdt.shape, relaxed_sig_snps_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_tdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relaxed_sig_snps_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pips = {}\n",
    "def get_contig_pip(row, pheno):\n",
    "    if not pheno in contig_pips:\n",
    "        contig_pips[pheno] = {}\n",
    "        \n",
    "    d = row.rs.split(\"_\")\n",
    "    contig = \"_\".join(d[:-1])\n",
    "    if not contig in contig_pips[pheno]:\n",
    "        contig_pips[pheno][contig] = {'betarb':0,'postrb':0}\n",
    "    contig_pips[pheno][contig]['postrb'] += row.postrb_hmean\n",
    "    contig_pips[pheno][contig]['betarb'] += row.betarb_hmean\n",
    "\n",
    "for pheno, df in list(mcmc_hmean.items()):\n",
    "    print(pheno)\n",
    "    df.apply(get_contig_pip, args=(pheno,), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_dfs = {}\n",
    "for pheno, data in list(contig_pips.items()):\n",
    "    contig_pip_dfs[pheno] = pd.DataFrame(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "contig_lengths = {}\n",
    "for rec in SeqIO.parse(assembly,\"fasta\"):\n",
    "    contig_lengths[rec.name] = {\"length\":len(rec)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df = pd.DataFrame(contig_lengths).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_mass = contig_pip_dfs['mass'].join(contig_length_df)\n",
    "contig_pip_tdt = contig_pip_dfs['tdt'].join(contig_length_df)\n",
    "contig_pip_pd = contig_pip_dfs['pd'].join(contig_length_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'contig_pip_mass', contig_pip_mass)\n",
    "save_df(analysis_dir, 'contig_pip_tdt', contig_pip_tdt)\n",
    "save_df(analysis_dir, 'contig_pip_pd', contig_pip_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contig_pip_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_contig_length_vs_pip(df, title):\n",
    "    plt.scatter(df.length, df.postrb)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"length of contig\")\n",
    "    plt.ylabel(\"postrb\")\n",
    "    plt.show()\n",
    "for key, df in list({'mass':contig_pip_mass, \n",
    "                'tdt': contig_pip_tdt, \n",
    "                'pd': contig_pip_pd}.items()):\n",
    "    plot_contig_length_vs_pip(df[df.postrb < 0.10], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_fig(key, ext):\n",
    "    plt.savefig(os.path.join(analysis_dir, \"%s.%s\" % (key, ext)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(contig_pip_dfs['tdt'].postrb.values, label=\"PIP\")\n",
    "plt.title(\"TDT contigs\")\n",
    "plt.legend()\n",
    "save_fig(\"TDT\", \"pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(contig_pip_dfs['mass'].postrb.values, label=\"PIP\")\n",
    "plt.title(\"Mass contigs\")\n",
    "plt.legend()\n",
    "save_fig(\"Mass\", \"pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(contig_pip_dfs['pd'].postrb.values, label=\"PIP\")\n",
    "plt.title(\"PD contigs\")\n",
    "plt.legend()\n",
    "save_fig(\"PD\", \"pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_mass))\n",
    "plt.plot(mcmc_mass_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_mass_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"Mass\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "save_fig(\"mass_pip_beta\", \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_pd))\n",
    "plt.plot(mcmc_pd_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_pd_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"PD\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "save_fig(\"pd_snp_beta\", \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_tdt))\n",
    "plt.plot(mcmc_tdt_hmean.postrb_hmean, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(mcmc_tdt_hmean.betarb_hmean, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"TDT\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "save_fig(\"tdt_pip_beta\", \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps = {}\n",
    "for pheno, files in list(snp_files.items()):\n",
    "    if not pheno in snps:\n",
    "        snps[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        h = open(f)\n",
    "        h.readline() ##skip header\n",
    "        header = h.readline().strip().split()\n",
    "        data = []\n",
    "        for line in h:\n",
    "            line = line.strip().split()\n",
    "            data.append(line)\n",
    "            \n",
    "        testdf = pd.DataFrame(data, columns=header)\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        snps[pheno] = pd.concat([snps[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass = snps['mass'][[x for x in snps['mass'] if '_1' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def read_gamma(f):\n",
    "    d = []\n",
    "    h = open(f)\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        line = line.strip().split()\n",
    "        d.append(line)\n",
    "    df = pd.DataFrame(d, columns=header)\n",
    "    return df.replace('NA', np.nan).astype(float)\n",
    "gamma_mass = read_gamma(gamma_files['mass'][0])\n",
    "gamma_pd = read_gamma(gamma_files['pd'][0])\n",
    "gamma_tdt = read_gamma(gamma_files['tdt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'gamma_mass', gamma_mass)\n",
    "save_df(analysis_dir, 'gamma_pd', gamma_pd)\n",
    "save_df(analysis_dir, 'gamma_tdt', gamma_tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"sig_snps_mass\", sig_snps_mass)\n",
    "save_df(analysis_dir, \"sig_snps_tdt\", sig_snps_tdt)\n",
    "save_df(analysis_dir, \"sig_snps_pd\", sig_snps_pd)\n",
    "save_df(analysis_dir, \"relaxed_sig_snps_mass\", relaxed_sig_snps_mass)\n",
    "save_df(analysis_dir, \"relaxed_sig_snps_tdt\", relaxed_sig_snps_tdt)\n",
    "save_df(analysis_dir, \"relaxed_sig_snps_pd\", relaxed_sig_snps_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_range_snps_to_hdf(snps, ranges, pheno):\n",
    "    for i, val in enumerate(ranges):\n",
    "        save_df(analysis_dir, 'range_snps_%s_%d' % (pheno, i), snps[i])\n",
    "add_range_snps_to_hdf(range_snps_mass, mass_quant_range, \"mass\")\n",
    "add_range_snps_to_hdf(range_snps_pd, pd_quant_range, \"pd\")\n",
    "add_range_snps_to_hdf(range_snps_tdt, tdt_quant_range, \"tdt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in range_snps_mass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_mass.betarb_hmean.values))\n",
    "plt.text(0.02, 1.5, r\"$n = %d$\" % len(sig_snps_mass))\n",
    "plt.title(r\"Mass ($> %.2f$)\" % mass_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"mass_beta_sig\", \"pdf\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_mass.betarb_hmean.values))\n",
    "plt.text(0.02, 700, r\"$n = %d$\" % len(relaxed_sig_snps_mass))\n",
    "plt.title(r\"Mass 99th($> %.5f$)\" % mass_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"mass_beta_relaxed\", \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_tdt.betarb_hmean.values))\n",
    "plt.text(0.1, 10, r\"$n = %d$\" % len(sig_snps_tdt))\n",
    "plt.title(r\"TDT ($> %.2f$)\" % tdt_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"tdt_beta_sig\", \"svg\")\n",
    "\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_tdt.betarb_hmean.values))\n",
    "plt.text(0.1, 700, r\"$n = %d$\" % len(relaxed_sig_snps_tdt))\n",
    "plt.title(r\"TDT 99th ($> %.5f$)\" % tdt_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"tdt_beta_relaxed\", \"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_pd.betarb_hmean.values))\n",
    "plt.text(0.005, 1.5, r\"$n = %d$\" % len(sig_snps_pd))\n",
    "plt.title(r\"PD ($> %.2f$)\" % pd_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"pd_beta_sig\", \"pdf\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_pd.betarb_hmean.values))\n",
    "plt.text(0.005, 600, r\"$n = %d$\" % len(relaxed_sig_snps_pd))\n",
    "plt.title(r\"PD 99th ($> %.5f$)\" % pd_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "save_fig(\"pd_beta_relaxed\", \"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "notify_time": "0"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
