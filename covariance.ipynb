{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os, sys\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import vcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "import shutil\n",
    "from utils import read_df, save_df\n",
    "from pathlib import Path, PurePath\n",
    "from ipyparallel import Client\n",
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "from scipy.stats import mannwhitneyu, ks_2samp, f_oneway\n",
    "import tables\n",
    "import ujson\n",
    "import pickle\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print = display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_dir = os.path.join(analysis_dir, \"gemma_run\")\n",
    "gemma_dir = os.path.join(gemma_dir, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ni_data = read_df(\"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni\", \"z12_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_missing(snp):\n",
    "    c = snp.value_counts()\n",
    "    if not -1 in c:\n",
    "        return 0\n",
    "    return c[-1]/np.sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing = ni_data.apply(percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenos = [\"mass\", \"tdt\", \"pd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_dfs = pickle.load(open(os.path.join(gemma_dir, \"combined_dfs.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps = pickle.load(open(os.path.join(gemma_dir, \"effect_snps.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df = read_df(analysis_dir, 'gt_base_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = sorted(set([x.split(\"_\")[0] for x in gt_base_df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_genotypes(snp):\n",
    "    counts = Counter()\n",
    "    for gt in snp:\n",
    "        try:\n",
    "            float(gt) #if gt is nan\n",
    "        except:\n",
    "            counts[gt[0]]+=1\n",
    "            counts[gt[-1]]+=1\n",
    "    return sorted(counts.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df['population'] = gt_base_df.apply(lambda x: x.name.split(\"_\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_data = {}\n",
    "\n",
    "def add_allele_freq(gt_list):\n",
    "    data = gt_list\n",
    "    ret = OrderedDict()\n",
    "    if len(gt_list) == 2:\n",
    "        total = data[0][1]+data[1][1]\n",
    "        ret[data[0][0]] = [data[0][1], data[0][1]/total]\n",
    "        ret[data[1][0]] = [data[1][1], data[1][1]/total]\n",
    "    else:\n",
    "        ret[data[0][0]] = [data[0][1], 1.0]\n",
    "    return ret\n",
    "\n",
    "for group, data in gt_base_df.groupby('population'):\n",
    "    data = data.drop('population', axis=1)\n",
    "    print(group, data.shape)\n",
    "    gt = data.apply(count_genotypes).apply(add_allele_freq)\n",
    "    pop_allele_data[group] = gt.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt = read_df(analysis_dir, '_gemma_gt').replace(\"NA\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pop_allele_data['VA1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs = read_df(analysis_dir, \"allele_freqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_counts = gt_base_df.apply(count_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af = gt_counts.apply(add_allele_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['gemma_gt'] = gemma_gt\n",
    "\n",
    "dview['pops'] = pops\n",
    "\n",
    "dview['analysis_dir'] = analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "import os, pickle, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"pop_allele_data_gemma.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(pop_allele_data, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "if not 'pop_allele_data' in dir():\n",
    "    pop_allele_data = pickle.load(open(os.path.join(analysis_dir, \"pop_allele_data_gemma.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_obs_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    for gt in snp:\n",
    "        if gt[0] != gt[-1]:\n",
    "            het += 1\n",
    "        if gt[1] == \"/\" or gt[1] == \"|\":\n",
    "            total += 1\n",
    "    return het/total\n",
    "\n",
    "def compute_exp_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    c = Counter()\n",
    "    for gt in snp:\n",
    "        c[gt[0]] += 1\n",
    "        c[gt[-1]] += 1\n",
    "    total = np.sum(list(c.values()))\n",
    "    He = 2\n",
    "    for a in c:\n",
    "        He *= (c[a]/total)\n",
    "    return He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "het_bins = np.linspace(0,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "He = gt_base_df.drop(\"population\", axis=1).apply(compute_exp_heterozygosity)\n",
    "He = pd.DataFrame(He, columns=[\"He\"])\n",
    "He['rs'] = He.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ho = gt_base_df.drop(\"population\", axis=1).apply(compute_obs_heterozygosity)\n",
    "Ho = pd.DataFrame(Ho, columns=[\"Ho\"])\n",
    "Ho['rs'] = Ho.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "He.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho = combined_dfs['tdt'].join(Ho, how=\"inner\")\n",
    "mass_ho = combined_dfs['mass'].join(Ho, how=\"inner\")\n",
    "pd_ho = combined_dfs['pd'].join(Ho, how=\"inner\")\n",
    "\n",
    "tdt_he = combined_dfs['tdt'].join(He, how=\"inner\")\n",
    "mass_he = combined_dfs['mass'].join(He, how=\"inner\")\n",
    "pd_he = combined_dfs['pd'].join(He, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho['het_bin'] = np.digitize(tdt_ho.Ho, het_bins)\n",
    "mass_ho['het_bin'] = np.digitize(mass_ho.Ho, het_bins)\n",
    "pd_ho['het_bin'] = np.digitize(pd_ho.Ho, het_bins)\n",
    "\n",
    "tdt_he['het_bin'] = np.digitize(tdt_he.He, het_bins)\n",
    "mass_he['het_bin'] = np.digitize(mass_he.He, het_bins)\n",
    "pd_he['het_bin'] = np.digitize(pd_he.He, het_bins)\n",
    "\n",
    "He[\"het_bin\"] = np.digitize(He.He, het_bins)\n",
    "Ho[\"het_bin\"] = np.digitize(Ho.Ho, het_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in (tdt_he, mass_he, pd_he, He)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PhenoContainer = namedtuple(\"PhenoContainer\", [\"He\", \"Ho\", \"hmean\", \"sig\", \"relaxed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PC = {\"mass\": PhenoContainer(mass_he, mass_ho, combined_dfs['mass'], \n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"pd\":PhenoContainer(pd_he, pd_ho, combined_dfs['pd'],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"tdt\":PhenoContainer(tdt_he, tdt_ho, combined_dfs['tdt'],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.995)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].He.gamma_hmean, PC[pheno].He.He)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{exp}$\")\n",
    "    plt.title(\"TDT\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].Ho.gamma_hmean, PC[pheno].Ho.Ho)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{obs}$\")\n",
    "    plt.title(pheno.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_snp = 'ctg7180005039298_50'\n",
    "test_minor = gemma_gt.ix[test_snp, \"minor\"]\n",
    "print(test_minor)\n",
    "for p in pop_allele_data:\n",
    "    if test_minor in pop_allele_data[p][test_snp]:\n",
    "        print(pop_allele_data[p][test_snp][test_minor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts = Counter()\n",
    "for col in gemma_gt.columns[2:]:\n",
    "    pop_counts[col.split(\"_\")[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts_alleles = Counter()\n",
    "for p in pop_allele_data:\n",
    "    for snp in pop_allele_data[p]:\n",
    "        for allele in pop_allele_data[p][snp]:\n",
    "            pop_counts_alleles[p] += pop_allele_data[p][snp][allele][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ind = np.sum(list(pop_counts.values()))\n",
    "total_alleles = np.sum(list(pop_counts_alleles.values()))\n",
    "for p in pop_counts:\n",
    "    print(p, pop_counts[p]/total_ind, pop_counts_alleles[p]/total_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs = allele_freqs.apply(lambda x: np.min((x.p, x.q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['pop_counts_alleles'] = pop_counts_alleles\n",
    "dview['pop_counts'] = pop_counts\n",
    "dview['allele_freqs'] = allele_freqs\n",
    "dview['mafs'] = mafs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Storz and Kelley (2008), Eqn 2\n",
    "\n",
    "# $D_{ij} = \\bigg(\\sum_{k}\\frac{n_k}{n}D_{ij,k}\\bigg) + \\bigg(\\sum_{k}\\frac{n_k}{n}(q_{i,k}q_{j,k} - q_iq_j)\\bigg)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@lview.remote()\n",
    "def do_pairwise_storz(sig_list):\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "    ret = {}\n",
    "    n = np.sum(list(pop_counts_alleles.values()))\n",
    "    for i, snp in enumerate(sig_list):\n",
    "        snp_i = snp\n",
    "        minor_allele_i = gemma_gt.ix[snp_i, \"minor\"]\n",
    "        qi = mafs[snp_i]\n",
    "        for j in range(i):\n",
    "            snp_j = sig_list[j]\n",
    "            minor_allele_j = gemma_gt.ix[snp_j, \"minor\"]\n",
    "            qj = mafs[snp_j]\n",
    "            \n",
    "            k_sum = 0\n",
    "            for p in pops:\n",
    "                nk = pop_counts_alleles[p]\n",
    "                \n",
    "                qik = qjk = 0.0\n",
    "                \n",
    "                if minor_allele_i in pop_allele_data[p][snp_i]:\n",
    "                    qik = pop_allele_data[p][snp_i][minor_allele_i][1]\n",
    "                    \n",
    "                if minor_allele_j in pop_allele_data[p][snp_j]:\n",
    "                    qjk = pop_allele_data[p][snp_j][minor_allele_j][1]\n",
    "                \n",
    "                k_sum += ((nk/n) * ((qik*qjk)-(qi*qj)))\n",
    "                \n",
    "            ret[snp_i, snp_j] = k_sum  \n",
    "    return ret\n",
    "\n",
    "\n",
    "@lview.remote()\n",
    "def do_pairwise_eckert(sig_list):\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "    ret = {}\n",
    "    for i, snp in enumerate(sig_list):\n",
    "        snp_i = snp\n",
    "        minor_allele_i = gemma_gt.ix[snp_i, \"minor\"]\n",
    "        for j in range(i):\n",
    "            snp_j = sig_list[j]\n",
    "            minor_allele_j = gemma_gt.ix[snp_j, \"minor\"]\n",
    "            in_prods = []\n",
    "            freqs = {snp_i: [], snp_j: []}\n",
    "            for p in pops:\n",
    "                paf_i = paf_j = 0.0\n",
    "                \n",
    "                if minor_allele_i in pop_allele_data[p][snp_i]:\n",
    "                    paf_i = pop_allele_data[p][snp_i][minor_allele_i][1]\n",
    "                    \n",
    "                if minor_allele_j in pop_allele_data[p][snp_j]:\n",
    "                    paf_j = pop_allele_data[p][snp_j][minor_allele_j][1]\n",
    "                \n",
    "                freqs[snp_i].append(paf_i)\n",
    "                freqs[snp_j].append(paf_j)\n",
    "                in_prods.append(paf_i * paf_j)\n",
    "            avg_in_prod = np.mean(in_prods)\n",
    "            freqs_avg = {k: np.mean(freqs[k]) for k in freqs}\n",
    "            across_freqs = list(freqs_avg.values())\n",
    "            across_prod = across_freqs[0] * across_freqs[1]\n",
    "            ret[snp_i, snp_j] = (avg_in_prod-across_prod)\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    sig = list(PC[pheno].sig)\n",
    "    storz = do_pairwise_storz(sig).r\n",
    "    eckert = do_pairwise_eckert(sig).r\n",
    "\n",
    "    storz_vals = []\n",
    "    eckert_vals = []\n",
    "    for pair in storz:\n",
    "        storz_vals.append(storz[pair])\n",
    "        eckert_vals.append(eckert[pair])\n",
    "        \n",
    "    sns.distplot(storz_vals, label=\"storz\")\n",
    "    sns.distplot(eckert_vals, label=\"eckert\")\n",
    "    plt.xlabel(\"pairwise D\")\n",
    "    plt.title(pheno)\n",
    "    plt.legend()\n",
    "    f, p = f_oneway(storz_vals, eckert_vals)\n",
    "    plt.text(0.02, 61, r\"$F = %.3f, p = %.3f$\" % (f, p))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nulls_by_het(args):\n",
    "    import pandas as pd\n",
    "    n, sig_df, df = args\n",
    "    sig = None\n",
    "    if isinstance(sig_df, pd.DataFrame):\n",
    "        sig = sig_df.index\n",
    "    elif isinstance(sig_df, set):\n",
    "        sig = sig_df\n",
    "    \n",
    "    assert sig is not None\n",
    "    \n",
    "    unassoc = df.drop(sig)\n",
    "    het_bin_counts = df.ix[sig]['het_bin'].value_counts()\n",
    "    het_bins = het_bin_counts.index.tolist()\n",
    "    unassoc = unassoc[unassoc.het_bin.isin(het_bins)]\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        inner = []\n",
    "        for het_bin, het_count in het_bin_counts.iteritems():\n",
    "            inner.extend(unassoc[unassoc.het_bin == het_bin].rs.sample(het_count).tolist())\n",
    "        data.append(inner)\n",
    "    return data, het_bins\n",
    "\n",
    "def get_nulls_naive(n, sig_df, df):\n",
    "    unassoc = df.drop(sig_df.index)\n",
    "    return [unassoc.rs.sample(len(sig_df)).tolist() for x in range(n)], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_nulls = get_nulls_by_het\n",
    "dview['get_nulls_naive'] = get_nulls_naive\n",
    "dview['get_nulls'] = get_nulls\n",
    "dview['get_nulls_by_het'] = get_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_pairwise(n):\n",
    "    return ((n*n)/2)-(n/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"env_outliers.pkl\"), \"rb\") as r:\n",
    "    bayenv_outliers = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bayenv_outliers = set()\n",
    "for bio in bayenv_outliers:\n",
    "    for snp in bayenv_outliers[bio].index:\n",
    "        all_bayenv_outliers.add(snp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_bayenv_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gwas_D = {}\n",
    "for pheno in PC:\n",
    "    sig = list(PC[pheno].sig)\n",
    "    res = do_pairwise_storz(sig).r\n",
    "    gwas_D[pheno] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_D = {}\n",
    "for bio in bayenv_outliers:\n",
    "    sig = list(bayenv_outliers[bio].index)\n",
    "    res = do_pairwise_storz(sig).r\n",
    "    bayenv_D[bio] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bayenv_D = do_pairwise_storz(list(all_bayenv_outliers)).r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulls = {}\n",
    "sig_het_bins = {}\n",
    "for pheno in PC:\n",
    "    sig = PC[pheno].hmean.ix[PC[pheno].sig]\n",
    "    nulls[pheno], sig_het_bins[pheno] = get_nulls_by_het((1000, sig, PC[pheno].He))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_null_jobs = {}\n",
    "for bio in bayenv_outliers:\n",
    "    print(bio)\n",
    "    sig = bayenv_outliers[bio]\n",
    "    bayenv_null_jobs[bio] = lview.apply_async(get_nulls_by_het, (1000, sig, He))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_nulls = {}\n",
    "bayenv_sig_het_bins = {}\n",
    "for bio in bayenv_outliers:\n",
    "    bayenv_nulls[bio], bayenv_sig_het_bins[bio] = bayenv_null_jobs[bio].r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bayenv_nulls, all_bayenv_sig_het_bins = get_nulls_by_het((1000, all_bayenv_outliers, He))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nulls_D = {}\n",
    "for pheno in PC:\n",
    "    nulls_D[pheno] = []\n",
    "    for i, null_list in enumerate(nulls[pheno]):\n",
    "        nulls_D[pheno].append(do_pairwise_storz(null_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_nulls_D = {}\n",
    "for bio in bayenv_outliers:\n",
    "    bayenv_nulls_D[bio] = []\n",
    "    for i, null_list in enumerate(bayenv_nulls[bio]):\n",
    "        bayenv_nulls_D[bio].append(do_pairwise_storz(null_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bayenv_nulls_D = [] \n",
    "for null_list in all_bayenv_nulls:\n",
    "    all_bayenv_nulls_D.append(do_pairwise_storz(null_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    nulls_D[pheno] = [np.abs(list(x.r.values())) for x in nulls_D[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bio in bayenv_outliers:\n",
    "    print(bio)\n",
    "    bayenv_nulls_D[bio] = [np.abs(list(x.r.values())) for x in bayenv_nulls_D[bio]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_bayenv_nulls_D)):\n",
    "#     all_bayenv_nulls_D[i] = np.abs(list(all_bayenv_nulls_D[i].r.values()))\n",
    "    all_bayenv_nulls_D[i] = np.abs(all_bayenv_nulls_D[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    d = np.abs(list(gwas_D[pheno].values()))\n",
    "    sns.distplot(d, label=\"sig\")\n",
    "    plt.xlabel(\"Pairwise D\")\n",
    "    plt.title(\"%s (n=%d, pairwise=%d)\" % (pheno.upper(), len(list(PC[pheno].sig)), len(d)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for bio in sorted(bayenv_outliers):\n",
    "    d = np.abs(list(bayenv_D[bio].values()))\n",
    "    sns.distplot(d, label=\"sig\")\n",
    "    plt.xlabel(\"Pairwise D\")\n",
    "    plt.title(\"%s (n=%d, pairwise=%d)\" % (bio.upper(), len(bayenv_outliers[bio]), len(d)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.abs(list(all_bayenv_D.values()))\n",
    "sns.distplot(d, label=\"sig\")\n",
    "plt.xlabel(\"Pairwise D\")\n",
    "plt.title(\"%s (n=%d, pairwise=%d)\" % (\"BIO\", len(all_bayenv_outliers), len(d)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_medians = {}\n",
    "null_tail = {}\n",
    "for pheno in PC:\n",
    "    null_medians[pheno] = []\n",
    "    null_tail[pheno] = []\n",
    "    for l in nulls_D[pheno]:\n",
    "        null_medians[pheno].append(np.median(l))\n",
    "        null_tail[pheno].append(pd.Series(l).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_null_medians = {}\n",
    "bayenv_null_tail = {}\n",
    "for bio in bayenv_outliers:\n",
    "    bayenv_null_medians[bio] = []\n",
    "    bayenv_null_tail[bio] = []\n",
    "    for l in bayenv_nulls_D[bio]:\n",
    "        bayenv_null_medians[bio].append(np.median(l))\n",
    "        bayenv_null_tail[bio].append(pd.Series(l).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bayenv_null_medians = []\n",
    "all_bayenv_null_tail = []\n",
    "for l in all_bayenv_nulls_D:\n",
    "    all_bayenv_null_medians.append(np.median(l))\n",
    "    all_bayenv_null_tail.append(pd.Series(l).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    d = nulls_D[pheno][0]\n",
    "    sns.distplot(d)\n",
    "    plt.title(\"nulls %s \" % pheno)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "for bio in sorted(bayenv_outliers):\n",
    "    d = bayenv_nulls_D[bio][0]\n",
    "    sns.distplot(d)\n",
    "    plt.title(\"nulls %s \" % bio)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = all_bayenv_nulls_D[0]\n",
    "sns.distplot(d)\n",
    "plt.title(\"nulls %s \" % \"ALL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"white\")\n",
    "for pheno in PC:\n",
    "    n = pd.Series(null_medians[pheno])\n",
    "    d = np.abs(pd.Series(gwas_D[pheno]))\n",
    "    sns.distplot(n, label=\"null\")\n",
    "    sns.distplot(d, label=\"observed\")\n",
    "    plt.title(\"%s (n = %d)\" % (pheno.upper(), len(PC[pheno].sig)))\n",
    "    plt.axvline(x=n.quantile(0.95), c=\"red\", zorder=0, label=\"null 95th\")\n",
    "    plt.axvline(x=np.median(d), c=\"blue\", zorder=0, label=\"obs. median\")\n",
    "    plt.xlabel(\"D\")\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    f = plt.gcf()\n",
    "    f.set_size_inches(10,8)\n",
    "    plt.savefig(\"{}_gemma_cov.pdf\".format(pheno))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "for bio in sorted(bayenv_outliers):\n",
    "    n = pd.Series(bayenv_null_medians[bio])\n",
    "    d = np.abs(pd.Series(bayenv_D[bio]))\n",
    "    sns.distplot(n, label=\"null\")\n",
    "    sns.distplot(d, label=\"observed\")\n",
    "    plt.title(\"%s (n = %d)\" % (bio, len(bayenv_outliers[bio])))\n",
    "    plt.axvline(x=n.quantile(0.95), c=\"red\", zorder=0, label=\"null 95th\")\n",
    "    plt.axvline(x=np.median(d), c=\"blue\", zorder=0, label=\"obs. median\")\n",
    "    plt.xlabel(\"D\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hm = {}\n",
    "for bio1 in bayenv_outliers:\n",
    "    if not bio1 in hm:\n",
    "        hm[bio1] = {}\n",
    "    i = bayenv_outliers[bio1].index\n",
    "    for bio2 in bayenv_outliers:\n",
    "        j = bayenv_outliers[bio2].index\n",
    "        maxval = np.min((len(i), len(j)))\n",
    "        hm[bio1][bio2] = len(i.intersection(j))/maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(hm));\n",
    "plt.title(\"Overlapping SNPs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?sns.distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = pd.Series(all_bayenv_null_medians)\n",
    "d = np.abs(pd.Series(all_bayenv_D))\n",
    "sns.distplot(n, label=\"null\")\n",
    "sns.distplot(d, label=\"observed\")\n",
    "plt.title(\"%s (n = %d)\" % (\"All Bayenv outliers\", len(all_bayenv_outliers)))\n",
    "plt.axvline(x=n.quantile(0.95), c=\"red\", zorder=0, label=\"null 95th\")\n",
    "plt.axvline(x=np.median(d), c=\"blue\", zorder=0, label=\"obs. median\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.legend()\n",
    "f = plt.gcf()\n",
    "f.set_size_inches(10, 8)\n",
    "f.get_axes()[0].set_yscale(\"log\")\n",
    "sns.despine()\n",
    "plt.xlim(0, np.max(d))\n",
    "plt.savefig(\"bayenv_outliers.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf = pd.read_csv(os.path.join(analysis_dir, \"isect_hierfstat.txt\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_results = pd.read_csv(os.path.join(bayenv_dir, \"bayenv_results.txt\"), sep='\\t', index_col=0)\n",
    "bf_cols =  [x for x in bayenv_results if '_bf' in x]\n",
    "bayenv_results['max_bf'] = bayenv_results[bf_cols].apply(lambda x: np.max(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_results_above_cutoff = bayenv_results[bayenv_results.max_bf >= 3.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bayenv_outliers_above_cutoff = set(bayenv_results_above_cutoff.index).intersection(all_bayenv_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['popid']\n",
    "cols.extend(list(all_bayenv_outliers_above_cutoff))\n",
    "bayenv_hierf = hierf[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i bayenv_hierf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(hierfstat)\n",
    "data = bayenv_hierf\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res_bayenv = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "boot_bayenv = boot.vc(levels=levels, loci=loci, diploid=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "boxplot(boot_bayenv$res[\"F-data.popid/Total\"][,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    sig = list(PC[pheno].sig)\n",
    "    cols = ['popid']\n",
    "    cols.extend(list(sig))\n",
    "    temp_hierf = hierf[cols]\n",
    "    ro.globalenv[\"%s_hierf\" % pheno] = temp_hierf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "data = mass_hierf\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res_mass = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "boot_mass = boot.vc(levels=levels, loci=loci, diploid=T)\n",
    "print(\"mass\")\n",
    "print(res$F)\n",
    "\n",
    "data = pd_hierf\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res_pd = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "boot_pd = boot.vc(levels=levels, loci=loci, diploid=T)\n",
    "print(\"pd\")\n",
    "print(res$F)\n",
    "\n",
    "data = tdt_hierf\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res_tdt = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "boot_tdt = boot.vc(levels=levels, loci=loci, diploid=T)\n",
    "print(\"tdt\")\n",
    "print(res$F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boot_mass = ro.r(\"boot_mass$res['F-data.popid/Total']\")\n",
    "boot_pd = ro.r(\"boot_pd$res['F-data.popid/Total']\")\n",
    "boot_tdt = ro.r(\"boot_tdt$res['F-data.popid/Total']\")\n",
    "boot_bayenv = ro.r(\"boot_bayenv$res['F-data.popid/Total']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boots = pd.concat((boot_mass, boot_pd, boot_tdt, boot_bayenv), axis=1)\n",
    "boots.columns = [\"mass\", \"pd\", \"tdt\", \"env\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "sns.boxplot(data=boots)\n",
    "plt.title(\"Multilocus %s (bootstrap n=1000)\" % r\"$F_{ST}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "?linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for pheno in combined_dfs:\n",
    "    print(pheno)\n",
    "    d = pd.DataFrame(ro.r('res_%s$loc' % pheno))\n",
    "    d.index = ro.r('rownames(res_%s$loc)' % pheno)\n",
    "    d['Fst'] = d.apply(compute_fst, axis=1)\n",
    "    d = d.join(combined_dfs[pheno])\n",
    "    x = 'Fst'\n",
    "    y = 'total_effect'\n",
    "    ax = sns.regplot(x, y, d, fit_reg=False)\n",
    "    plt.xlim(np.min(d[x]), np.max(d[x]))\n",
    "    plt.ylim(np.min(d[y]), np.max(d[y]))\n",
    "    plt.title(pheno)\n",
    "    m, b, r, p, e = sp.stats.linregress(d[x], d[y])\n",
    "    print(\"y = %.3fx + %.3f (r=%.3f, p=%.3f)\" %  (m, b, r, p))\n",
    "    plt.plot(d[x], m*d[x] + b, '-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_results = pd.read_csv(os.path.join(bayenv_dir, \"bayenv_results.txt\"), sep='\\t', index_col=0)\n",
    "\n",
    "bf_cols =  [x for x in bayenv_results if '_bf' in x]\n",
    "bayenvmer_results['max_bf'] = bayenv_results[bf_cols].apply(lambda x: np.max(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for bio in bayenv_outliers:\n",
    "    print(bio)\n",
    "    bayenv_col = \"%s_bf\" % bio\n",
    "    bayenv = bayenv_results.ix[bayenv_outliers[bio], bayenv_col]\n",
    "    d = pd.DataFrame(ro.r('res_bayenv$loc'))\n",
    "    d.index = ro.r('rownames(res_bayenv$loc)')\n",
    "    d['Fst'] = d.apply(compute_fst, axis=1)\n",
    "    d = d.join(bayenv).dropna()\n",
    "    d = d[d[bayenv_col]]\n",
    "    x = 'Fst'\n",
    "    y = bayenv_col\n",
    "    ax = sns.regplot(x, y, d, fit_reg=False)\n",
    "    plt.xlim(np.min(d[x]), np.max(d[x]))\n",
    "    plt.ylim(np.min(d[y]), np.max(d[y]))\n",
    "    plt.title(bio)\n",
    "    m, b, r, p, e = sp.stats.linregress(d[x], d[y])\n",
    "    print(\"y = %.3fx + %.3f (r=%.3f, p=%.3f)\" %  (m, b, r, p))\n",
    "    plt.plot(d[x], m*d[x] + b, '-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res_all = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/isect_hierfstat_varcomp.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bio in bayenv_outliers:\n",
    "    print(bio)\n",
    "    bayenv_col = \"%s_bf\" % bio\n",
    "    bayenv = bayenv_results.ix[:, bayenv_col]\n",
    "    d = pd.DataFrame(ro.r('res_all$loc'))\n",
    "    d.index = ro.r('rownames(res_all$loc)')\n",
    "    d['Fst'] = d.apply(compute_fst, axis=1)\n",
    "    d = d.join(bayenv).dropna()\n",
    "    d[bayenv_col] = np.log10(d[bayenv_col])\n",
    "    x = 'Fst'\n",
    "    y = bayenv_col\n",
    "    ax = sns.regplot(x, y, d, fit_reg=False)\n",
    "    plt.xlim(np.min(d[x]), np.max(d[x]))\n",
    "    plt.ylim(np.min(d[y]), np.max(d[y]))\n",
    "    plt.title(\"%s (n=%d)\" % (bio, len(d)))\n",
    "    m, b, r, p, e = sp.stats.linregress(d[x], d[y])\n",
    "    print(\"y = %.3fx + %.3f (r=%.3f, p=%.3f)\" %  (m, b, r, p))\n",
    "    plt.plot(d[x], m*d[x] + b, '-')\n",
    "    plt.ylabel(\"log10(%s)\" % bayenv_col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_res_all = pd.DataFrame(ro.r('res_all$loc'))\n",
    "hierf_res_all.index = ro.r('rownames(res_all$loc)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_res_all['fst'] = hierf_res_all.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_outliers_hierf = hierf_res_all.ix[all_bayenv_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_res_all['outlier'] = hierf_res_all.apply(lambda x: x.name in all_bayenv_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_res_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_rug_color(row):\n",
    "    if row.max_bf >=3.2:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"blue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = hierf_res_all.join(bayenv_results)\n",
    "ax = sns.distplot(d.fst, kde=False)\n",
    "rug_data = pd.DataFrame(d[d.outlier==True])\n",
    "rug_data['rug_col'] = rug_data.apply(assign_rug_color, axis=1)\n",
    "for i, row in rug_data.iterrows():\n",
    "#     print(row.fst)\n",
    "    sns.rugplot([row.fst], axis=ax, c=row.rug_col)\n",
    "ile_95 = d.fst.quantile(0.95)\n",
    "import matplotlib.patches as mpatches\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"BF >= 3.2\")\n",
    "blue_patch = mpatches.Patch(color=\"blue\", label=\"BF < 3.2\")\n",
    "green_patch = mpatches.Patch(color=\"green\", label=\"95th %ile\")\n",
    "black_patch = mpatches.Patch(color=\"black\", label=\"median\")\n",
    "plt.legend(handles=[red_patch, blue_patch, gren_patch, black_patch])\n",
    "plt.xlabel(r\"$F_{ST}$\")\n",
    "plt.axvline(ile_95, color=\"green\")\n",
    "plt.axvline(np.median(d.fst), color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
