{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T13:19:24.490496",
     "start_time": "2016-03-17T13:19:23.162343"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils/\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib.request as urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import dill\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "import geopy\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.3/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.18/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-08T17:21:14.235524",
     "start_time": "2016-03-08T17:21:14.129502"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ni_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni\"\n",
    "imp_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40\"\n",
    "notimputed_vcf_gz = os.path.join(ni_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "imputed_vcf_gz = os.path.join(imp_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "vcf_files = [notimputed_vcf_gz, imputed_vcf_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-08T17:21:17.160635",
     "start_time": "2016-03-08T17:21:17.053359"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans = {0:11, 1:12, 2:22, -1:'NA'}\n",
    "def apply_hierf_trans(series):\n",
    "    return [hierf_trans[x] if x in hierf_trans else x for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-08T17:21:23.776812",
     "start_time": "2016-03-08T17:21:23.661457"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_df(dirname, fname):\n",
    "    f = os.path.join(dirname, \"%s.txt\" % fname)\n",
    "    return pd.read_csv(f, sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:32:08.401573",
     "start_time": "2016-03-10T11:30:55.817740"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = [read_df(x, \"z12_swapped\") for x in [ni_dir, imp_dir]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:32:08.522909",
     "start_time": "2016-03-10T11:32:08.404878"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "hierf_df = [x.ix[:,:-2].apply(apply_hierf_trans) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_df[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, df in enumerate(hierf_df):\n",
    "    hierf_df[i] = z12_swapped[i][['popid']].join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, elem in enumerate(vcf_files):\n",
    "    filedir = os.path.dirname(elem)\n",
    "    outfile = os.path.join(filedir, \"isect_hierfstat.txt\")\n",
    "    hierf_df[i].to_csv(outfile, header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put into R (because it can be slow)\n",
    "\n",
    "```\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "data = fread(\"isect_hierfstat.txt\", header=T, sep=\"\\t\", data.table=F)\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "bs = basic.stats(data)\n",
    "saveRDS(bs, \"isect_hierfstat_basic_stats.rds\")\n",
    "res = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "saveRDS(res, \"isect_hierfstat_varcomp.rds\")\n",
    "```\n",
    "\n",
    "### Also compute pairwise Fst (qrsh)\n",
    "```\n",
    "rm(list=ls())\n",
    "library(hierfstat)\n",
    "library(data.table)\n",
    "library(snow)\n",
    "data = fread(\"isect_hierfstat.txt\", header=T, sep=\"\\t\", data.table=F)\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "\n",
    "run_varcomp = function(idx) {\n",
    "    i = args[[idx]]$i\n",
    "    j = args[[idx]]$j\n",
    "    key = paste(i, j, sep=\"-\")\n",
    "    d = copy(data)\n",
    "    d = subset(d, d$popid == i | d$popid == j)\n",
    "    levels = data.frame(d$popid)\n",
    "    loci = d[,2:ncol(d)]\n",
    "    return(varcomp.glob(levels=levels, loci=loci, diploid=T))\n",
    "}\n",
    "\n",
    "args = list()\n",
    "for (i in 1:6) {\n",
    "    for (j in 1:i) {\n",
    "        if (i != j) {\n",
    "            args[[length(args)+1]] = list(i=i, j=j)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "hosts = rep(\"localhost\", length(args))\n",
    "cl = makeSOCKcluster(hosts)\n",
    "clusterExport(cl, \"data\")\n",
    "clusterEvalQ(cl, library(hierfstat))\n",
    "clusterEvalQ(cl, library(data.table))\n",
    "clusterExport(cl, \"args\")\n",
    "clusterExport(cl, \"run_varcomp\")\n",
    "pairwise_res = parLapply(cl, 1:length(args), \"run_varcomp\")\n",
    "saveRDS(pairwise_res, \"isect_hierfstat_pairwise.rds\")\n",
    "saveRDS(args, \"isect_hierfstat_pairwise_args.rds\")\n",
    "stopCluster(cl)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "varcomp_not = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni/isect_hierfstat_varcomp.rds\")\n",
    "bs_not = readRDS(\"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni/isect_hierfstat_basic_stats.rds\")\n",
    "varcomp_imp = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/isect_hierfstat_varcomp.rds\")\n",
    "bs_imp = readRDS(\"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3//beagle40/isect_hierfstat_basic_stats.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_r_series(key):\n",
    "    s = pd.Series(get_r(key))\n",
    "    s.index = get_r(\"names(%s)\" % key)\n",
    "    return s\n",
    "\n",
    "def get_r_df(key):\n",
    "    df = pd.DataFrame(get_r(key))\n",
    "    try:\n",
    "        rname = get_r(\"rownames(%s)\" % key)\n",
    "        df.index = rname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        cname = get_r(\"colnames(%s)\" % key)\n",
    "        df.columns = cname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_r(key):\n",
    "    return r(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perloc_not = get_r_df(\"bs_not$perloc\")\n",
    "Ho_not = get_r_df(\"bs_not$Ho\")\n",
    "Hs_not = get_r_df(\"bs_not$Hs\")\n",
    "Fis_not = get_r_df(\"bs_not$Fis\")\n",
    "overall_not = get_r_series(\"bs_not$overall\")\n",
    "n_ind_samp_not = get_r_df(\"bs_not$n.ind.samp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perloc_imp = get_r_df(\"bs_imp$perloc\")\n",
    "Ho_imp = get_r_df(\"bs_imp$Ho\")\n",
    "Hs_imp = get_r_df(\"bs_imp$Hs\")\n",
    "Fis_imp = get_r_df(\"bs_imp$Fis\")\n",
    "overall_imp = get_r_series(\"bs_imp$overall\")\n",
    "n_ind_samp_imp = get_r_df(\"bs_imp$n.ind.samp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df(dirname, fname, df):\n",
    "    f = os.path.join(dirname, \"%s.txt\" % fname) \n",
    "    df.to_csv(f, \n",
    "              header=True,\n",
    "              index=True,\n",
    "              sep=\"\\t\")\n",
    "    print(\"saved %s\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_df_not = get_r_df('varcomp_not$loc')\n",
    "F_df_not = get_r_df('varcomp_not$F')\n",
    "overall_df_not = get_r_df('varcomp_not$overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_df_imp = get_r_df('varcomp_imp$loc')\n",
    "F_df_imp = get_r_df('varcomp_imp$F')\n",
    "overall_df_imp = get_r_df('varcomp_imp$overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_df_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_fst_not = loc_df_not.apply(compute_fst, axis=1)\n",
    "loci_fst_imp = loc_df_imp.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst_not.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst_imp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    if i == 0:\n",
    "        save_df(d, 'perloc', perloc_not)\n",
    "        save_df(d, 'Ho', Ho_not)\n",
    "        save_df(d, \"Hs\", Hs_not)\n",
    "        save_df(d, 'Fis', Fis_not)\n",
    "        save_df(d, 'overall', overall_not)\n",
    "        save_df(d, 'n_ind_samp', n_ind_samp_not)\n",
    "        save_df(d, 'loc_df', loc_df_not)\n",
    "        save_df(d, 'F_df', F_df_not)\n",
    "        save_df(d, 'varcomp_overall', overall_df_not)\n",
    "        save_df(d, 'loci_fst', loci_fst_not)\n",
    "    else:\n",
    "        save_df(d, 'perloc', perloc_imp)\n",
    "        save_df(d, 'Ho', Ho_imp)\n",
    "        save_df(d, \"Hs\", Hs_imp)\n",
    "        save_df(d, 'Fis', Fis_imp)\n",
    "        save_df(d, 'overall', overall_imp)\n",
    "        save_df(d, 'n_ind_samp', n_ind_samp_imp)\n",
    "        save_df(d, 'loc_df', loc_df_imp)\n",
    "        save_df(d, 'F_df', F_df_imp)\n",
    "        save_df(d, 'varcomp_overall', overall_df_imp)\n",
    "        save_df(d, 'loci_fst', loci_fst_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(loci_fst_not, bins=50)\n",
    "plt.title(\"not imputed n=%d mean=%.4f +/- %.4f [%.4f, %.4f]\" % (len(loci_fst_not), \n",
    "                                                    np.mean(loci_fst_not), \n",
    "                                                    np.std(loci_fst_not),\n",
    "                                                    np.min(loci_fst_not), \n",
    "                                                    np.max(loci_fst_not)))\n",
    "plt.xlabel(r\"$F_{ST}$\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(loci_fst_imp, bins=50)\n",
    "plt.title(\"imputed n=%d mean=%.4f +/- %.4f [%.4f, %.4f]\" % (len(loci_fst_imp), \n",
    "                                                    np.mean(loci_fst_imp), \n",
    "                                                    np.std(loci_fst_imp),\n",
    "                                                    np.min(loci_fst_imp), \n",
    "                                                    np.max(loci_fst_imp)))\n",
    "plt.xlabel(r\"$F_{ST}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popid_map = {}\n",
    "for population, data in z12_swapped[1].groupby(\"population\"):\n",
    "    popid = data['popid'].unique()[0]\n",
    "    print(population, popid)\n",
    "    popid_map[popid] = population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perloc = read_df(imp_dir, \"perloc\")\n",
    "loc_df = read_df(imp_dir, \"loc_df\")\n",
    "Ho = read_df(imp_dir, \"Ho\")\n",
    "Ho.columns = [popid_map[int(x)] for x in Ho.columns]\n",
    "overall = read_df(imp_dir, \"overall\")\n",
    "n_ind_samp = read_df(imp_dir, \"n_ind_samp\")\n",
    "n_ind_samp.columns = [[popid_map[int(x)] for x in n_ind_samp.columns]]\n",
    "fis = read_df(imp_dir, \"Fis\")\n",
    "fis.columns = [popid_map[int(x)] for x in fis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ho.to_csv(\"Ho_labelled.txt\", \n",
    "          index=True, \n",
    "          header=True, \n",
    "          sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"Ho_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ho.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.f_oneway(Ho['NC'], Ho['NY'], Ho['QC32'], Ho['QC93'], Ho['VA1'], Ho['VA2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=Ho);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "bs_imp$pop.freq$ctg7180005039298_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_freq = r('bs_imp$pop.freq')\n",
    "\n",
    "pop_freq_names = pandas2ri.ri2py(pop_freq.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_He(elem):\n",
    "    He = 2\n",
    "    for x in elem:\n",
    "        He *= x\n",
    "    return He\n",
    "\n",
    "He_dict = {}\n",
    "\n",
    "for i, name in enumerate(pop_freq_names):\n",
    "    af = pandas2ri.ri2py_dataframe(pop_freq.rx2(name))\n",
    "    af.columns = [x+1 for x in af.columns]\n",
    "    He_dict[name] = af.apply(compute_He).to_dict()\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(\"at %d\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "He = pd.DataFrame(He_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "He.columns = [popid_map[x] for x in He.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ho_He = Ho.join(He, lsuffix = \"_Ho\", rsuffix = \"_He\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = pd.DataFrame(Ho_He.apply(np.mean)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diffs = Ho-He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=diffs)\n",
    "plt.ylabel(r\"$Ho - He$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=np.abs(diffs))\n",
    "plt.ylabel(r\"$|Ho-He|$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:18:34.683556",
     "start_time": "2016-03-10T11:18:31.127383"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pairwise = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/isect_hierfstat_pairwise.rds\")\n",
    "pairwise_args = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/isect_hierfstat_pairwise_args.rds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:16:21.125288",
     "start_time": "2016-03-10T11:16:17.900963"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pairwise[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:19:14.858626",
     "start_time": "2016-03-10T11:19:14.751206"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairwise = r(\"pairwise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:47:11.577024",
     "start_time": "2016-03-10T11:47:11.324492"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairwise_fst = np.zeros((7,7))\n",
    "for arg in range(len(pairwise_args)):\n",
    "    arg = arg+1\n",
    "    i = pairwise_args.rx2(arg).rx2(\"i\")[0]\n",
    "    j = pairwise_args.rx2(arg).rx2(\"j\")[0]\n",
    "    print(i, j)\n",
    "    F = pandas2ri.ri2py_dataframe(pairwise.rx2(arg).rx2(\"F\"))\n",
    "    pairwise_fst[i, j] = F.ix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:47:11.663231",
     "start_time": "2016-03-10T11:47:11.579880"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pairwise_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:47:11.794672",
     "start_time": "2016-03-10T11:47:11.704577"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_dict = {}\n",
    "for idx, data in z12_swapped[1][['population', 'popid']].iterrows():\n",
    "    pop_dict[data.popid] = data.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:47:11.940397",
     "start_time": "2016-03-10T11:47:11.869578"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(pairwise_df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:50:16.502775",
     "start_time": "2016-03-10T11:50:16.230778"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairwise_df = pd.DataFrame(pairwise_fst)\n",
    "pairwise_df = pairwise_df.drop(0, axis=1).drop(6, axis=1).drop(0)\n",
    "pairwise_df.columns = [pop_dict[x] for x in pairwise_df]\n",
    "pairwise_df.index = [pop_dict[x] for x in pairwise_df.index]\n",
    "pairwise_df.replace(0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T11:50:19.588569",
     "start_time": "2016-03-10T11:50:18.065767"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "sns.heatmap(pairwise_df, vmin=0, vmax=pairwise_df.max().max(), cmap=cmap, annot=True)\n",
    "plt.title(\"Pairwise multilocus %s\" % r'$F_{ST}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T13:17:49.990604",
     "start_time": "2016-03-17T13:17:49.781405"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latlon = read_df(imp_dir, \"bioclim_df\")[[\"lat\", \"lon\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T13:17:54.679104",
     "start_time": "2016-03-17T13:17:54.454343"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T13:30:22.422350",
     "start_time": "2016-03-17T13:30:22.092094"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty\n",
    "dist = {}\n",
    "for i in range(len(latlon.index)):\n",
    "    ipop = latlon.index[i]\n",
    "    icoord = (latlon.ix[ipop].lat, latlon.ix[ipop].lon)\n",
    "    if not ipop in dist:\n",
    "        dist[ipop] = {}\n",
    "    for j in range(i):\n",
    "        jpop = latlon.index[j]\n",
    "        jcoord = (latlon.ix[jpop].lat, latlon.ix[jpop].lon)\n",
    "        d = vincenty(icoord, jcoord).km\n",
    "        print(ipop, jpop, d)\n",
    "        dist[ipop][jpop] = d\n",
    "        if not jpop in dist:\n",
    "            dist[jpop] = {}\n",
    "        dist[jpop][ipop] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T13:31:11.387094",
     "start_time": "2016-03-17T13:31:11.124041"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_df = pd.DataFrame(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:11:09.033661",
     "start_time": "2016-03-17T14:11:08.743361"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fst_gps = {}\n",
    "for p in pairwise_df.index:\n",
    "    for q in pairwise_df.index:\n",
    "        if not p == q:\n",
    "            print(p, q)\n",
    "            fst = -1\n",
    "            try:\n",
    "                fst = pairwise_df.ix[p, q]\n",
    "            except:\n",
    "                fst = pairwise_df.ix[q, p]\n",
    "            key = \"-\".join(sorted([p, q]))\n",
    "            fst_gps[key] = {\"vincenty\": dist_df.ix[p,q],\n",
    "                                         \"fst\": fst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:11:24.828775",
     "start_time": "2016-03-17T14:11:24.473372"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fst_gps_df = pd.DataFrame(fst_gps).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:11:25.667289",
     "start_time": "2016-03-17T14:11:25.297462"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fst_gps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:11:31.929938",
     "start_time": "2016-03-17T14:11:29.680935"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.lmplot(\"fst\", \"vincenty\", data=fst_gps_df, scatter_kws={\"s\": 100})\n",
    "g.fig.set_size_inches(10, 10)\n",
    "for i in fst_gps_df.index:\n",
    "    plt.annotate(i, \n",
    "                 xy=(fst_gps_df.ix[i, \"fst\"], fst_gps_df.ix[i, \"vincenty\"]), \n",
    "                xytext = (-10, 20),\n",
    "                textcoords = 'offset points', ha = 'right', va = 'bottom', \n",
    "                arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "plt.ylabel(\"Vincenty (km)\")\n",
    "plt.xlabel(r'Pairwise $F_{ST}$')\n",
    "plt.show()\n",
    "#bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "#arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:12:04.512928",
     "start_time": "2016-03-17T14:12:04.230505"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-17T14:12:04.718589",
     "start_time": "2016-03-17T14:12:04.517101"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ols(\"fst~vincenty\", data=fst_gps_df).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
