{
 "metadata": {
  "name": "",
  "signature": "sha256:8d89649f2bfe671cfccabe7218fe792da1d26b209a97b3ca9b45842e459cb85c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, vcf\n",
      "from IPython.parallel import Client\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "from __future__ import division\n",
      "os.environ['R_HOME'] = '/home/cfriedline/R3/lib64/R'\n",
      "os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], os.environ['LD_LIBRARY_PATH'])\n",
      "import rpy2.robjects as robjects\n",
      "%load_ext rpy2.ipython\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import pandas.rpy.common as com\n",
      "import scipy.stats as stats\n",
      "import statsmodels.formula.api as smf\n",
      "import statsmodels.api as sm\n",
      "from multiprocessing import Pool\n",
      "from scipy.stats.stats import pearsonr\n",
      "import numbers\n",
      "import warnings\n",
      "import traceback"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "warnings.simplefilter(action=\"ignore\", category=pd.io.pytables.PerformanceWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_views():\n",
      "    rc = Client(profile='huge')\n",
      "    dview = rc[:]\n",
      "    lview = rc.load_balanced_view()\n",
      "    print \"Connected to %d IPython engines\" % len(rc)\n",
      "    return rc, dview, lview"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc, dview, lview = get_views()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc, dview, lview = get_views()\n",
      "with dview.sync_imports():\n",
      "    import os\n",
      "    import sys\n",
      "    import scipy.stats\n",
      "    import statsmodels.formula.api\n",
      "    import statsmodels.api\n",
      "    from scipy.stats.stats import pearsonr\n",
      "    import numpy\n",
      "    import scipy\n",
      "    import pandas\n",
      "    import rpy2\n",
      "    import numbers\n",
      "    import traceback\n",
      "    import socket\n",
      "    \n",
      "def setup_engines():   \n",
      "    os.environ['R_HOME'] = '/home/cfriedline/R3/lib64/R'\n",
      "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], os.environ['LD_LIBRARY_PATH'])\n",
      "    import rpy2.robjects as robjects\n",
      "    r = robjects.r\n",
      "    r(\"source('tw_calc.R')\")\n",
      "    r(\"test=read.table('twtable', header=F)\")\n",
      "\n",
      "dview['setup_engines'] = setup_engines\n",
      "setup = dview.apply(setup_engines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcftools = \"~/data7/src/vcftools_0.1.12a/bin/vcftools\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    /home/cfriedline/data7/src/freebayes/bin/freebayes -L /data7/eckertlab/gypsy_indiv/bamlist.txt -f /home/cfriedline/data7/assemblies/gypsy/masurca/CA/10-gapclose/genome.ctg.fasta -v /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#vcf called from freebayes\n",
      "fb_vcf = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --vcf $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    After filtering, kept 86785 out of a possible 86785 Sites\n",
      "    Run Time = 3.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Outputs the allele frequency for each site in a file with the suffix \".frq\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --freq --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --freq\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Frequency Statistics...\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 43.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Outputs the raw allele counts for each site in a file with the suffix \".frq.count\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --counts --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --counts\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Frequency Statistics...\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 41.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Calculates a measure of heterozygosity on a per-individual basis. Specfically, the inbreeding coefficient, F, is estimated for each individual using a method of moments. The resulting file has the suffix \".het\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --het --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --het\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Individual Heterozygosity\n",
      "        Individual Heterozygosity: Only using fully diploid SNPs.\n",
      "        Individual Heterozygosity: Only using biallelic SNPs.\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 40.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "\n",
      "Reports a p-value for each site from a Hardy-Weinberg Equilibrium test (as defined by Wigginton, Cutler and Abecasis (2005)). The resulting file (with suffix \".hwe\") also contains the Observed numbers of Homozygotes and Heterozygotes and the corresponding Expected numbers under HWE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --hardy --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "This option outputs the genotypes as a large matrix. Three files are produced. The first, with suffix \".012\", contains the genotypes of each individual on a separate line. Genotypes are represented as 0, 1 and 2, where the number represent that number of non-reference alleles. Missing genotypes are represented by -1. The second file, with suffix \".012.indv\" details the individuals included in the main file. The third file, with suffix \".012.pos\" details the site locations included in the main file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --remove-indels --min-alleles 2 --max-alleles 2 --mac 1 --remove-filtered-all --012 --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --mac 1\n",
      "        --max-alleles 2\n",
      "        --min-alleles 2\n",
      "        --012\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-filtered-all\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Writing 012 matrix files ... Done.\n",
      "    After filtering, kept 30791 out of a possible 86785 Sites\n",
      "    Run Time = 55.00 seconds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snp_quals = []\n",
      "snp_dp = []\n",
      "for i, rec in enumerate(vcf.Reader(open(fb_vcf))):\n",
      "    if rec.INFO['TYPE'][0] == 'snp':\n",
      "        snp_quals.append(rec.QUAL)\n",
      "        snp_dp.append(rec.INFO['DP'])\n",
      "    if i % 5000 == 0:\n",
      "        print \"at %d\" % i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(snp_quals, bins=100)\n",
      "plt.title(\"%.2f +/- %.2f [%d, %d]\" % (np.mean(snp_quals), np.std(snp_quals), np.min(snp_quals), np.max(snp_quals)))\n",
      "plt.xlabel(\"QUAL\")\n",
      "plt.xlim(0, 10000)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(snp_dp, bins=100)\n",
      "plt.title(\"%.2f +/- %.2f [%d, %d]\" % (np.mean(snp_dp), np.std(snp_dp), np.min(snp_dp), np.max(snp_dp)))\n",
      "plt.xlabel(\"DP\")\n",
      "plt.xlim((0,700))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "##Create file for afsource"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_missing(rec):\n",
      "    missing = 0.0\n",
      "    for sample in rec.samples:\n",
      "        if not sample.data.AO:\n",
      "            missing += 1\n",
      "    return missing\n",
      "\n",
      "def is_valid_snp(rec, min_qual, missing_prob):\n",
      "    if rec.QUAL < min_qual:\n",
      "        return False\n",
      "    t = rec.INFO['TYPE']\n",
      "    if len(t) > 1:\n",
      "        return False\n",
      "    if t[0] != 'snp':\n",
      "        return False\n",
      "    if get_missing(rec)/len(rec.samples) >= missing_prob:\n",
      "        return False\n",
      "    return True    \n",
      "\n",
      "afsource_file = \"%s.afsource_missing_0.5\" % fb_vcf\n",
      "with open(afsource_file, \"w\") as o:\n",
      "    for i, rec in enumerate(vcf.Reader(open(fb_vcf))):\n",
      "        if is_valid_snp(rec, 20, 0.5):\n",
      "            o.write(\"%s\\n\" % \"locus %s pos %d %g\" % (rec.CHROM, rec.POS, 1/rec.QUAL))\n",
      "            for sample in rec.samples:\n",
      "                ref = 0\n",
      "                alt = 0\n",
      "                if sample.data.RO:\n",
      "                    ref = sample.data.RO\n",
      "                if sample.data.AO:\n",
      "                    alt = sample.data.AO\n",
      "                try:\n",
      "                    o.write(\"%s\\n\" % \"%d %d\" % (ref, alt))\n",
      "                except:\n",
      "                    print rec.INFO\n",
      "                    print sample.data\n",
      "        if i % 5000 == 0:\n",
      "            print \"at %d\" % i\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "##Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hardy_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.hwe\"\n",
      "het_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.het\"\n",
      "freq_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.frq\"\n",
      "counts_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.frq.count\"\n",
      "z12_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012\"\n",
      "pos_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012.pos\"\n",
      "indv_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012.indv\"\n",
      "trans_table = \"translation_table.csv\"\n",
      "store_path = \"/data7/cfriedline/ipython/notebooks/gypsy_moth/store.h5\"\n",
      "store = pd.HDFStore(store_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview['store_path'] = store_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Read in 012 file from vcf tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z12_df = None\n",
      "if 'z12_df' in store:\n",
      "    z12_df = store['z12_df']\n",
      "else:\n",
      "    z12_df = pd.read_csv(z12_file, header=None, sep=\"\\t\")\n",
      "    z12_df = z12_df.drop(0, axis=1)\n",
      "    z12_df.columns = pd.Series(z12_df.columns)-1\n",
      "    store['z12_df'] = z12_df\n",
      "# pos_df = pd.read_csv(pos_file, header=None, sep=\"\\t\", names=[\"contig\", \"pos\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_allele_counts(series, filter_missing=True):\n",
      "    P = 0.0\n",
      "    Q = 0.0\n",
      "    PQ = 0.0\n",
      "    missing = 0.0\n",
      "    c = series.value_counts()\n",
      "    if 0 in c:\n",
      "        P = c[0]\n",
      "    if 2 in c:\n",
      "        Q = c[2]\n",
      "    if 1 in c:\n",
      "        PQ = c[1]\n",
      "    if -1 in c:\n",
      "        missing = c[-1]\n",
      "    missing_perc = missing/len(series)\n",
      "    if filter_missing and missing_perc > 0.5:\n",
      "#         print \"too much missing data %g\" % missing_perc\n",
      "        P = PQ = Q = 0.0\n",
      "    return (P, PQ, Q)\n",
      "\n",
      "def get_correction(n):\n",
      "    #for finite sample size\n",
      "    return (2*n)/(2*n-1)\n",
      "\n",
      "def get_allele_freqs(series, filter_missing=True):\n",
      "    c = get_allele_counts(series, filter_missing)\n",
      "    if c:\n",
      "        if sum(c) == 0:\n",
      "            return 0.0,0.0, 0.0, c\n",
      "        else:\n",
      "            P = 2*c[0] + c[1]\n",
      "            Q = 2*c[2] + c[1]\n",
      "            total = P + Q\n",
      "            p = P/total\n",
      "            q = Q/total\n",
      "            maf = min(p, q)\n",
      "            return maf, p, q, c \n",
      "        \n",
      "def get_he(series):\n",
      "    maf, p, q, c = get_allele_freqs(series)\n",
      "    if p:\n",
      "        He = 2 * p * q * get_correction(sum(c))\n",
      "        return He\n",
      "    return None\n",
      "\n",
      "def get_ho(series):\n",
      "    c = get_allele_counts(series)\n",
      "    if c:\n",
      "        if sum(c) == 0:\n",
      "            return 0.0\n",
      "        else:\n",
      "            Ho = c[1]/(sum(c))\n",
      "            return Ho\n",
      "    return None\n",
      "    \n",
      "def get_Fis(df):\n",
      "#     df = df.ix[:,0:10]\n",
      "    #need cols b/c we might be loading modified table from h5, only want orig snp cols\n",
      "    cols = [x for x in df.columns if isinstance(x, numbers.Number)]\n",
      "    obs = df[cols].apply(get_ho)\n",
      "    exp = df[cols].apply(get_he)\n",
      "    Fis = 1 - obs/exp\n",
      "    return obs, exp, Fis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs = exp = Fis = None\n",
      "# [store.remove(x) for x in ['obs', 'exp', 'Fis'] if x in store]\n",
      "if 'Fis' in store:\n",
      "    obs = store['obs']\n",
      "    exp = store['exp']\n",
      "    Fis = store['Fis']\n",
      "else:\n",
      "    obs, exp, Fis = get_Fis(z12_df)\n",
      "    store['obs'] = obs\n",
      "    store['exp'] = exp\n",
      "    store['Fis'] = Fis\n",
      "Fis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = Fis.replace([np.inf, -np.inf], np.nan).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(x, bins=12)\n",
      "plt.title(\"n=%d\" % len(x))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Remove based on F_is outliers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Fis_filter_fis = Fis[(Fis >= -0.5) & (Fis <= 0.5)] # by Fis value\n",
      "print \"removed\", (len(Fis)-len(Fis_filter_fis))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    removed 19551"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Remove based on MAF < 0.01"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rare = []\n",
      "for snp_index in Fis_filter_fis.index:\n",
      "    maf, p, q, c = get_allele_freqs(z12_df[snp_index])\n",
      "    if maf < 0.01:\n",
      "        rare.append(snp_index)\n",
      "print len(rare)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    219"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Fis_filter_fis_rare = Fis_filter_fis.drop(rare)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Put filtered data back with sample/pop"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = None\n",
      "if 'df' in store:\n",
      "    df = store['df']\n",
      "    z12_df = store['z12_df']\n",
      "else:\n",
      "    trans_df = pd.read_csv(trans_table, header=0, index_col=0, sep=\"\\t\")\n",
      "    for i, line in enumerate(open(indv_file)):\n",
      "        line = line.strip()\n",
      "        trans = trans_df.ix[line]\n",
      "        z12_df.ix[i, 'sample'] = \"%s_%d\" % (trans['pop'], trans['indiv'])\n",
      "        z12_df.ix[i, 'pop'] = trans['pop']\n",
      "        z12_df.ix[i, 'dupl'] = trans['dup']\n",
      "    df = z12_df[z12_df['dupl']==0]\n",
      "    df = df.drop('dupl', axis=1)\n",
      "    store['df'] = df\n",
      "    store['z12_df'] = z12_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pop_id = {}\n",
      "i = 0\n",
      "for p in sorted(z12_df['pop'].unique()):\n",
      "    pop_id[p] = i\n",
      "    i+=1\n",
      "pop_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hierf = None\n",
      "# store.remove('hierf')\n",
      "if 'hierf' in store:\n",
      "    hierf = store['df']\n",
      "    df = store['df']\n",
      "else:\n",
      "    hierf_trans = {0:11, 1:12, 2:22, -1:'NA'}\n",
      "    def apply_hierf_trans(series):\n",
      "        return [hierf_trans[x] if x in hierf_trans else x for x in series]\n",
      "    df = df.apply(apply_hierf_trans)\n",
      "\n",
      "    def assign_popid(series):\n",
      "        series['popid'] = pop_id[series['pop']]\n",
      "        return series\n",
      "    df = df.apply(assign_popid, axis=1)  \n",
      "\n",
      "    import numbers\n",
      "    hierfcols = ['sample', 'popid']\n",
      "    # hierfcols.extend(df.columns.values[0:-3])\n",
      "    hierfcols.extend(Fis_filter_fis_rare.index)\n",
      "    hierf = df[hierfcols].sort('popid')\n",
      "    cols = [None]*len(hierf.columns)\n",
      "    for i, x in enumerate(hierf.columns):\n",
      "        if isinstance(x, numbers.Number):\n",
      "            cols[i] = \"L%d\" % x\n",
      "        else:\n",
      "            cols[i] = x\n",
      "    hierf.columns = pd.Index(cols)\n",
      "    hierf.to_csv(\"hierfstat.txt\", header=True, index=False, sep=\"\\t\")\n",
      "    store['hierf'] = hierf\n",
      "    store['df'] = df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(hierfstat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "data = read.table(\"hierfstat.txt\", header=T, sep=\"\\t\")\n",
      "levels = data.frame(data$popid)\n",
      "loci = data[,3:ncol(data)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "res = varcomp.glob(levels=levels, loci=loci, diploid=T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "saveRDS(res, \"hierfstat.rds\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "res = readRDS(\"hierfstat.rds\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = com.convert_robj(robjects.r('res'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "loc_df = res['loc']\n",
      "F_df = res['F']\n",
      "overall_df = res['overall']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def compute_fst(series):\n",
      "    Hs = series[0]\n",
      "    Ht = sum(series)\n",
      "    return (Ht-Hs)/Ht"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loci_fst = loc_df.apply(compute_fst, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(loci_fst, bins=20)\n",
      "plt.title(\"n=%d (%.2f, %.2f)\" % (len(loci_fst), np.min(loci_fst), np.max(loci_fst)))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "###Setup for PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_data = None\n",
      "if 'pca_data' in store:\n",
      "    pca_data = store['pca_data']\n",
      "else:\n",
      "    filtered_cols = Fis_filter_fis_rare.index.tolist()\n",
      "    filtered_cols.extend(['sample', 'pop','dupl'])\n",
      "    pca_data = z12_df[filtered_cols]\n",
      "    pca_data = pca_data[pca_data['dupl']==0]\n",
      "    cols = [None]*len(pca_data.columns)\n",
      "    for i, x in enumerate(pca_data.columns):\n",
      "        if isinstance(x, numbers.Number):\n",
      "            cols[i] = \"L%d\" % x\n",
      "        else:\n",
      "            cols[i] = x\n",
      "    pca_data.columns = pd.Index(cols)\n",
      "    store['pca_data'] = pca_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def swap_alleles(series):\n",
      "#     series=pca_data[series]\n",
      "    if series.name.startswith(\"L\"):\n",
      "        maf,p,q,c = get_allele_freqs(series, filter_missing=False)\n",
      "        if maf == p:\n",
      "            return series.replace({0:2, 2:0})\n",
      "    return series\n",
      "\n",
      "def center_and_standardize_value(val, u, var):\n",
      "    if val == -1:\n",
      "        return 0.0\n",
      "    return (val-u)/var\n",
      "\n",
      "\n",
      "def center_and_standardize(series):\n",
      "#     series=pca_data[series]\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    if series.name.startswith(\"L\"):\n",
      "        maf,p,q,c = get_allele_freqs(series, filter_missing=False)\n",
      "        u = sum([i*x for i, x in enumerate(c)])/sum(c)\n",
      "        var = np.sqrt(maf*(1-maf))\n",
      "        return series.apply(center_and_standardize_value, args=(u, var))\n",
      "    return series\n",
      "\n",
      "# dview['swap_alleles'] = swap_alleles\n",
      "# dview['swap_allele'] = swap_allele\n",
      "# dview['center_and_standardize'] = center_and_standardize\n",
      "# dview['center_and_standardize_value'] = center_and_standardize_value\n",
      "# dview['get_allele_counts'] = get_allele_counts\n",
      "# dview['get_allele_freqs'] = get_allele_freqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dview.push({'pca_data':pca_data})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make sure minor allele is 2\n",
      "pca_maf = None\n",
      "if 'pca_maf' in store:\n",
      "    pca_maf = store['pca_maf']\n",
      "else:\n",
      "    pca_maf = pca_data.apply(swap_alleles)\n",
      "    # pca_maf = pd.concat(lview.map_async(swap_alleles, pca_data.columns.tolist()).get(), axis=1)\n",
      "    store['pca_maf'] = pca_maf\n",
      "\n",
      "#standardize with minor allele freq\n",
      "pca_std = None\n",
      "pca_std_data = None\n",
      "if 'pca_std' in store:\n",
      "    pca_std = store['pca_std']\n",
      "    pca_std_data = store['pca_std_data']\n",
      "else:\n",
      "    pca_std = pca_maf.apply(center_and_standardize)\n",
      "    # pca_std = pd.concat(lview.map_async(center_and_standardize, [pca_maf[col] for col in pca_maf]).get(), axis=1)\n",
      "    #get only the data cols\n",
      "    pca_std_data = pca_std.ix[:,0:-3]\n",
      "    store['pca_std'] = pca_std\n",
      "    store['pca_std_data'] = pca_std_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in xrange(5):\n",
      "    print pca_std_data.ix[:,x].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    count    1.890000e+02\n",
      "    mean     2.937098e-18\n",
      "    std      9.833783e-01\n",
      "    min     -3.631365e-01\n",
      "    25%     -3.631365e-01\n",
      "    50%      0.000000e+00\n",
      "    75%      0.000000e+00\n",
      "    max      5.326002e+00\n",
      "    dtype: float64\n",
      "    count    1.890000e+02\n",
      "    mean    -1.844498e-16\n",
      "    std      9.954059e-01\n",
      "    min     -6.188527e-01\n",
      "    25%     -6.188527e-01\n",
      "    50%      0.000000e+00\n",
      "    75%      0.000000e+00\n",
      "    max      2.922360e+00\n",
      "    dtype: float64\n",
      "    count    1.890000e+02\n",
      "    mean     3.289550e-17\n",
      "    std      1.302756e+00\n",
      "    min     -9.047280e-01\n",
      "    25%     -9.047280e-01\n",
      "    50%     -9.047280e-01\n",
      "    75%      1.758245e+00\n",
      "    max      4.421218e+00\n",
      "    dtype: float64\n",
      "    count    1.890000e+02\n",
      "    mean     4.346905e-17\n",
      "    std      1.379861e+00\n",
      "    min     -9.794946e-01\n",
      "    25%     -9.794946e-01\n",
      "    50%     -9.794946e-01\n",
      "    75%      1.552122e+00\n",
      "    max      4.083739e+00\n",
      "    dtype: float64\n",
      "    count    1.890000e+02\n",
      "    mean    -8.693810e-17\n",
      "    std      1.431318e+00\n",
      "    min     -1.326130e+00\n",
      "    25%     -1.326130e+00\n",
      "    50%      0.000000e+00\n",
      "    75%      8.450828e-01\n",
      "    max      3.016296e+00\n",
      "    dtype: float64"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = robjects.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prcomp = r('prcomp')\n",
      "summary = r('summary')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prcomp_res = prcomp(pca_std_data, scale=False, center=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print summary(prcomp_res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = com.convert_robj(prcomp_res.rx2(\"x\"))\n",
      "x.index = pca_std_data.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joined = x.join(pca_maf)\n",
      "store['joined'] = joined\n",
      "joined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "colors=[pop_id[x.split(\"_\")[0]] for x in joined.sample.tolist()]\n",
      "labels = [x.split(\"_\")[0] for x in joined.sample.tolist()]\n",
      "plt.scatter(joined.PC1, joined.PC2, c=colors, s=50)\n",
      "fig = plt.gcf()\n",
      "fig.set_size_inches(10,8)\n",
      "plt.title(\"PCA of n=%d samples on %d loci\" % (len(joined), len(pca_std_data.columns)))\n",
      "plt.xlabel(\"PC1 (0.021%)\")\n",
      "plt.ylabel(\"PC2 (0.015%)\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_missing_perc(series):\n",
      "    missing = 0\n",
      "    total = 0\n",
      "    for x in series.index:\n",
      "        if x.startswith(\"L\"):\n",
      "            if series[x] == -1:\n",
      "                missing += 1\n",
      "            total +=1\n",
      "    return missing/total\n",
      "    \n",
      "missing_perc = joined.apply(compute_missing_perc, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joined['missing_perc'] = missing_perc\n",
      "store['joined'] = joined\n",
      "joined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(joined.missing_perc, joined.PC1)\n",
      "plt.xlabel(\"missing perc\")\n",
      "plt.ylabel(\"PC1\")\n",
      "fig = plt.gcf()\n",
      "fig.set_size_inches(10,8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
      "response = urllib2.urlopen(url)\n",
      "pheno = pd.read_excel(response, \"Males-forGenomics-final\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
      "for x in pheno.index:\n",
      "    pheno.ix[x, 'sample_pheno'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno_index = []\n",
      "missing = [] \n",
      "for x in pheno.index:\n",
      "    sample = pheno.ix[x]['sample_pheno']\n",
      "    target = joined[joined['sample']==sample]\n",
      "    if len(target.index):\n",
      "        i = target.index.tolist()[0]\n",
      "        pheno_index.append(i)\n",
      "    else:\n",
      "        missing.append(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno = pheno.drop(missing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno = pheno.set_index(pd.Index(pheno_index))\n",
      "pheno = pheno.sort()\n",
      "store['pheno'] = pheno"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jp = None\n",
      "if 'jp' in store:\n",
      "    jp = store['jp']\n",
      "else:\n",
      "    jp=pd.concat([joined,pheno], axis=1)\n",
      "    jp=jp.drop(jp[np.isnan(jp['Mass'])].index)\n",
      "    store['jp'] = jp\n",
      "jp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "###PCA Price et al. 2006"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R \n",
      "source('tw_calc.R')\n",
      "test=read.table(\"twtable\", header=F)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_data2 = pca_data2_std = None\n",
      "if 'pca_data2' in store:\n",
      "    pca_data2 = store['pca_data2']\n",
      "    pca_data2_std = store['pca_data2_std']\n",
      "else:\n",
      "    pca_data2 = jp[[x for x in jp.columns if x.startswith(\"L\")]]\n",
      "    pca_data2_std = pca_data2.apply(center_and_standardize)\n",
      "    pca_data2_std.columns = [x.replace(\"L\", \"S\") for x in pca_data2_std.columns]\n",
      "    store['pca_data2'] = pca_data2\n",
      "    store['pca_data2_std'] = pca_data2_std"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = robjects.r\n",
      "prcomp = r('prcomp')\n",
      "TWcalc = r('TWcalc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drop = 0\n",
      "S0 = pca_data2_std.drop('S%d' % drop, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tw_e = tw_p = None\n",
      "if 'tw_p' in store:\n",
      "    tw_p = store['tw_p']\n",
      "    tw_e = store['tw_e']\n",
      "else:\n",
      "    tw = TWcalc(com.convert_to_r_matrix(S0), 10)\n",
      "    tw_p = com.convert_robj(tw.rx2(2))\n",
      "    tw_e = com.convert_robj(tw.rx2(1))\n",
      "    store['tw_p'] = pd.Series(tw_p)\n",
      "    store['tw_e'] = pd.Series(tw_e)\n",
      "print tw_e\n",
      "print tw_p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tw_num = 0\n",
      "for i, p in enumerate(tw_p):\n",
      "    if p > 0.05:\n",
      "        tw_num = i\n",
      "        break\n",
      "print \"Tracy-Widom test yields %d axes of pop structure\" % tw_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_pca(df_name, col):\n",
      "    import traceback\n",
      "    try:\n",
      "        store = pandas.HDFStore(store_path, \"r\")\n",
      "        df = store[df_name]\n",
      "        df = df.drop(col, axis=1)\n",
      "        prcomp = rpy2.robjects.r('prcomp')\n",
      "        import pandas.rpy.common as com\n",
      "        res = prcomp(com.convert_to_r_matrix(df), center=False, scale=False)\n",
      "        store.close()\n",
      "        return df_name, col, socket.gethostname(), com.convert_robj(res.rx2('x'))\n",
      "    except:\n",
      "        return df_name, col, socket.gethostname(), traceback.format_exc()\n",
      "dview['do_pca'] = do_pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Do Leave-One-Out PCA for all loci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc, dview, lview = get_views()\n",
      "pca_jobs = []\n",
      "for i, col in enumerate(pca_data2_std):\n",
      "    if col.startswith(\"S\"):\n",
      "        if i % 1000 == 0:\n",
      "            print \"at %d\" % i\n",
      "#             do_pca('pca_data2_std', col)\n",
      "        pca_jobs.append(lview.apply_async(do_pca, 'pca_data2_std', col))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write = True\n",
      "pca_ready = 0\n",
      "submitted = []\n",
      "completed = []\n",
      "pca_results = []\n",
      "failed = []\n",
      "for j in pca_jobs:\n",
      "#     print j.stdout\n",
      "    if j.ready():\n",
      "        pca_ready+=1\n",
      "        submitted.append(j.metadata.submitted)\n",
      "        completed.append(j.metadata.completed)\n",
      "        if write:\n",
      "            res = None\n",
      "            try:\n",
      "                res = j.get()\n",
      "                pca_results.append(res)\n",
      "                if not isinstance(res[-1], pd.DataFrame):\n",
      "                    print \"failed at %s\" % res\n",
      "                    failed.append(res)\n",
      "            except:\n",
      "                pass\n",
      "print \"%d/%d\" % (pca_ready, len(pca_jobs))\n",
      "print failed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, p in enumerate(pca_results):\n",
      "    if i % 1000 == 0:\n",
      "        print i, p[0:3]\n",
      "    node = \"pca/%s\" % p[1]\n",
      "    store[node] = p[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max(completed)-min(submitted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    0:29:16.933227"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###group loci by maf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_maf_bin(series):\n",
      "    bins = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "    maf, p, q, c = get_allele_freqs(pca_maf[series])\n",
      "    for elem in bins:\n",
      "        if maf <= elem:\n",
      "            return elem\n",
      "maf_bins = pca_maf.groupby(get_maf_bin, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loci = 0\n",
      "bin_names = []\n",
      "if not store.is_open:\n",
      "    store.open()\n",
      "for b, pca_maf_bin in maf_bins:\n",
      "    bin_cols = [x for x in pca_maf_bin.columns if x.startswith(\"L\")]\n",
      "    std_cols = [x.replace(\"L\", \"S\") for x in bin_cols]\n",
      "    std_bin = pca_data2_std[std_cols]\n",
      "    print b, len(bin_cols), len(std_bin.columns)\n",
      "    loci += len(bin_cols)\n",
      "    bin_name = \"pca_bin/bin_%s/df\" % str(int(b*100))\n",
      "    store[bin_name] = std_bin    \n",
      "    bin_names.append(bin_name)\n",
      "print loci"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc, dview, lview = get_views()\n",
      "bin_jobs = {}\n",
      "if not store.is_open:\n",
      "    store.open()\n",
      "for bin_name in bin_names:\n",
      "    print bin_name\n",
      "    df = store[bin_name]\n",
      "    node_path = \"/\".join(bin_name.split(\"/\")[0:-1])\n",
      "    bin_jobs[node_path] = []\n",
      "    for i, col in enumerate(df):\n",
      "        if col.startswith(\"S\"):\n",
      "            if i % 1000 == 0:\n",
      "                print \"at %d\" % i\n",
      "#             print do_pca(bin_name, col)\n",
      "#             bin_jobs[node_path].append(col)\n",
      "            bin_jobs[node_path].append(lview.apply_async(do_pca, bin_name, col))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write=True\n",
      "failed = []\n",
      "bin_results = []\n",
      "if not store.is_open:\n",
      "    store.open()\n",
      "for node_path, jobs in bin_jobs.items():\n",
      "    ready = 0\n",
      "    good = 0\n",
      "    local_failed = 0\n",
      "    for j in jobs:\n",
      "        if j.ready():\n",
      "            res = j.get()\n",
      "            if isinstance(res[-1], pd.DataFrame):\n",
      "                good += 1\n",
      "                if write:                    \n",
      "                    bin_results.append(res)\n",
      "            else:\n",
      "                local_failed += 1\n",
      "                failed.append(res)\n",
      "            ready+=1\n",
      "    print \"%s: %d/%d (%d, %d)\" % (node_path, ready, len(jobs), good, local_failed)\n",
      "print \"failed %s\" % len(failed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    pca_bin/bin_10: 4123/4123 (4123)\n",
      "    pca_bin/bin_20: 2988/2988 (2988)\n",
      "    pca_bin/bin_30: 2365/2365 (2365)\n",
      "    pca_bin/bin_40: 914/914 (914)\n",
      "    pca_bin/bin_50: 631/631 (631)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bin_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[store.remove(x) for x in ['pca_bin/bin_10',\n",
      "                           'pca_bin/bin_20',\n",
      "                           'pca_bin/bin_30',\n",
      "                           'pca_bin/bin_40',\n",
      "                           'pca_bin/bin_50'] if x in store]\n",
      "counts = {}\n",
      "for i, res in enumerate(bin_results):\n",
      "    parent = \"%s\" % \"/\".join(res[0].split(\"/\")[0:-1])\n",
      "    path = \"%s/%s\" % (\"/\".join(res[0].split(\"/\")[0:-1]), res[1])\n",
      "    \n",
      "    if not parent in counts:\n",
      "        counts[parent] = 1\n",
      "    else:\n",
      "        counts[parent] += 1\n",
      "        store[path] = res[-1]\n",
      "    if i % 1000 == 0:\n",
      "        print i, path\n",
      "counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "concat_data = pd.concat([store[x] for x in ['pca_data2_std', 'pca_data2', 'pheno']], \n",
      "                        axis=1, \n",
      "                        join=\"inner\")\n",
      "store['concat_data'] = concat_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_fit_results(fit):\n",
      "    import numbers\n",
      "    import pandas as pd\n",
      "    summary = None\n",
      "    params = None\n",
      "    diag=None\n",
      "    curkey = None\n",
      "    for i, table in enumerate(fit.summary().tables):\n",
      "        if i != 1:\n",
      "            sdata = {}\n",
      "            for elem in table.data:\n",
      "                for ind in elem:\n",
      "                    ind = ind.strip()\n",
      "                    if \":\" in ind:\n",
      "                        curkey = ind\n",
      "                    else:\n",
      "                        val = None\n",
      "                        if isinstance(ind, numbers.Number):\n",
      "                            val = float(ind)\n",
      "                        else:\n",
      "                            val = ind\n",
      "                        sdata[curkey] = val\n",
      "            if i == 0:\n",
      "                summary = pd.Series(sdata)\n",
      "            else:\n",
      "                diag = pd.Series(sdata, dtype=float)\n",
      "        else:\n",
      "            params = pd.DataFrame(table.data)\n",
      "\n",
      "    params.ix[0,0] = \"x\"\n",
      "    params.columns=[x.replace(\" \", \"\") for x in params.ix[0,:]]\n",
      "    params = params.drop(0)\n",
      "    params.index = params.ix[:,0]\n",
      "    params.index.name = None\n",
      "    params=params.drop(\"x\", axis=1)\n",
      "    return summary, params, diag, fit.resid\n",
      "dview['convert_fit_results'] = convert_fit_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def refresh_store():\n",
      "    import os\n",
      "    import socket\n",
      "    import pandasf\n",
      "    store = pandas.HDFStore(\"store.h5\")\n",
      "    store.close()\n",
      "    return os.getpid(), socket.gethostname()\n",
      "dview['refresh_store'] = refresh_store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc, dview, lview = get_views()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_model(df_path, locus, dep_var, tw_num):\n",
      "    import pandas as pd\n",
      "    import statsmodels.formula.api as smf\n",
      "    from scipy.stats.stats import pearsonr\n",
      "    try:\n",
      "        store = pd.HDFStore(\"store.h5\")\n",
      "        df = store[df_path]\n",
      "        df.index = pd.Index([int(x) for x in df.index])\n",
      "        m = pd.concat([store['concat_data'], df], axis=1, join=\"inner\")\n",
      "        ind = \"+\".join([\"PC%d\" % (x+1) for x in xrange(tw_num)])\n",
      "        p_model = smf.ols(formula=\"%s ~ %s\" % (dep_var, ind), data=m)\n",
      "        p_fit = p_model.fit()\n",
      "        g_model = smf.ols(formula=\"%s ~ %s\" % (locus, ind), data=m)\n",
      "        g_fit = g_model.fit()\n",
      "        store.close()\n",
      "        corrected_r = pearsonr(p_fit.resid, g_fit.resid)\n",
      "        uncorrected_r = pearsonr(m[dep_var], m[locus])\n",
      "        return {\"p_fit\":convert_fit_results(p_fit), \"g_fit\":convert_fit_results(g_fit), \"r_c\":corrected_r, \"r_u\":uncorrected_r}\n",
      "    except:\n",
      "        return traceback.format_exc()\n",
      "dview['fit_model']=fit_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bin_nodes(bin_names):\n",
      "    d = {}\n",
      "    for name in bin_names:\n",
      "        name = '/'.join(name.split(\"/\")[0:-1])\n",
      "        d[name] = []\n",
      "        node = store.get_node(name)\n",
      "        for child, df in node._v_children.items():\n",
      "            d[name].append(df._v_pathname)\n",
      "    return d\n",
      "bin_nodes = get_bin_nodes(bin_names)\n",
      "for k, v in bin_nodes.items():\n",
      "    print k, len(v)            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rc, dview, lview = get_views()\n",
      "# refresh=dview.apply(refresh_store).get()\n",
      "# print \"refreshed %d engines\" % len(refresh)\n",
      "\n",
      "bin_model_jobs = {}\n",
      "dep_vars = [\"Mass\", \"Pupual Duration\", \"Total Dev Time\"]\n",
      "if not store.is_open:\n",
      "    store.open()\n",
      "for node, children in bin_nodes.items():\n",
      "    node_count = 0\n",
      "    \n",
      "    for df_path in children:\n",
      "        locus = df_path.split(\"/\")[-1]\n",
      "        if locus.startswith(\"S\"): #ignore the df node\n",
      "            node_count += 1\n",
      "            for dep_var in dep_vars:\n",
      "                bin_model_jobs[node].append(lview.apply_async(fit_model, df_path, locus, dep_var, tw_num))\n",
      "    print node, node_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not store.is_open:\n",
      "    store.open()\n",
      "for k, v in bin_model_jobs.items():\n",
      "    ready = 0\n",
      "    for j in v:\n",
      "        if j.ready():\n",
      "            ready+=1\n",
      "            res = None\n",
      "            res = j.get()\n",
      "            print res\n",
      "            break\n",
      "    break\n",
      "    print \"%s: %d/%d\" % (k, ready, len(v))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "store.root.pca_bin."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pearsonr(p_fit.resid, g_fit.resid)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}