{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:36:17.834469",
     "start_time": "2016-03-03T13:36:17.702495"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:36:18.419438",
     "start_time": "2016-03-03T13:36:18.408257"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/ipynb/gypsy_moth/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:53:14.958620",
     "start_time": "2016-03-25T14:53:14.071379"
    },
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp\n",
    "import shutil\n",
    "import pickle\n",
    "from utils import read_df, save_df\n",
    "import iterlib\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "from ipyparallel import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:36:41.327027",
     "start_time": "2016-03-03T13:36:41.315712"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir_notimp = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni/\"\n",
    "analysis_dir_imp = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:36:41.344839",
     "start_time": "2016-03-03T13:36:41.334018"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = [analysis_dir_notimp, analysis_dir_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:36:45.427358",
     "start_time": "2016-03-03T13:36:41.352670"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(sp)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raster = r(\"raster\")\n",
    "extract = r(\"extract\")\n",
    "\n",
    "gps = {'QC32':[47.2509807, -79.4060515],\n",
    "      'QC93': [46.90826, -70.8061075],\n",
    "      'NC': [36.449125, -76.024672],\n",
    "      'NY': [42.897768, -74.094761],\n",
    "      'VA1': [38.657615, -77.463603],\n",
    "      'VA2': [38.857470, -77.695003]}\n",
    "gps_df = pd.DataFrame(gps).T\n",
    "gps_df.columns = ['lat','lon']\n",
    "\n",
    "latlon = pandas2ri.py2ri(gps_df[['lon', 'lat']])\n",
    "\n",
    "bioclim_dir = \"/gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/bioclim_13\"\n",
    "bioclim = !ls {bioclim_dir}/*.bil\n",
    "bioclim = sorted(bioclim)\n",
    "bioclim_df = pd.DataFrame(gps_df)\n",
    "for b in bioclim:\n",
    "    rast = raster(b)\n",
    "    bio = os.path.basename(b).split(\"_\")[0].upper()\n",
    "    vals = pd.DataFrame(pandas2ri.ri2py(extract(rast, latlon)))\n",
    "    vals.index = bioclim_df.index\n",
    "    vals.columns = [bio]\n",
    "    bioclim_df = bioclim_df.join(vals)\n",
    "bioclim_df = bioclim_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in analysis_dir:\n",
    "    save_df(d, \"bioclim_df\", bioclim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = []\n",
    "for d in analysis_dir:\n",
    "    z12_swapped.append(read_df(d, \"z12_swapped\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:18:56.802140",
     "start_time": "2016-03-25T14:18:45.228094"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = []\n",
    "for d in analysis_dir:\n",
    "    infile = os.path.join(d, \"pop_allele_data.pkl\")\n",
    "    paf = pickle.load(open(infile, \"rb\"))\n",
    "    pop_allele_freqs.append(paf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:28:36.310714",
     "start_time": "2016-03-25T14:21:38.431957"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsfile_df = []\n",
    "for i, paf in enumerate(pop_allele_freqs):\n",
    "    pops = sorted(paf)\n",
    "    paf_data = defaultdict(defaultdict)\n",
    "    for popn in pops:\n",
    "        af = pd.DataFrame(paf[popn])\n",
    "        for snp in af:\n",
    "            paf_data[\"%s_1\" % snp][popn] = af.ix[\"P\",snp]\n",
    "            paf_data[\"%s_2\" % snp][popn] = af.ix[\"Q\",snp]  \n",
    "    df = pd.DataFrame(paf_data).T\n",
    "    df['blank'] = \"\"\n",
    "    snpsfile_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:14.917246",
     "start_time": "2016-03-25T14:30:14.899525"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environ_cols = snpsfile_df[0].columns.drop(\"blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:15.230352",
     "start_time": "2016-03-25T14:30:15.218300"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environ_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:22.832033",
     "start_time": "2016-03-25T14:30:22.768733"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [read_df(x, \"bioclim_df\") for x in analysis_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:22.940047",
     "start_time": "2016-03-25T14:30:22.929098"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bioclim[1].to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:23.197551",
     "start_time": "2016-03-25T14:30:23.131310"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [bioclim[1]]\n",
    "bioclim = [x[[y for y in x if 'BIO' in y]] for x in bioclim]\n",
    "bioclim = [x.T for x in bioclim]\n",
    "bioclim = [x[environ_cols] for x in bioclim]\n",
    "bioclim = [x.astype(float) for x in bioclim]\n",
    "bioclim = [x.apply(preprocessing.scale, axis=1) for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:25.670262",
     "start_time": "2016-03-25T14:30:25.658494"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [x.assign(blank=lambda x: \"\") for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:30:26.082404",
     "start_time": "2016-03-25T14:30:26.073709"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim.append(bioclim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,snps in enumerate(snpsfile_df):\n",
    "    snp_outfile = os.path.join(analysis_dir[i], \"snpsfile\")\n",
    "    env_outfile = os.path.join(analysis_dir[i], \"environfile\")\n",
    "    snps.to_csv(snp_outfile, sep=\"\\t\", header=False, index=False)\n",
    "    envs = bioclim[i]\n",
    "    envs.to_csv(env_outfile, sep=\"\\t\", header=False, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bayenv to create covariance matrix\n",
    "\n",
    "```bash\n",
    "~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 100000 -r 187564 > matrix.out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check cov matrix estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir[1], \"bayenv_cov.txt\"), \"w\") as o:\n",
    "    for i in range(0, 5):\n",
    "        r = random.getrandbits(16)\n",
    "        cmd = \"~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 100000 -r %g > matrix_%d.out\" % (r, i)\n",
    "        o.write(\"%s\\n\" % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir[1], \"bayenv_cov_1M.txt\"), \"w\") as o:\n",
    "    for i in range(0, 5):\n",
    "        r = random.getrandbits(16)\n",
    "        cmd = \"~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 1000000 -r %g > matrix_1M_%d.out\" % (r, i)\n",
    "        o.write(\"%s\\n\" % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir[1], \"bayenv_cov_500k.txt\"), \"w\") as o:\n",
    "    for i in range(0, 5):\n",
    "        r = random.getrandbits(16)\n",
    "        cmd = \"~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 500000 -r %g > matrix_500k_%d.out\" % (r, i)\n",
    "        o.write(\"%s\\n\" % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-03T13:38:13.824509",
     "start_time": "2016-03-03T13:38:13.814571"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mat(m):\n",
    "    vcovs = []\n",
    "    current = None\n",
    "    for line in open(m):\n",
    "        if \"VAR-COVAR\" in line:\n",
    "            current = []\n",
    "            vcovs.append(current)\n",
    "        if isinstance(current, list):\n",
    "            current.append(line.strip().split(\"\\t\"))\n",
    "    return vcovs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mats = {}\n",
    "for i in range(0,5):\n",
    "    fname = os.path.join(basedir, \"matrix_%d.out\" % i)\n",
    "    mats[i] = read_mat(fname)\n",
    "\n",
    "mat_dfs = {}\n",
    "for m in mats:\n",
    "    temp = []\n",
    "    for i, elem in enumerate(mats[m]):\n",
    "        temp.append(pd.DataFrame(elem[1:]).T)\n",
    "    mat_dfs[m] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_hm = pd.DataFrame(np.zeros((len(mat_dfs),len(mat_dfs))))\n",
    "for i in mat_dfs:\n",
    "    idf = mat_dfs[i][-1].drop(6, axis=1)\n",
    "    idf = [float(x) for x in idf.values.flatten()]\n",
    "    for j in mat_dfs:\n",
    "        jdf = mat_dfs[j][-1].drop(6, axis=1)\n",
    "        jdf = [float(x) for x in jdf.values.flatten()]\n",
    "        bayenv_hm.ix[i,j] = sp.stats.pearsonr(idf, jdf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_mats = []\n",
    "for i in mat_dfs:\n",
    "    final_mats.append(mat_dfs[i][-1].drop(6, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_mat = pd.DataFrame(index=final_mats[0].index, columns=final_mats[1].columns)\n",
    "for i in range(len(mean_mat)):\n",
    "    for j in range(len(mean_mat)):\n",
    "        vals = []\n",
    "        for k in range(len(final_mats)):\n",
    "            vals.append(final_mats[k].ix[i, j])\n",
    "        vals = [float(x) for x in vals]\n",
    "        mean_mat.ix[i,j] = np.mean(vals)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_corr(idf, jdf):\n",
    "    idf = [float(x) for x in idf.values.flatten()]\n",
    "    jdf = [float(x) for x in jdf.values.flatten()]\n",
    "    return sp.stats.pearsonr(idf, jdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fm in final_mats:\n",
    "    print(mat_corr(mean_mat, fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_matrix = os.path.join(basedir, \"matrix_chain_avg.out\")\n",
    "mean_mat.to_csv(out_matrix, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_indv = [x.drop(\"blank\", axis=1) for x in snpsfile_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in snp_indv:\n",
    "    s['snp_name'] = s.apply(lambda x: \"_\".join(x.name.split(\"_\")[0:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_bayenv_files(dirname, snp_indv_data):\n",
    "    bayenv = []\n",
    "    for i, s in enumerate(snp_indv_data):\n",
    "        if i == 0:\n",
    "            continue            \n",
    "        temp = []\n",
    "        bayenv.append(temp)\n",
    "        outdir = os.path.join(analysis_dir[i], dirname)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "        for group, data in s.groupby(\"snp_name\"):\n",
    "            bayenv_file = os.path.join(outdir, \"%s.txt\" % group)\n",
    "            temp.append(bayenv_file)\n",
    "            data = pd.DataFrame(data)\n",
    "            data['blank'] = \"\"\n",
    "            data = data.drop(\"snp_name\", axis=1)\n",
    "            data.to_csv(bayenv_file, index=False, header=False, sep=\"\\t\")\n",
    "    return bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayenv = write_bayenv_files(\"bayenv_runs/infiles\", snp_indv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-04T14:28:48.724905",
     "start_time": "2016-03-04T14:28:48.155352"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = !find {os.path.join(analysis_dir[1], \"bayenv_runs/infiles\")} -name \"*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-04T14:28:48.739677",
     "start_time": "2016-03-04T14:28:48.730062"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = [bayenv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-04T14:28:55.540723",
     "start_time": "2016-03-04T14:28:55.536131"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv.insert(0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-04T14:28:56.382054",
     "start_time": "2016-03-04T14:28:56.375804"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bayenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-04T14:28:57.857014",
     "start_time": "2016-03-04T14:28:57.853020"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_jobs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:07.770219",
     "start_time": "2016-03-05T14:14:07.765243"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_chains = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:09.215876",
     "start_time": "2016-03-05T14:14:09.209585"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks = int(np.round(len(bayenv[1])/bayenv_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:09.672007",
     "start_time": "2016-03-05T14:14:09.665173"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:11.425433",
     "start_time": "2016-03-05T14:14:11.416463"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_rundir = os.path.join(analysis_dir_imp, \"bayenv_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:13.935215",
     "start_time": "2016-03-05T14:14:13.925181"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_bayenv_dirs(base, n):\n",
    "    for i in range(n):\n",
    "        os.makedirs(os.path.join(base, \"chain_%d\" % i), exist_ok=True)\n",
    "\n",
    "\n",
    "make_bayenv_dirs(bayenv_rundir, num_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:23.439158",
     "start_time": "2016-03-05T14:14:23.434673"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngen = 5e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:08:47.892238",
     "start_time": "2016-03-25T12:08:47.879146"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bayenv_seed():\n",
    "    s = int(random.getrandbits(16))\n",
    "    if s == 0:\n",
    "        return get_bayenv_seed()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:14:41.537433",
     "start_time": "2016-03-05T14:14:26.791521"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrapper = \"ipython ~/ipynb/gypsy_moth/run_bayenv.ipy\"\n",
    "bayenv_exe = \"/home/cfriedline/g/src/bayenv2_public/bayenv2\"\n",
    "bayenv_opt = \"-i snpfile -m matrixfile -e environfile -p 6 -k 100000 -n 19 -t -X -c -f -r rand\"\n",
    "matrix_file = \"matrix_chain_avg.out\"\n",
    "environfile = \"environfile\"\n",
    "for i, bayenv_files in enumerate(bayenv):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    thedir = analysis_dir[i]\n",
    "    shutil.copy(os.path.join(thedir, matrix_file), os.path.dirname(bayenv_files[0]))\n",
    "    shutil.copy(os.path.join(thedir, environfile), os.path.dirname(bayenv_files[0]))\n",
    "    chunks=[bayenv_files[x:x+num_chunks] for x in range(0, len(bayenv_files), num_chunks)]\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(os.path.dirname(bayenv_files[0]), \"bayenv_parallel_%d\" % i), \"w\") as o:\n",
    "            for bayenv_file in chunk:\n",
    "                for chain in range(num_chains):\n",
    "                    outdir = os.path.join(bayenv_rundir, \"chain_%d\" % chain)\n",
    "                    bayenv_cmd = \" \".join([bayenv_exe, bayenv_opt]).split()\n",
    "                    bayenv_cmd[2] = os.path.basename(bayenv_file)\n",
    "                    bayenv_cmd[4] = matrix_file\n",
    "                    bayenv_cmd[6] = environfile\n",
    "                    bayenv_cmd[-1] = get_bayenv_seed()\n",
    "                    bayenv_cmd[10] = int(ngen)\n",
    "                    outfile = os.path.basename(bayenv_file).replace(\".txt\",\"\")\n",
    "                    bayenv_cmd.append(\"-o %s\" % os.path.join(outdir, outfile))\n",
    "                    o.write(\"%s '\" % wrapper)\n",
    "                    o.write(\"%s\" % \" \".join([str(x) for x in bayenv_cmd]))\n",
    "                    o.write(\"'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:24.412647",
     "start_time": "2016-03-05T14:52:24.383025"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_qsub_files(bayenv_parallel, dirname):\n",
    "    files = []\n",
    "    for i, f in enumerate(bayenv_parallel):\n",
    "        d = os.path.join(analysis_dir[1], dirname)\n",
    "        qsub_file = os.path.join(d, \"qsub_%d.sh\" % i)\n",
    "        files.append(qsub_file)\n",
    "        with open(qsub_file, \"w\") as o:\n",
    "            os.chmod(o.name, 0o744)\n",
    "            #print(o.name)\n",
    "            o.write(\"%s\\n\" % \"\\n\".join([\"#!/bin/bash\", \n",
    "                                        \"#$ -N bayenv%d\" % i,\n",
    "                                        \"#$ -V\",\n",
    "                                        \"#$ -cwd\",\n",
    "                                       \"#$ -pe smp 30\",\n",
    "                                       \"#$ -j y\",\n",
    "                                        \"#$ -q all.q\",\n",
    "                                        \"#$ -e ../bayenv%d.err\" % i,\n",
    "                                        \"#$ -o ../bayenv%d.out\" % i,\n",
    "                                        \"unset module\",\n",
    "                                        \"echo \\\"Running on $HOSTNAME\\\"\",\n",
    "                                       \"cat %s | ~/bin/parallel -j 30 --delay 1 --\" % f]))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:51:11.853128",
     "start_time": "2016-03-05T14:51:11.836243"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_infile_dir = os.path.join(bayenv_rundir, \"infiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:51:15.354638",
     "start_time": "2016-03-05T14:51:12.149220"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_parallel = !ls {bayenv_infile_dir} | grep parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:51:15.367013",
     "start_time": "2016-03-05T14:51:15.358682"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bayenv_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:51:16.431819",
     "start_time": "2016-03-05T14:51:16.394630"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qsub_files = write_qsub_files(bayenv_parallel, bayenv_infile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:27.156888",
     "start_time": "2016-03-05T14:52:26.960788"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat /home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/bayenv_runs/infiles/qsub_0.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:30.199030",
     "start_time": "2016-03-05T14:52:30.178951"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, ad in enumerate(analysis_dir):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    d = bayenv_infile_dir\n",
    "    with open(os.path.join(d, \"qsub_runner.sh\"), \"w\") as o:\n",
    "        os.chmod(o.name, 0o744)\n",
    "        o.write(\"#!/bin/bash\\n\")\n",
    "        o.write(\"unset module\\n\")\n",
    "        for q in qsub_files:\n",
    "            o.write(\"qsub %s\\n\" % q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:30.505499",
     "start_time": "2016-03-05T14:52:30.330191"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!head -n5 {os.path.join(d, \"qsub_runner.sh\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:30.696824",
     "start_time": "2016-03-05T14:52:30.516722"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qhost = !qhost | grep godel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-05T14:52:45.084407",
     "start_time": "2016-03-05T14:52:31.404610"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for elem in qhost:\n",
    "    host = elem.split()[0]\n",
    "    if not host in ['godel200',\n",
    "                   'godel21',\n",
    "                   'godel37']:\n",
    "        !ssh {host} pkill -9 bayenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bayenv jobs\n",
    "\n",
    "```bash\n",
    "cd ~/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/bayenv_runs/infiles\n",
    "./qsub_runner.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-10T12:47:50.334262",
     "start_time": "2016-03-10T12:47:50.319277"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_rundir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:14:20.003005",
     "start_time": "2016-03-25T12:13:55.175731"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_progress():\n",
    "    progress = {}\n",
    "    for i in range(num_chains):\n",
    "        d = os.path.join(bayenv_rundir, \"chain_%d\" % i)\n",
    "        files = [os.path.join(d, x) for x in scandir.listdir(d) if \".bf\" in x]\n",
    "        print(d, len(files))\n",
    "        for f in files:\n",
    "            name = os.path.basename(f)\n",
    "            chain = os.path.basename(os.path.dirname(f))\n",
    "            if not name in progress:\n",
    "                progress[name] = []\n",
    "            progress[name].append(chain)\n",
    "    return progress\n",
    "\n",
    "def progress_stats(progress):\n",
    "    c = Counter()\n",
    "    inprogress = set()\n",
    "    for snp in progress:\n",
    "        if len(progress[snp]) < 5:\n",
    "            inprogress.add(snp)\n",
    "        c[len(progress[snp])] += 1\n",
    "    return c, sorted(inprogress), progress\n",
    "\n",
    "progress = check_progress()\n",
    "c, inprog, prog = progress_stats(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:04:00.042216",
     "start_time": "2016-03-25T12:03:57.511939"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallel_files = !ls {os.path.join(bayenv_rundir, \"infiles\")}/bayenv_parallel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:04:14.226086",
     "start_time": "2016-03-25T12:04:01.940095"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_parallel_file(snp):\n",
    "    snp = snp.replace(\".bf\", \"\")\n",
    "    cmd = \"grep %s %s/bayenv_parallel*\" % (snp, bayenv_infile_dir)\n",
    "    res = !$cmd\n",
    "    return res\n",
    "\n",
    "leftovers = []\n",
    "for snp in inprog:\n",
    "    completed = prog[snp]\n",
    "    res = get_parallel_file(snp)\n",
    "    for elem in res:\n",
    "        f, cmd = elem.split(\":\")\n",
    "        chain = os.path.basename(os.path.dirname(cmd.split()[-1]))\n",
    "        if chain not in completed:\n",
    "            leftovers.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:04:35.041758",
     "start_time": "2016-03-25T12:04:35.034399"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leftovers, len(leftovers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random seed fixing\n",
    "\n",
    "for some reason (me), some random seeds were randomly set to zero, let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:11:04.620292",
     "start_time": "2016-03-25T12:11:04.588425"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_makeup = os.path.join(bayenv_infile_dir, \"bayenv_makeup.txt\")\n",
    "with open(bayenv_makeup, \"w\") as o:\n",
    "    for elem in leftovers:\n",
    "        cmd = elem.split()\n",
    "        if (int(cmd[20])) == 0:\n",
    "            cmd[20] = str(get_bayenv_seed())\n",
    "        print(cmd)\n",
    "        elem = \" \".join(cmd)\n",
    "        print(elem)\n",
    "        o.write(\"%s\\n\" % elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayenv makeup job\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "# makeup.sh\n",
    "#$ -N bayenv_makeup\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -pe smp 30\n",
    "#$ -j y\n",
    "#$ -q all.q\n",
    "#$ -e ../bayenv_makeup.err\n",
    "#$ -o ../bayenv_makeup.out\n",
    "unset module\n",
    "echo \"Running on $HOSTNAME\"\n",
    "cat bayenv_makeup.txt | ~/bin/parallel -j 30 --delay 1 --\n",
    "```\n",
    "\n",
    "```\n",
    "cd /gpfs_fs/home/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/bayenv_runs/infiles\n",
    "qsub makeup.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T12:14:26.184876",
     "start_time": "2016-03-25T12:14:26.168288"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(leftovers), c, inprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:31:08.736942",
     "start_time": "2016-03-25T14:31:08.722235"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vartypes = ['bf', 'rho', 'rs']\n",
    "bf_cols = []\n",
    "for b in bioclim[0].index:\n",
    "    for v in vartypes:\n",
    "        bf_cols.append(\"%s_%s\" % (b, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:34:27.672264",
     "start_time": "2016-03-25T14:34:27.667743"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chain_dirs = [os.path.join(bayenv_rundir, \"chain_%d\" % x) for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:48:25.741056",
     "start_time": "2016-03-25T14:48:12.717830"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtxs = {}\n",
    "bfs = {}\n",
    "for d in chain_dirs:\n",
    "    name = os.path.basename(d)\n",
    "    files = [os.path.join(d, x) for x in scandir.listdir(d)]\n",
    "    xtxs[name] = [x for x in files if x.endswith(\".xtx\")]\n",
    "    bfs[name] = [x for x in files if x.endswith(\".bf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:50:31.305022",
     "start_time": "2016-03-25T14:50:31.296473"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[len(bfs[x]) for x in bfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T14:54:02.855652",
     "start_time": "2016-03-25T14:54:02.751601"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")\n",
    "dv = rc[:]\n",
    "lv = rc.load_balanced_view()\n",
    "len(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:01:40.055341",
     "start_time": "2016-03-25T15:01:40.013634"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_bayenv(args):\n",
    "    f, key, cols, chain = args\n",
    "    import pandas as pd\n",
    "    key = key.lower()\n",
    "    df = pd.read_csv(f, sep=\"\\t\", header=None, index_col=0)\n",
    "    if key == 'xtx':\n",
    "        df.columns = ['xtx']\n",
    "    elif key == \"bf\":\n",
    "        df = df.drop(df.columns[-1], axis=1)\n",
    "    df.index = [\"%s-%s\" % (x.replace(\".txt\", \"\"), chain) for x in df.index]\n",
    "    df.index.name = \"SNP\"\n",
    "    if cols:\n",
    "        df.columns=cols\n",
    "    return df.ix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:01:41.515080",
     "start_time": "2016-03-25T15:01:40.943958"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv['read_bayenv'] = read_bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:02:19.636763",
     "start_time": "2016-03-25T15:01:43.396827"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_args = []\n",
    "for chain in bfs:\n",
    "    for x in bfs[chain]:\n",
    "        bf_args.append((x, 'bf', bf_cols, chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:03:55.608416",
     "start_time": "2016-03-25T15:03:55.594223"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bf_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:04:05.851047",
     "start_time": "2016-03-25T15:04:03.721718"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs = dv.map_async(read_bayenv, bf_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:11:53.081355",
     "start_time": "2016-03-25T15:11:53.063748"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs.progress, bf_dfs.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:11:55.500793",
     "start_time": "2016-03-25T15:11:55.491270"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_dfs = bf_dfs.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-25T15:11:57.523640",
     "start_time": "2016-03-25T15:11:57.507006"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-03-25T19:12:05.991Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf = pd.concat([pd.DataFrame(x).T for x in bf_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-03-25T19:12:11.000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(xtx)\n",
    "ax.set_xlabel(\"XtX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = xtx.join(bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_dir = os.path.join(analysis_dir_imp, \"bayenv\")\n",
    "joined.to_csv(os.path.join(bayenv_dir, \"bayenv_results.txt\"), \n",
    "             sep=\"\\t\", \n",
    "             header=True,\n",
    "             index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bf_vs_xtx(df, imputed, dir_name):\n",
    "    num_figs = len(df.columns)-1\n",
    "    print(num_figs)\n",
    "    plt.gcf().set_size_inches(20,20)\n",
    "    for i in range(num_figs):\n",
    "        if i > 0:\n",
    "            plt.subplot(5,4,i)\n",
    "            plt.title(\"%s (%s)\" % (df.columns[i].split(\"_\")[0], imputed))\n",
    "            plt.xlabel(\"BF\")\n",
    "            plt.ylabel(df.columns[0])\n",
    "            plt.scatter(df.ix[:,i],df.ix[:,0])\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "                    wspace=.5, hspace=.5)\n",
    "    plt.savefig(\"%s.pdf\" % os.path.join(dir_name, \"bf_vs_xtx_%s\" % imputed))\n",
    "    plt.show()\n",
    "plot_bf_vs_xtx(pd.DataFrame(xtx).join(bf[[x for x in bf if 'bf' in x]]), \"imputed\", analysis_dir[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_xtx = np.median(joined.xtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mad = np.median(np.abs(joined.xtx-med_xtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtx_outliers = []\n",
    "impute_status = [\"imputed\"]\n",
    "for i, res in enumerate([joined]):\n",
    "    XtX = res.xtx\n",
    "    M = np.median(XtX)    \n",
    "    MAD = sm.robust.mad(XtX)\n",
    "    lower_cutoff = M-(3*MAD)\n",
    "    upper_cutoff = M+(3*MAD)\n",
    "    lower_snps = sorted(XtX[XtX<lower_cutoff].index.tolist())\n",
    "    upper_snps = sorted(XtX[XtX>upper_cutoff].index.tolist())\n",
    "    percent_cutoff = np.percentile(XtX, 99)\n",
    "    percent_cutoff_outliers = sorted(XtX[XtX > percent_cutoff].index.tolist())\n",
    "    o = pd.DataFrame([impute_status[i], \n",
    "                      M,\n",
    "                      MAD,\n",
    "                      lower_cutoff, \n",
    "                      upper_cutoff, \n",
    "                      len(lower_snps), \n",
    "                      len(upper_snps), \n",
    "                      lower_snps, \n",
    "                      upper_snps,\n",
    "                     percent_cutoff, \n",
    "                      len(percent_cutoff_outliers),\n",
    "                      percent_cutoff_outliers]).T\n",
    "    o.columns = ['state', 'median_XtX', 'MAD', 'lower_cutoff', 'upper_cutoff', 'n_lower', 'n_upper', \n",
    "                'lower_snps', 'upper_snps', 'percent_cutoff_XtX', 'n_percent_cutoff', '99th_snps']\n",
    "    xtx_outliers.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(xtx_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_outliers = {}\n",
    "env_cols = [x for x in joined if '_bf' in x or '_rho' in x]\n",
    "env_df = joined[env_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bio, data in env_df.groupby(lambda x: x.split(\"_\")[0], axis=1):\n",
    "    env_outliers[bio] = []\n",
    "    cutoff = data.apply(lambda x: x.quantile(0.99))\n",
    "    for c in cutoff.index:\n",
    "        outliers = set(data[data[c] >= cutoff[c]].index.tolist())\n",
    "        env_outliers[bio].append(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_outliers_isect = env_outliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bio in env_outliers_isect:\n",
    "    snplist = env_outliers_isect[bio]\n",
    "    env_outliers_isect[bio] = snplist[0].intersection(snplist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(bayenv_dir, \"env_outliers_isect.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(env_outliers_isect, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bayenv convergence testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_bf = joined[[x for x in joined if '_bf' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_bf_test = joined_bf[joined_bf.BIO10_bf > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_bf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_seeds = {\n",
    "    \"jtg7180005921436f_7180005479371f_7180005921437f_7180005921438f_5770\": 17046,\n",
    "    \"jtg7180005937218f_7180005937219f_4892\": 54214\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_indv_test = snp_indv.copy()\n",
    "snp_indv_test[0] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_indv_test[1] = snp_indv_test[1][snp_indv_test[1].snp_name.isin(high_bf_test.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_files = write_bayenv_files(\"bayenv_test\", snp_indv_test)\n",
    "test_files.insert(0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_exe = \"/home/cfriedline/g/src/bayenv2_public/bayenv2\"\n",
    "bayenv_opt = \"-i snpfile -m matrixfile -e environfile -p 6 -k 100000 -n 19 -t -X -c -f -r rand -o outfile\"\n",
    "\n",
    "max_cpu = 30\n",
    "cpu = 0\n",
    "for i, bayenv_files in enumerate(test_files):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    thedir = analysis_dir[i]\n",
    "    shutil.copy(os.path.join(thedir, \"matrix_last.out\"), os.path.dirname(bayenv_files[0]))\n",
    "    shutil.copy(os.path.join(thedir, \"environfile\"), os.path.dirname(bayenv_files[0]))\n",
    "    chunks=[bayenv_files[x:x+num_chunks] for x in range(0, len(bayenv_files), num_chunks)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(os.path.dirname(bayenv_files[0]), \"bayenv_parallel_%d\" % i), \"w\") as o:\n",
    "            for bayenv_file in chunk:\n",
    "                seed = int(random.getrandbits(16))\n",
    "                for i in range(100000, 10200000, 500000):\n",
    "                    if cpu == max_cpu:\n",
    "                        cpu = 0\n",
    "                    bayenv_cmd = \" \".join([bayenv_exe, bayenv_opt]).split()\n",
    "                    bayenv_cmd[2] = os.path.basename(bayenv_file)\n",
    "                    bayenv_cmd[4] = \"matrix_last.out\"\n",
    "                    bayenv_cmd[6] = \"environfile\"\n",
    "                    #bayenv_cmd[18] = int(random.getrandbits(16)) # set random seed\n",
    "                    #bayenv_cmd[18] = original_seeds[os.path.basename(bayenv_file).replace(\".txt\",\"\")]\n",
    "                    bayenv_cmd[18] = seed\n",
    "                    bayenv_cmd[14] = \"\" #discard xtx\n",
    "                    bayenv_cmd[10] = i\n",
    "                    bayenv_cmd[-1] = \"%s-%d\" % (os.path.basename(bayenv_file).replace(\".txt\",\"\"), i)\n",
    "                    bayenv_cmd.insert(0, \"taskset -c %d\" % cpu)\n",
    "                    o.write(\"%s\\n\" % \" \".join([str(x) for x in bayenv_cmd]))   \n",
    "                    cpu += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_parallel = !find {os.path.join(analysis_dir[1], \"bayenv_test\")} | grep parallel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_qsub_files(test_parallel, \"bayenv_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run bayenv\n",
    "\n",
    "```\n",
    "qsub qsub_0.sh\n",
    "```\n",
    "\n",
    "Notes:\n",
    "* bayenv_test_3 - original fixed seed, change generations\n",
    "* bayenv_test_2 - change seed for each # of generations\n",
    "* bayenv_test_1 - change seed for each # of generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_test_bayenv(args):\n",
    "        f, key, cols = args\n",
    "        import pandas as pd\n",
    "        key = key.lower()\n",
    "        df = pd.read_csv(f, sep=\"\\t\", header=None, index_col=0)\n",
    "        if key == 'xtx':\n",
    "            df.columns = ['xtx']\n",
    "        elif key == \"bf\":\n",
    "            df = df.drop(df.columns[-1], axis=1)\n",
    "        base = os.path.basename(f).replace(\".bf\", \"\")\n",
    "        base_data = base.split(\"-\")\n",
    "        assert len(df) == 1\n",
    "        df.index = [base]\n",
    "        df.index.name = \"SNP\"\n",
    "        if cols:\n",
    "            df.columns=cols\n",
    "\n",
    "        df['snp'] = base_data[0]\n",
    "        df['ngen'] = int(base_data[1])\n",
    "        return df.ix[0,:]\n",
    "\n",
    "all_tests = {}\n",
    "    \n",
    "for test_dir in [\"bayenv_test\", \"bayenv_test_1\", \"bayenv_test_2\", \"bayenv_test_3\"]:\n",
    "    test_bfs = !ls {analysis_dir[1]}/{test_dir} | grep '.bf'\n",
    "    test_bfs = sorted([os.path.join(analysis_dir[1] + test_dir, x) for x in test_bfs])\n",
    "\n",
    "    test_bf_args = [(x, 'bf', bf_cols) for x in test_bfs]\n",
    "\n",
    "    test_bfs = []\n",
    "    for x in test_bf_args:\n",
    "        test_bfs.append(read_test_bayenv(x))\n",
    "\n",
    "    test_joined = pd.concat([pd.DataFrame(x).T for x in test_bfs])[['BIO10_bf', 'snp', 'ngen']]\n",
    "    all_tests[test_dir] = test_joined\n",
    "    for snp, data in test_joined.groupby('snp'):\n",
    "        sns.regplot(\"ngen\", \"BIO10_bf\", data=data, fit_reg=False)\n",
    "        plt.title(\"%s (%s)\" % (snp, test_dir))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in all_tests:\n",
    "    d = all_tests[key]\n",
    "    d.index = [\"%s-%s\" % (key, x) for x in d.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([all_tests[x] for x in all_tests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df['test'] = all_df.apply(lambda x: x.name.split(\"-\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "box_data = {}\n",
    "for key, data in all_df.groupby((\"snp\")):\n",
    "    g = sns.boxplot(x=\"ngen\", y=\"BIO10_bf\", data=data)\n",
    "    g.set_yscale('log')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
