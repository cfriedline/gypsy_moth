{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import dill\n",
    "import random\n",
    "import cyvcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/\"\n",
    "snp_file_gz = \"isect.vcf.gz.sorted.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write piMASS files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "def get_dosage(GP):\n",
    "    total = 0\n",
    "    if sum(GP) == 0:\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        pvals = [convert_GQ_to_p(x) for x in GP]\n",
    "        pval_sum = np.sum(pvals)\n",
    "        pvals = [x/pval_sum for x in pvals]\n",
    "        for i, val in enumerate(pvals):\n",
    "            total += val*i\n",
    "            \n",
    "    return np.round(total, 3)\n",
    "\n",
    "def get_GP(sample, flip):\n",
    "    if flip:\n",
    "        return sample['GT'], sample['GP'][::-1], \"flipped\"\n",
    "    else:\n",
    "        return sample['GT'], sample['GP'], \"\"\n",
    "        \n",
    "\n",
    "def get_major_minor(snp):\n",
    "    d = snp.name.split(\"_\")\n",
    "    contig = \"_\".join(d[0:-1])\n",
    "    loc = int(d[-1])\n",
    "    minor_major = []\n",
    "    for gt in snp:\n",
    "        if isinstance(gt, float):\n",
    "            pass\n",
    "        else:\n",
    "            mm = \"%s%s\" % (gt[0],gt[-1])\n",
    "            if not mm in minor_major and mm[0] != mm[1]:\n",
    "                minor_major.append(mm)\n",
    "    mm = minor_major[0]\n",
    "    global thesnp\n",
    "    for x in reader.fetch(contig, loc-1, loc):\n",
    "        thesnp = x\n",
    "        break\n",
    "    #assert isinstance(thesnp, vcf.model._Record)\n",
    "    snp_mm = \"%s%s\" % (thesnp.REF, thesnp.ALT[0])\n",
    "    flip = False\n",
    "    if mm != snp_mm:\n",
    "        flip = True\n",
    "    dosages = []\n",
    "    samples = []\n",
    "    for sample in thesnp.samples:\n",
    "        gt, gp, flipped = get_GP(sample, flip)\n",
    "        dosages.append(get_dosage(gp))\n",
    "        samples.append(sample.sample)\n",
    "    data = [mm[0], mm[1]]\n",
    "    index = [\"minor\", \"major\"]\n",
    "    index.extend(samples)\n",
    "    data.extend(dosages)\n",
    "    ret = pd.Series(data, index=index)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = HDFStoreHelper(os.path.join(analysis_dir, \"isect.hd5\"))\n",
    "hdf_all = HDFStoreHelper(os.path.join(analysis_dir, \"gypsy_samtools12_snps.vcf.gz.hd5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf_all.get_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdf.get_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno = hdf_all.get(\"pca_std_pheno\")[[\"Population\",\n",
    "                                             \"Number\",\n",
    "                                             \"Mass\",\"Pupual Duration\", \"Total Dev Time\"]]\n",
    "pimass_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = hdf.get('pca_x')\n",
    "pca_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = pimass_pheno.join(pca_x, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno_pca = pca_std_pheno[[x for x in pca_std_pheno if \"PC\" in x or 'Mass' in x or 'Pupual' in x or 'Total Dev' in x]]\n",
    "pimass_pheno_pca.columns = [x.replace(\" \", \"_\") for x in pimass_pheno_pca.columns]\n",
    "pimass_pheno_pca.index = [x for x in pimass_pheno_pca.index]\n",
    "phenos = [\"Mass\", \"Pupual_Duration\", \"Total_Dev_Time\"]\n",
    "for p in phenos:\n",
    "    mod = smf.ols(formula=\"%s~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8\" % p, data=pimass_pheno_pca)\n",
    "    res = mod.fit()\n",
    "    col = \"%s_resid\" % p\n",
    "    col = col.lower()\n",
    "    pimass_pheno[col] = res.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = hdf.get(\"z12_swapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "def get_correct_name(row, trans):\n",
    "    trans[row.name] = \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "\n",
    "name_translation = {}\n",
    "translation_df.apply(get_correct_name, args=(name_translation,), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readvcf = open(os.path.join(analysis_dir, snp_file_gz))\n",
    "reader = cyvcf.VCFReader(readvcf)\n",
    "gt_base_data = {}\n",
    "gt_ref_alt = {}\n",
    "at = 0\n",
    "for snp in reader:\n",
    "    snp_id = \"%s_%d\" % (snp.CHROM, snp.POS)\n",
    "    gt_ref_alt[snp_id] = {'ref': snp.REF, 'alt': snp.ALT[0]}\n",
    "    for sample in snp.samples:\n",
    "        if not snp_id in gt_base_data:\n",
    "            gt_base_data[snp_id] = {}\n",
    "        sample_name = name_translation[sample.sample]\n",
    "        bases = sample.gt_bases\n",
    "        gt_base_data[snp_id][sample_name] = bases\n",
    "    at += 1\n",
    "    if at % 1000 == 0:\n",
    "        print at\n",
    "gt_base_df = pd.DataFrame(gt_base_data)\n",
    "readvcf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_gt_alleles(gt, het):   \n",
    "    if isinstance(gt, float): #NaN\n",
    "        return np.NaN\n",
    "    if gt is None:\n",
    "        return np.NaN\n",
    "    if gt[0] == gt[-1]:\n",
    "        return gt\n",
    "    else:\n",
    "        return het # already in minor/major\n",
    "    \n",
    "def swap_gt(snp):\n",
    "    vc = snp.value_counts()\n",
    "    counts = {}\n",
    "    for v in vc.index:\n",
    "        if not v[0] in counts:\n",
    "            counts[v[0]] = 0.0\n",
    "        if not v[-1] in counts:\n",
    "            counts[v[-1]] = 0.0\n",
    "        counts[v[0]] += vc[v]\n",
    "        counts[v[-1]] += vc[v]\n",
    "    counts2 = sorted(counts.items(), key=operator.itemgetter(1)) #e.g., [('A', 110.0), ('G', 236.0)]\n",
    "    minor = counts2[0][0]\n",
    "    major = counts2[1][0]\n",
    "    het = \"%s/%s\" % (minor, major)\n",
    "    gt_ref_alt[snp.name]['minor'] = minor\n",
    "    gt_ref_alt[snp.name]['major'] = major\n",
    "    return snp.apply(swap_gt_alleles, args=(het,))\n",
    "gt_base_df_swapped = gt_base_df.apply(swap_gt)\n",
    "gt_base_df_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_GQ_to_p(q):\n",
    "    return pow(10,(q/-10.0))\n",
    "\n",
    "def get_dosage(GP):\n",
    "    total = 0\n",
    "    if GP is None:\n",
    "        return \"NA\"\n",
    "    if sum(GP) == 0:\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        pvals = [convert_GQ_to_p(x) for x in GP]\n",
    "        pval_sum = np.sum(pvals)\n",
    "        pvals = [x/pval_sum for x in pvals]\n",
    "        for i, val in enumerate(pvals):\n",
    "            total += val*i\n",
    "            \n",
    "    return np.round(total, 3)\n",
    "\n",
    "def get_GP(sample, flip):\n",
    "    if sample['GT'] is None:\n",
    "        return None, [0,0,0], \"\"\n",
    "    if flip:\n",
    "        return sample['GT'], sample['GP'][::-1], \"flipped\"\n",
    "    else:\n",
    "        return sample['GT'], sample['GP'], \"\"\n",
    "        \n",
    "\n",
    "def get_major_minor(snp, reader):\n",
    "    d = snp.name.split(\"_\")\n",
    "    loc = int(d[-1])\n",
    "    contig = \"_\".join(d[0:-1])\n",
    "    minor_major = \"%s%s\" % (gt_ref_alt[snp.name]['minor'], gt_ref_alt[snp.name]['major'])\n",
    "    ref_alt = \"%s%s\" % (gt_ref_alt[snp.name]['ref'], gt_ref_alt[snp.name]['alt'])\n",
    "    flip = False\n",
    "    if minor_major != ref_alt:\n",
    "        flip = True\n",
    "    dosages = []\n",
    "    samples = []\n",
    "    thesnp = list(reader.fetch(contig, loc, loc))[0]\n",
    "    for sample in thesnp.samples:\n",
    "        gt, gp, flipped = get_GP(sample, flip)\n",
    "        dosages.append(get_dosage(gp))\n",
    "        samples.append(sample.sample)\n",
    "    data = [minor_major[0], minor_major[1]]\n",
    "    index = [\"minor\", \"major\"]\n",
    "    index.extend(samples)\n",
    "    data.extend(dosages)\n",
    "    ret = pd.Series(data, index=index)\n",
    "    return ret\n",
    "h = open(os.path.join(analysis_dir, snp_file_gz))\n",
    "reader = cyvcf.VCFReader(h)\n",
    "pimass_gt = gt_base_df_swapped.apply(get_major_minor, args=(reader,)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno = pimass_pheno.reindex(index=gt_base_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i pimass_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "massx = qqnorm(pimass_pheno$mass_resid, plot.it=F)$x\n",
    "tdtx = qqnorm(pimass_pheno$total_dev_time_resid, plot.it=F)$x\n",
    "pdx = qqnorm(pimass_pheno$pupual_duration_resid, plot.it=F)$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno['massx'] = r('massx')\n",
    "pimass_pheno['tdtx'] = r('tdtx')\n",
    "pimass_pheno['pdx'] = r('pdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_pheno.massx.to_csv(os.path.join(analysis_dir, \"pimass_mass.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.tdtx.to_csv(os.path.join(analysis_dir, \"pimass_tdt.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.pdx.to_csv(os.path.join(analysis_dir, \"pimass_pd.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "pimass_pheno.to_csv(os.path.join(analysis_dir, \"pimass_pheno.txt\"),\n",
    "                                     index=True,\n",
    "                                     header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_contigs = {}\n",
    "with open(os.path.join(analysis_dir, \"pimass_loc.txt\"), \"w\") as o:    \n",
    "    for x in pimass_gt.index:\n",
    "        data = x.split(\"_\")\n",
    "        contig = \"_\".join(data[0:-1])\n",
    "        pos = data[-1]\n",
    "        if not contig in pimass_contigs:\n",
    "            pimass_contigs[contig] = []\n",
    "        pimass_contigs[contig].append(pos)\n",
    "    \n",
    "    chrom_id = 1\n",
    "    for contig, positions in pimass_contigs.items():\n",
    "        for p in positions:\n",
    "            o.write(\"%s_%s\\t%s\\t%d\\n\" % (contig, p, p, chrom_id))\n",
    "        chrom_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def create_pimass_run_files(num_runs):\n",
    "    phenos = [\"mass\", 'tdt', 'pd']\n",
    "    for p in phenos:\n",
    "        with open(os.path.join(analysis_dir, \"pimass_%s_run.txt\" % p), \"w\") as o:\n",
    "            for i in xrange(num_runs):\n",
    "                cmd = \"~/g/src/pimass/pimass-lin \\\n",
    "-g pimass_gt.txt \\\n",
    "-p pimass_%s.txt -pos pimass_loc.txt \\\n",
    "-o pimass_%s_out_%d \\\n",
    "-w 1000000 \\\n",
    "-s 10000000 \\\n",
    "-num 500 \\\n",
    "-smin 1 \\\n",
    "-smax 100 \\\n",
    "-hmin 0.01 \\\n",
    "-hmax 0.9 \\\n",
    "-pmin 1 \\\n",
    "-pmax 1000 \\\n",
    "-r %.0f\" % (p, p, i, int(random.getrandbits(32)))\n",
    "                o.write(\"%s\\n\" % cmd) \n",
    "                \n",
    "\n",
    "\n",
    "def create_qsub_files():\n",
    "    files = !ls {analysis_dir}*run.txt\n",
    "    for f in files:\n",
    "        with open(\"%s_qsub.sh\" % f, \"w\") as o:\n",
    "            o.write(\"\"\"#!/bin/bash\n",
    "#$ -j y\n",
    "#$ -V\n",
    "#$ -N pimass_%s\n",
    "#$ -cwd\n",
    "parallel -a %s\n",
    "\"\"\" % (os.path.basename(f).split(\"_\")[1], f))\n",
    "            \n",
    "create_pimass_run_files(10)\n",
    "create_qsub_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## run piMASS\n",
    "\n",
    "```bash\n",
    "./run_pimass.sh\n",
    "mv output output_comeault_isect\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "assembly = \"/home/cfriedline/gpfs/assemblies/gypsy/masurca_new/CA/10-gapclose/genome.ctg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "filedir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/output_comeault_isect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "hide_input": false,
    "init_cell": true,
    "locked": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def dump_session():\n",
    "    dill.settings['recurse'] = True\n",
    "    dill.settings['fmode'] = dill.HANDLE_FMODE\n",
    "    dill.dump_session(filename=os.path.join(filedir, \"pimass.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_files = {}\n",
    "mcmc_files = {}\n",
    "gamma_files = {}\n",
    "snp_files = {}\n",
    "for root, dirs, files in scandir.walk(filedir):\n",
    "    for f in files:\n",
    "        d = f.split(\"_\")\n",
    "        pheno = d[1]\n",
    "        if not pheno in path_files:\n",
    "            path_files[pheno] = []\n",
    "            mcmc_files[pheno]= []\n",
    "            gamma_files[pheno] = []\n",
    "            snp_files[pheno] = []\n",
    "        if 'path' in f:\n",
    "            path_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'mcmc' in f:\n",
    "            mcmc_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'gamma' in f:\n",
    "            gamma_files[pheno].append(os.path.join(root, f))\n",
    "        elif 'snp' in f:\n",
    "            snp_files[pheno].append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(coda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = r('mcmc')\n",
    "mcmc_list = r('mcmc.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "phenos = [\"mass\", \"pd\", \"tdt\"]\n",
    "for pheno in phenos:\n",
    "    frames = [pd.read_csv(x,sep=\"\\t\") for x in path_files[pheno]]\n",
    "    frames = [x.ix[:,:-1] for x in frames]\n",
    "    for df in frames:\n",
    "        df.columns = [x.strip() for x in df.columns]\n",
    "    dfs[pheno] = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dfs['mass'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "path_mcmc_r = {}\n",
    "path_mcmc = {}\n",
    "thin = 1\n",
    "for key, dflist in dfs.items():\n",
    "    path_mcmc_r[key] = [mcmc(pandas2ri.DataFrame(x.sample(frac=thin).sort_index())) for x in dflist]\n",
    "    path_mcmc[key] = [x.sample(frac=thin).sort_index() for x in dflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_mcmc_list_mass = mcmc_list(path_mcmc_r['mass'])\n",
    "path_mcmc_list_pd = mcmc_list(path_mcmc_r['pd'])\n",
    "path_mcmc_list_tdt = mcmc_list(path_mcmc_r['tdt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%R -i path_mcmc_list_mass -i path_mcmc_list_pd -i path_mcmc_list_tdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "effective_sizes_mass = lapply(path_mcmc_list_mass,effectiveSize)\n",
    "effective_sizes_pd = lapply(path_mcmc_list_pd,effectiveSize)\n",
    "effective_sizes_tdt = lapply(path_mcmc_list_tdt,effectiveSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_effective_sizes(r_name):\n",
    "    df = pd.DataFrame([pandas2ri.ri2py(x) for x in r[r_name]])\n",
    "    test = r[r_name].rx2(1)\n",
    "    df.columns = r('names')(test)\n",
    "    return df\n",
    "ne_tdt = get_effective_sizes('effective_sizes_tdt')\n",
    "ne_pd= get_effective_sizes('effective_sizes_pd')\n",
    "ne_mass= get_effective_sizes('effective_sizes_mass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print ne_tdt.mean()\n",
    "print ne_tdt.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_pd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ne_mass.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print \"MASS\", r(\"summary\")(path_mcmc_list_mass)\n",
    "print \"PD\", r(\"summary\")(path_mcmc_list_pd)\n",
    "print \"TDT\", r(\"summary\")(path_mcmc_list_tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(path_mcmc_list_mass)\n",
    "plot(path_mcmc_list_pd)\n",
    "plot(path_mcmc_list_tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc = {}\n",
    "for pheno, files in mcmc_files.items():\n",
    "    if not pheno in mcmc:\n",
    "        mcmc[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        testdf = pd.read_csv(f, sep=\"\\t\")\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        mcmc[pheno] = pd.concat([mcmc[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc_mass = mcmc['mass']\n",
    "mcmc_pd = mcmc['pd']\n",
    "mcmc_tdt = mcmc['tdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_difference(x, y):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    return (np.abs(x-y)/np.mean([x, y]))*100\n",
    "\n",
    "def get_quantile_max(name, data, q):\n",
    "    d = data.quantile(q)\n",
    "    d.index = [str(x) for x in d.index]\n",
    "    d['median_val'] = data.median()\n",
    "    d['mean_val'] = data.mean()\n",
    "    d['cutoff'] = 0.01\n",
    "    d[\"x99_cutoff\"] = percent_difference(d['0.99'], d['cutoff'])\n",
    "    d[\"x99_median\"] =  percent_difference(d['0.99'], d['median_val'])\n",
    "    d[\"x95_cutoff\"] = percent_difference(d['0.95'], d['cutoff'])\n",
    "    d[\"x95_median\"] =  percent_difference(d['0.95'], d['median_val'])\n",
    "    d['relaxed_cutoff'] = d['0.99']\n",
    "    d['min'] = data.min()\n",
    "    d['max'] = data.max()\n",
    "    d.name = name\n",
    "    return d\n",
    "\n",
    "mass_quant = get_quantile_max(\"mass\", mcmc_mass.postrb_0, [0.95,0.99])\n",
    "pd_quant = get_quantile_max(\"pd\", mcmc_pd.postrb_0, [0.95,0.99])\n",
    "tdt_quant =get_quantile_max(\"tdt\", mcmc_tdt.postrb_0, [0.95,0.99]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print \"%s\\n\\n%s\\n\\n%s\\n\" % (mass_quant, pd_quant, tdt_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('mass_quant', mass_quant)\n",
    "hdf.put('pd_quant', pd_quant)\n",
    "hdf.put('tdt_quant', tdt_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_snps_mass = mcmc_mass[mcmc_mass.postrb_0 > mass_quant.cutoff]\n",
    "sig_snps_tdt = mcmc_tdt[mcmc_tdt.postrb_0 > tdt_quant.cutoff]\n",
    "sig_snps_pd = mcmc_pd[mcmc_pd.postrb_0 > pd_quant.cutoff]\n",
    "\n",
    "relaxed_sig_snps_mass = mcmc_mass[mcmc_mass.postrb_0 > mass_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_tdt = mcmc_tdt[mcmc_tdt.postrb_0 > tdt_quant.relaxed_cutoff]\n",
    "relaxed_sig_snps_pd = mcmc_pd[mcmc_pd.postrb_0 > pd_quant.relaxed_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pips = {}\n",
    "def get_contig_pip(row, pheno):\n",
    "    if not pheno in contig_pips:\n",
    "        contig_pips[pheno] = {}\n",
    "        \n",
    "    d = row.rs_1.split(\"_\")\n",
    "    contig = \"_\".join(d[:-1])\n",
    "    if not contig in contig_pips[pheno]:\n",
    "        contig_pips[pheno][contig] = {'postc':0,\n",
    "                              'beta':0,\n",
    "                              'betarb':0,\n",
    "                              'postrb':0}\n",
    "    contig_pips[pheno][contig]['postc'] += row.postc_1\n",
    "    contig_pips[pheno][contig]['postrb'] += row.postrb_1\n",
    "    contig_pips[pheno][contig]['beta'] += row.beta_1\n",
    "    contig_pips[pheno][contig]['betarb'] += row.betarb_1\n",
    "\n",
    "for pheno, df in mcmc.items():\n",
    "    print pheno\n",
    "    df.apply(get_contig_pip, args=(pheno,), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_dfs = {}\n",
    "for pheno, data in contig_pips.items():\n",
    "    contig_pip_dfs[pheno] = pd.DataFrame(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contig_pip_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "contig_lengths = {}\n",
    "for rec in SeqIO.parse(assembly,\"fasta\"):\n",
    "    contig_lengths[rec.name] = {\"length\":len(rec)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df = pd.DataFrame(contig_lengths).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_length_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "contig_pip_mass = contig_pip_dfs['mass'].join(contig_length_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(contig_pip_dfs['tdt'].postrb, label=\"PIP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_mass))\n",
    "#plt.plot(avg_pip_mass, label=\"PIP\")\n",
    "#plt.plot(avg_effect_mass, alpha=0.5, label=\"Beta\")\n",
    "plt.plot(avg_pip_mass_rb, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(avg_effect_mass_rb, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"Mass\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_pd))\n",
    "#plt.plot(avg_pip_pd, label=\"PIP\")\n",
    "#plt.plot(avg_effect_pd, alpha=0.5, label=\"Beta\")\n",
    "plt.plot(avg_pip_pd_rb, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(avg_effect_pd_rb, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"PD\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, len(mcmc_tdt))\n",
    "#plt.plot(avg_pip_tdt, label=\"PIP\")\n",
    "#plt.plot(avg_effect_tdt, alpha=0.5, label=\"Beta\")\n",
    "plt.plot(avg_pip_tdt_rb, alpha=0.5, label=\"PIP (RB)\")\n",
    "plt.plot(avg_effect_tdt_rb, alpha=0.5, label=\"Beta (RB)\")\n",
    "plt.title(\"TDT\")\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mcmc_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps = {}\n",
    "for pheno, files in snp_files.items():\n",
    "    if not pheno in snps:\n",
    "        snps[pheno] = pd.DataFrame()\n",
    "    for f in files:\n",
    "        index = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "        h = open(f)\n",
    "        h.readline() ##skip header\n",
    "        header = h.readline().strip().split()\n",
    "        data = []\n",
    "        for line in h:\n",
    "            line = line.strip().split()\n",
    "            data.append(line)\n",
    "            \n",
    "        testdf = pd.DataFrame(data, columns=header)\n",
    "        testdf.columns = [\"%s_%s\" % (x.strip(), index) for x in testdf.columns]\n",
    "        snps[pheno] = pd.concat([snps[pheno], testdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass = snps['mass'][[x for x in snps['mass'] if '_1' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def read_gamma(f):\n",
    "    d = []\n",
    "    h = open(f)\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        line = line.strip().split()\n",
    "        d.append(line)\n",
    "    df = pd.DataFrame(d, columns=header)\n",
    "    return df.replace('NA', np.nan).astype(float)\n",
    "gamma_mass = read_gamma(gamma_files['mass'][0])\n",
    "gamma_pd = read_gamma(gamma_files['pd'][0])\n",
    "gamma_tdt = read_gamma(gamma_files['tdt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "snp_density = {}\n",
    "def get_snp_density(row):\n",
    "    included = row[1:].dropna()\n",
    "    for snp_id in included:\n",
    "        if not snp_id in snp_density:\n",
    "            snp_density[snp_id] = 0\n",
    "        snp_density[snp_id] += 1\n",
    "    \n",
    "gamma_mass.apply(get_snp_density, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_snps_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_hmean(df, col_pattern):\n",
    "    cols = ['rs','chr']\n",
    "    cols.extend([\"%s_hmean\" % x for x in col_pattern])\n",
    "    d = pd.DataFrame(columns=cols, index=df.index)\n",
    "    d['rs'] = df.rs_1.values\n",
    "    d[\"chr\"] = df.chr_1.values\n",
    "    for cp in col_pattern:\n",
    "        #np. abs here to account for negative betas\n",
    "        d[\"%s_hmean\" % cp] = df[[x for x in df if cp in x]].apply(np.abs, axis=1).apply(sp.stats.hmean, axis=1).values\n",
    "    return d\n",
    "sig_snps_mass_hmean = get_hmean(sig_snps_mass, [\"postrb\", \"betarb\"])\n",
    "sig_snps_tdt_hmean = get_hmean(sig_snps_tdt, [\"postrb\", \"betarb\"])\n",
    "sig_snps_pd_hmean = get_hmean(sig_snps_pd, [\"postrb\", \"betarb\"])\n",
    "relaxed_sig_snps_mass_hmean = get_hmean(relaxed_sig_snps_mass, [\"postrb\", \"betarb\"])\n",
    "relaxed_sig_snps_tdt_hmean = get_hmean(relaxed_sig_snps_tdt, [\"postrb\", \"betarb\"])\n",
    "relaxed_sig_snps_pd_hmean = get_hmean(relaxed_sig_snps_pd, [\"postrb\", \"betarb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"sig_snps_mass\", sig_snps_mass)\n",
    "hdf.put(\"sig_snps_tdt\", sig_snps_tdt)\n",
    "hdf.put(\"sig_snps_pd\", sig_snps_pd)\n",
    "hdf.put(\"relaxed_sig_snps_mass\", relaxed_sig_snps_mass)\n",
    "hdf.put(\"relaxed_sig_snps_tdt\", relaxed_sig_snps_tdt)\n",
    "hdf.put(\"relaxed_sig_snps_pd\", relaxed_sig_snps_pd)\n",
    "\n",
    "hdf.put(\"sig_snps_mass_hmean\", sig_snps_mass_hmean)\n",
    "hdf.put(\"sig_snps_tdt_hmean\", sig_snps_tdt_hmean)\n",
    "hdf.put(\"sig_snps_pd_hmean\", sig_snps_pd_hmean)\n",
    "hdf.put(\"relaxed_sig_snps_mass_hmean\", relaxed_sig_snps_mass_hmean)\n",
    "hdf.put(\"relaxed_sig_snps_tdt_hmean\", relaxed_sig_snps_tdt_hmean)\n",
    "hdf.put(\"relaxed_sig_snps_pd_hmean\", relaxed_sig_snps_pd_hmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_mass.betarb_0.values))\n",
    "plt.text(0.010, 50, r\"$n = %d$\" % len(sig_snps_mass))\n",
    "plt.title(r\"Mass ($> %.2f$)\" % mass_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_mass.betarb_0.values))\n",
    "plt.text(0.01, 70, r\"$n = %d$\" % len(relaxed_sig_snps_mass))\n",
    "plt.title(r\"Mass 99th($> %.5f$)\" % mass_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_tdt.betarb_0.values))\n",
    "plt.text(0.015, 12, r\"$n = %d$\" % len(sig_snps_tdt))\n",
    "plt.title(r\"TDT ($> %.2f$)\" % tdt_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_tdt.betarb_0.values))\n",
    "plt.text(0.015, 100, r\"$n = %d$\" % len(relaxed_sig_snps_tdt))\n",
    "plt.title(r\"TDT 99th ($> %.5f$)\" % tdt_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.abs(sig_snps_pd.betarb_0.values))\n",
    "plt.text(0.0045, 3, r\"$n = %d$\" % len(sig_snps_pd))\n",
    "plt.title(r\"PD ($> %.2f$)\" % pd_quant.cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()\n",
    "plt.hist(np.abs(relaxed_sig_snps_pd.betarb_0.values))\n",
    "plt.text(0.0045, 70, r\"$n = %d$\" % len(relaxed_sig_snps_pd))\n",
    "plt.title(r\"PD 99th ($> %.5f$)\" % pd_quant.relaxed_cutoff)\n",
    "plt.xlabel(r\"$\\beta$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
