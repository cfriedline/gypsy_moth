{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T14:04:10.280729",
     "start_time": "2016-03-24T14:04:10.071564"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils/\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "#import urllib2\n",
    "import urllib.request as urllib2\n",
    "import urllib\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import pickle\n",
    "from IPython.display import FileLink, FileLinks, display\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.3/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.18/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:21:39.247415",
     "start_time": "2016-03-24T13:21:39.086053"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ni_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni\"\n",
    "imp_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:21:39.356802",
     "start_time": "2016-03-24T13:21:39.255425"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notimputed_vcf_gz = os.path.join(ni_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "imputed_vcf_gz = os.path.join(imp_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:21:54.694944",
     "start_time": "2016-03-24T13:21:54.657042"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcfs = [notimputed_vcf_gz, imputed_vcf_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in vcfs:\n",
    "    !$vcftools --gzvcf $v --012 --out $v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:25:57.574100",
     "start_time": "2016-03-24T13:25:57.427392"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12s = [\"%s.012\" % x for x in vcfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:21:58.490959",
     "start_time": "2016-03-24T13:21:58.310566"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "def get_translated_name(n):\n",
    "    row = translation_df.ix[n.strip()]\n",
    "    return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:26:36.056202",
     "start_time": "2016-03-24T13:26:05.487724"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_z12_df(z12_file):\n",
    "    indv_file = \"%s.indv\" % z12_file\n",
    "    pos_file = \"%s.pos\" % z12_file\n",
    "    z12_data = []\n",
    "    for i, line in enumerate(open(z12_file)):\n",
    "        line = line.strip()\n",
    "        line = [int(x) for x in line.split(\"\\t\")]\n",
    "        z12_data.append(np.array(line))\n",
    "    z12_data = np.array(z12_data)\n",
    "    p = pd.read_csv(pos_file, sep=\"\\t\", names=['contig', 'pos'])\n",
    "    i = pd.read_csv(indv_file, names=['sample_name'])\n",
    "    df = pd.DataFrame(z12_data)\n",
    "    df = df.drop(0, axis=1)\n",
    "    df.columns = p.apply(lambda x: \"%s_%s\" % (x.contig, x.pos), axis=1)\n",
    "    df.index = [get_translated_name(x) for x in i.sample_name]\n",
    "    return df\n",
    "z12_dfs = [get_z12_df(x) for x in z12s]\n",
    "#z12_dfs = [x[keep_snps.index] for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:27:44.849470",
     "start_time": "2016-03-24T13:27:38.256827"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pheno():\n",
    "    url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    pheno = pd.read_excel(response, \"Males-forGenomics-final\")\n",
    "    pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
    "    for x in pheno.index:\n",
    "        pheno.ix[x, 'sample_pheno'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])\n",
    "    pheno['sample_id'] = pheno.apply(lambda x: \"%s_0\" % x.sample_pheno, axis=1)\n",
    "    pheno.index = pheno['sample_id']\n",
    "    pheno = pheno.drop('sample_id', axis=1)\n",
    "    return pheno\n",
    "pheno = get_pheno()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:27:47.284291",
     "start_time": "2016-03-24T13:27:46.929597"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure z12 files match to authoritative names in phenotype file\n",
    "z12_dfs = [x.ix[x.index.isin(pheno.index)] for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:27:55.512619",
     "start_time": "2016-03-24T13:27:54.953638"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_population(df):\n",
    "    df['population'] = df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "[assign_population(x) for x in z12_dfs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:27:57.160402",
     "start_time": "2016-03-24T13:27:57.035126"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:28:20.129837",
     "start_time": "2016-03-24T13:28:19.938102"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    if total_alleles == 0:\n",
    "        return None\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:41:56.285925",
     "start_time": "2016-03-24T13:31:11.319816"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = [x.ix[:,:-1].apply(get_allele_freqs, args=(False,)) for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:41:56.397462",
     "start_time": "2016-03-24T13:41:56.291096"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in allele_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:42:05.934894",
     "start_time": "2016-03-24T13:41:56.403289"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mafs = [x.apply(lambda x: min(x[\"p\"], x[\"q\"])) for x in allele_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:42:05.985916",
     "start_time": "2016-03-24T13:42:05.938639"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mafs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:42:06.035349",
     "start_time": "2016-03-24T13:42:05.989445"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:42:54.760509",
     "start_time": "2016-03-24T13:42:52.113911"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(mafs[0], mafs[1])\n",
    "plt.title(\"MAF\")\n",
    "plt.xlabel(\"not imputed\")\n",
    "plt.ylabel(\"imputed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:43:32.602229",
     "start_time": "2016-03-24T13:43:32.483500"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_alleles(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        if maf == freqs[\"p\"]:\n",
    "            return locus.replace({0:2,2:0})\n",
    "        return locus\n",
    "    else:\n",
    "        return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:44:49.905244",
     "start_time": "2016-03-24T13:43:32.634897"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = []\n",
    "for i, z12 in enumerate(z12_dfs):\n",
    "    z12_swapped.append(z12.apply(swap_alleles, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:44:50.058061",
     "start_time": "2016-03-24T13:44:49.947236"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:44:50.146886",
     "start_time": "2016-03-24T13:44:50.060904"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:44:50.201943",
     "start_time": "2016-03-24T13:44:50.151931"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(z12_dfs[0]['population'].unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1\n",
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:44:50.249053",
     "start_time": "2016-03-24T13:44:50.206747"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_popid(series):\n",
    "    series['popid'] = pop_id[series['population']]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:45:41.876936",
     "start_time": "2016-03-24T13:44:50.253387"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = [x.apply(assign_popid, axis=1) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:45:42.070360",
     "start_time": "2016-03-24T13:45:41.930523"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:46:57.932364",
     "start_time": "2016-03-24T13:46:57.798316"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        #locus_id = int(locus.name[1:])\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:52:23.816469",
     "start_time": "2016-03-24T13:46:57.939375"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = []\n",
    "for i, df in enumerate(z12_swapped):\n",
    "    pca_std.append(df.apply(center_and_standardize, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:52:24.632912",
     "start_time": "2016-03-24T13:52:23.865287"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = [x.ix[:,:-2] for x in pca_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:52:24.675511",
     "start_time": "2016-03-24T13:52:24.635674"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni = pca_std_data[0]\n",
    "pca_std_data_imp = pca_std_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:53:02.490091",
     "start_time": "2016-03-24T13:53:02.444876"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni.shape, pca_std_data_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni.to_csv(os.path.join(ni_dir, \"pca_std_data.txt\"), header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_imp.to_csv(os.path.join(imp_dir, \"pca_std_data.txt\"), header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:55:10.167950",
     "start_time": "2016-03-24T13:53:38.068791"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "ni_dir ='/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni'\n",
    "imp_dir = '/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/'\n",
    "data_ni = fread(paste(ni_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "data_imp = fread(paste(imp_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "rownames(data_ni) = data_ni$V1\n",
    "\n",
    "rownames(data_imp) = data_imp$V1\n",
    "drops = c(\"V1\")\n",
    "data_ni = data_ni[,!(names(data_ni) %in% drops)]\n",
    "data_imp = data_imp[,!(names(data_imp) %in% drops)]\n",
    "res_ni = prcomp(data_ni, scale=F, center=F)\n",
    "res_imp = prcomp(data_imp, scale=F, center=F)\n",
    "rownames(res_ni$x) = rownames(data_ni)\n",
    "\n",
    "rownames(res_imp$x) = rownames(data_imp)\n",
    "fname = 'pca_res.rds'\n",
    "ni = paste(ni_dir, \"/\", fname, sep='')\n",
    "imp = paste(imp_dir, \"/\", fname, sep='')\n",
    "saveRDS(res_ni, ni)\n",
    "saveRDS(res_imp, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:57:53.740725",
     "start_time": "2016-03-24T13:57:50.508114"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r(\"res_ni = readRDS('%s/pca_res.rds')\" % ni_dir);\n",
    "r(\"res_imp = readRDS('%s/pca_res.rds')\" % imp_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:57:54.670490",
     "start_time": "2016-03-24T13:57:54.561264"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pca_x(res):\n",
    "    x = pd.DataFrame(pandas2ri.ri2py(res.rx2(\"x\")))\n",
    "    x.index = res.rx2(\"x\").names[0]\n",
    "    x.columns = res.rx2(\"x\").names[1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:57:55.522457",
     "start_time": "2016-03-24T13:57:55.407399"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(r('res_ni').rx2('x').names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:58:00.457338",
     "start_time": "2016-03-24T13:58:00.346925"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:58:00.662734",
     "start_time": "2016-03-24T13:58:00.565046"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prcomp_res = [x for x in [r['res_ni'], r['res_imp']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:58:03.647181",
     "start_time": "2016-03-24T13:58:03.521024"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = [get_pca_x(x) for x in [r['res_ni'], r['res_imp']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:58:03.892473",
     "start_time": "2016-03-24T13:58:03.785069"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x[0].index = pca_std_data_ni.index\n",
    "pca_x[1].index = pca_std_data_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T13:58:04.168545",
     "start_time": "2016-03-24T13:58:04.063305"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T14:05:37.210282",
     "start_time": "2016-03-24T14:05:36.905378"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))\n",
    "def plot_pca(key, pca_std, pca_std_data, pca_x, prcomp_res):\n",
    "    joined = pca_std.join(pca_x)\n",
    "    legend = {}\n",
    "    for row in joined.iterrows():\n",
    "        pop = row[1]['population']\n",
    "        n = norm(pop_id[pop])\n",
    "        color = cm.rainbow(n)\n",
    "        legend[pop] = color\n",
    "        plt.scatter(row[1].PC1, \n",
    "                    row[1].PC2, \n",
    "                    s=50, \n",
    "                    c=color)\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    cmap = plt.get_cmap()\n",
    "    fig.set_size_inches(10,8)\n",
    "    plt.title(\"PCA of n=%d samples on %d loci (%s)\" % (len(joined), len(pca_std_data.columns), key))\n",
    "    imp = summary(prcomp_res).rx(\"importance\")[0]\n",
    "    plt.xlabel(\"PC1 (%g)\" % imp.rx(2,1)[0])\n",
    "    plt.ylabel(\"PC2 (%g)\" % imp.rx(2,2)[0])\n",
    "\n",
    "    handles = []\n",
    "    for pop in sorted(legend):\n",
    "        handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "    plt.legend(handles=handles)\n",
    "    \n",
    "    out_file = \"%s.pdf\" % key.replace(\" \", \"_\")\n",
    "    plt.savefig(out_file)\n",
    "    plt.show()\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-24T14:07:03.676946",
     "start_time": "2016-03-24T14:06:48.831789"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, key in enumerate([\"not imputed\", \"imputed\"]):\n",
    "    f = plot_pca(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i])\n",
    "    display(FileLink(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df(dirname, fname, df):\n",
    "    f = os.path.join(dirname, \"%s.txt\" % fname) \n",
    "    df.to_csv(f, \n",
    "              header=True,\n",
    "              index=True,\n",
    "              sep=\"\\t\")\n",
    "    print(\"saved %s\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "ni_dir ='/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni'\n",
    "imp_dir = '/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/'\n",
    "data_ni = fread(paste(ni_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "data_imp = fread(paste(imp_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "rownames(data_ni) = data_ni$V1\n",
    "rownames(data_imp) = data_imp$V1\n",
    "drops = c(\"V1\")\n",
    "data_ni = data_ni[,!(names(data_ni) %in% drops)]\n",
    "data_imp = data_imp[,!(names(data_imp) %in% drops)]\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "tw_ni = TWcalc(as.matrix(data_ni),20)\n",
    "tw_imp = TWcalc(as.matrix(data_imp),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tws = [r(\"tw_ni[[2]]\"), r(\"tw_imp[[2]]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sig_tracywidom(tw_p):\n",
    "    ps = []\n",
    "    for i, p in enumerate(tw_p):\n",
    "        if p > 0.05:\n",
    "            print(i, p)\n",
    "            break\n",
    "        else:\n",
    "            ps.append(p)\n",
    "    return len(ps), ps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = [get_sig_tracywidom(x) for x in tws]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracy-Widom\n",
    "\n",
    "```\n",
    "Not imputed: 13\n",
    "Imputed: 15\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = [None]*2\n",
    "pca_cov[0] = pca_x[0].ix[:,0:tw_num[0][0]]\n",
    "pca_cov[1] = pca_x[1].ix[:,0:tw_num[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in pca_cov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d, f in zip([ni_dir, imp_dir], pca_cov):\n",
    "    save_df(d, 'pca_cov', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [ni_dir, imp_dir]:\n",
    "    save_df(d, 'pheno', pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca_std_pheno = pheno.join(pca_cov, how=\"inner\").join(pca_maf.ix[:,:-2], how=\"inner\")\n",
    "pca_std_pheno = []\n",
    "for i, df in enumerate(pca_cov):\n",
    "    df = pheno.join(pca_cov[i], how='inner').join(z12_swapped[i], how='inner')\n",
    "    print(df.shape)\n",
    "    pca_std_pheno.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    save_df(d, 'pca_std_pheno', pca_std_pheno[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    save_df(d, \"z12_df\", z12_dfs[i])\n",
    "    save_df(d, \"z12_swapped\", z12_swapped[i])\n",
    "    save_df(d, \"pca_std\", pca_std[i])\n",
    "    save_df(d, \"pca_std_data\", pca_std_data[i])\n",
    "    save_df(d, \"mafs\", mafs[i])\n",
    "    save_df(d, \"allele_freqs\", allele_freqs[i])\n",
    "    save_df(d, \"pca_x\", pca_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_data = []\n",
    "\n",
    "for i, df in enumerate(z12_swapped):\n",
    "    pop_data = {}\n",
    "    for group, data in df.groupby('population'):\n",
    "        data = data.drop(['population', 'popid'], axis=1)\n",
    "        print(i, group, data.shape)\n",
    "        gt = data.apply(get_allele_freqs, debug=False)\n",
    "        pop_data[group] = gt.to_dict()\n",
    "    pop_allele_data.append(pop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    pickle.dump(pop_allele_data[i], \n",
    "                open(os.path.join(d, \"pop_allele_data.pkl\"), \"wb\"), \n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(z12_dfs[1].index).to_csv(os.path.join(os.path.dirname(ni_dir), \"good_samples.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
