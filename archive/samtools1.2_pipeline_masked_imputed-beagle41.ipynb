{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../include_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from IPython.parallel import Client\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import cyvcf\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = \"/home/cfriedline/ipynb/gypsy_moth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "R.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_session():\n",
    "    dill.dump_session(\"session.dill\")\n",
    "    \n",
    "def load_session():\n",
    "    dill.load_session(\"session.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis\"\n",
    "analysis_dir = os.path.join(bam_dir, \"samtools1.2\")\n",
    "if not os.path.exists(analysis_dir):\n",
    "    os.makedirs(analysis_dir)\n",
    "assert os.path.exists(analysis_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam_files = !find /home/cfriedline/eckertlab/gypsy_indiv/masked | grep new | grep 'rg.bam$' | grep -v OTIS\n",
    "bam_files = [os.path.abspath(x) for x in bam_files if '.bam' in x]\n",
    "len(bam_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.2/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.2/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.16/bin/perl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembly = \"/home/cfriedline/gpfs/assemblies/gypsy/masurca_new/CA/10-gapclose/genome.ctg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam_rmdup_files = !ls {analysis_dir} | grep 'dedup.bam$' | grep -v OTIS\n",
    "bam_rmdup_files = sorted([os.path.join(analysis_dir, x) for x in bam_rmdup_files])\n",
    "len(bam_rmdup_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembly_dir = os.path.dirname(assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_file = os.path.join(analysis_dir, \"samtools_1.2.vcf.gz\")\n",
    "assert os.path.exists(vcf_file)\n",
    "vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.2/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.2/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/samtools-1.2/htslib-1.2.1/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/samtools-1.2/htslib-1.2.1/bgzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41\"\n",
    "analysis_vcf = \"imputed_41.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_vcf = os.path.join(analysis_dir, analysis_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools --012 \\\n",
    "--gzvcf \\\n",
    "$working_vcf \\\n",
    "--out $working_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hdfstorehelper import HDFStoreHelper\n",
    "hdf = HDFStoreHelper(os.path.join(analysis_dir, \"gypsy_samtools12_%s.hd5\" % analysis_vcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_file = os.path.join(analysis_dir, \"%s.012\" % analysis_vcf)\n",
    "z12_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(z12_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_data = []\n",
    "for i, line in enumerate(open(z12_file)):\n",
    "    line = line.strip()\n",
    "    line = [int(x) for x in line.split(\"\\t\")]\n",
    "    z12_data.append(np.array(line))\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "z12_data = np.array(z12_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df = pd.DataFrame(z12_data)\n",
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df = z12_df.drop(0, axis=1)\n",
    "z12_df.columns = pd.Series(z12_df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_df.columns = [\"L%d\" % x for x in z12_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "indv = os.path.join(analysis_dir, \"%s.indv\" % os.path.basename(z12_file))\n",
    "\n",
    "def get_translated_name(n):\n",
    "    row = translation_df.ix[n.strip()]\n",
    "    return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [get_translated_name(x) for x in open(indv).readlines()]\n",
    "z12_df.index=names\n",
    "\n",
    "z12_df['population'] = z12_df.apply(lambda row: row.name.split(\"_\")[0], axis=1)\n",
    "z12_df['duplicate'] = z12_df.apply(lambda row: row.name[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snp_pos = pd.read_csv(os.path.join(analysis_dir, indv.replace(\"indv\", \"pos\")), \n",
    "                              sep=\"\\t\",\n",
    "                              header=None,\n",
    "                              names=['contig', 'pos'])\n",
    "snps = pd.DataFrame([int(x[1:]) for x in z12_df.columns[:-2]])\n",
    "snps.columns = ['snp_id']\n",
    "snps.index=snps.snp_id\n",
    "snp_id_pos = pd.merge(snps, snp_pos, how=\"inner\", left_index=True, right_index=True)\n",
    "snp_id_pos.index = [\"L%d\" % x for x in snp_id_pos.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_pos.shape, snp_id_pos.shape, z12_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('snp_pos', snp_pos)\n",
    "hdf.put('snp_id_pos', snp_id_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = vcf.VCFReader(filename=os.path.join(analysis_dir, analysis_vcf))\n",
    "def get_ref_alt_alleles(row):\n",
    "    alleles = reader.fetch(row.contig, row.pos-1)\n",
    "    for allele in alleles:\n",
    "        row['ref'] = allele.REF\n",
    "        row['alt'] = allele.ALT\n",
    "        break\n",
    "    return row\n",
    "snp_id_pos_ref_alt = snp_id_pos.apply(get_ref_alt_alleles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt['ref_len'] = snp_id_pos_ref_alt.apply(lambda x: len(x.ref), axis=1)\n",
    "snp_id_pos_ref_alt_snps_only = snp_id_pos_ref_alt[snp_id_pos_ref_alt.ref_len==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('snp_id_pos_ref_alt', snp_id_pos_ref_alt)\n",
    "hdf.put('snp_id_pos_ref_alt_snps_only', snp_id_pos_ref_alt_snps_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt.to_csv(os.path.join(analysis_dir, \n",
    "                                       \"snp_id_pos_ref_alt.csv\"), \n",
    "                          header=True, \n",
    "                          index=True, \n",
    "                          sep=\"\\t\")\n",
    "snp_id_pos_ref_alt_snps_only.to_csv(os.path.join(analysis_dir, \n",
    "                                                 \"snp_id_pos_ref_alt_snps_only.csv\"),\n",
    "                                    header=True, \n",
    "                                    index=True,\n",
    "                                    sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_snp_names(col):\n",
    "    if col.name.startswith(\"L\"):\n",
    "        return\"%s_%s_%d\" % (col.name,\n",
    "                             snp_id_pos_ref_alt_snps_only.ix[col.name, 'contig'],\n",
    "                                snp_id_pos_ref_alt_snps_only.ix[col.name, 'pos'])\n",
    "    return col.name\n",
    "colnames = z12_df.apply(add_snp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_df.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"z12_df\", z12_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_percent_missing(col):\n",
    "    return len(col[col==-1])*1.0/len(col)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing = z12_df.apply(get_percent_missing, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('percent_missing', percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc = z12_df.ix[:,percent_missing <= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc', z12_df_50_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_monomorphic(col):\n",
    "    u = col[col != -1].value_counts()\n",
    "    if len(u) == 1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monomorphic_loci = z12_df_50_perc.apply(is_monomorphic, axis=0)\n",
    "monomorphic_loci = monomorphic_loci[monomorphic_loci==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(monomorphic_loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic = z12_df_50_perc.drop(monomorphic_loci.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic', z12_df_50_perc_polymorphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = z12_df_50_perc_polymorphic.ix[:,:-2].apply(get_allele_freqs, args=(False,))\n",
    "mafs = allele_freqs.apply(lambda x: min(x[\"p\"], x[\"q\"]))\n",
    "len(mafs[mafs<0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs.ix[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('allele_freqs', allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf = z12_df_50_perc_polymorphic.drop(mafs[mafs<0.01].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic_maf', z12_df_50_perc_polymorphic_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_fis = allele_freqs[z12_df_50_perc_polymorphic_maf.columns[:-2]].apply(lambda x: x[\"Fis\"])\n",
    "fis_outliers = global_fis[(global_fis < -0.5) | (global_fis > 0.5)]\n",
    "z12_df_50_perc_polymorphic_maf_fis = z12_df_50_perc_polymorphic_maf.drop(fis_outliers.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf.shape, z12_df_50_perc_polymorphic_maf_fis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic_maf_fis', z12_df_50_perc_polymorphic_maf_fis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duplicates = z12_df_50_perc_polymorphic_maf_fis[z12_df_50_perc_polymorphic_maf_fis.duplicate==\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duplicates[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis_dedup = z12_df_50_perc_polymorphic_maf_fis.drop(duplicates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis_dedup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('z12_df_50_perc_polymorphic_maf_fis_dedup', z12_df_50_perc_polymorphic_maf_fis_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis_dedup = hdf.get('z12_df_50_perc_polymorphic_maf_fis_dedup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = z12_df_50_perc_polymorphic_maf_fis_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs = hdf.get(\"allele_freqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.to_csv(os.path.join(analysis_dir,\n",
    "                               \"z12_df_50_perc_polymorphic_maf_fis_dedup.txt\"),\n",
    "                                          header=True,\n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(allele_freqs.T[\"Fis\"].values, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs_final = z12_df_50_perc_polymorphic_maf_fis_dedup.ix[:,:-2].apply(get_allele_freqs,\n",
    "                                                                              args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('allele_freqs_final', allele_freqs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs_final = hdf.get('allele_freqs_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(allele_freqs_final.T[\"Fis\"].values, bins=50)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(allele_freqs.T[\"Fis\"].values, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs = allele_freqs_final.apply(lambda x: np.min((x['p'], x['q'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mafs, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = pd.read_csv(os.path.join(analysis_dir, \n",
    "                                      \"z12_df_50_perc_polymorphic_maf_fis_dedup.txt\"),\n",
    "                                      sep=\"\\t\",\n",
    "                                      index_col=0)\n",
    "# cols = [int(x) for x in working_df.columns.tolist()[:-2]]\n",
    "# cols.extend(working_df.columns.tolist()[-2:])\n",
    "# working_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = hdf.get('z12_df_50_perc_polymorphic_maf_fis_dedup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swap_alleles(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        locus_id = locus.name\n",
    "        freqs = allele_freqs[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        if maf == freqs[\"p\"]:\n",
    "            return locus.replace({0:2,2:0})\n",
    "        return locus\n",
    "    else:\n",
    "        return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_swapped = working_df.apply(swap_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"working_swapped\", working_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans = {0:11, 1:12, 2:22, -1:'NA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_hierf_trans(series):\n",
    "    return [hierf_trans[x] if x in hierf_trans else x for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = working_swapped.apply(apply_hierf_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df', hierf_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = hdf.get('hierf_trans_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
    "response = urllib.request.urlopen(url)\n",
    "pheno = pd.read_excel(response, \"Males-forGenomics-final\")\n",
    "pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
    "for x in pheno.index:\n",
    "    pheno.ix[x, 'sample_pheno'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"pheno\", pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(working_df['population'].unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1\n",
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_popid(series):\n",
    "    series['popid'] = pop_id[series['population']]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = hierf_trans_df.apply(assign_popid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df.to_csv(os.path.join(analysis_dir, \"hierf_trans_df.txt\"), header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = pd.read_csv(os.path.join(analysis_dir, \"hierf_trans_df.txt\"), header=0, index_col=0, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df', hierf_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df = hdf.get('hierf_trans_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['popid']\n",
    "cols.extend(hierf_trans_df.columns[:-3])\n",
    "#cols.extend(snp_id_pos_ref_alt_snps_only.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2 = hierf_trans_df[[x for x in cols if x in hierf_trans_df.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2 = hierf_trans_df2.sort(\"popid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('hierf_trans_df2', hierf_trans_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2 = hdf.get('hierf_trans_df2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.popid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.to_csv(os.path.join(analysis_dir, \"hierfstat_samtools.txt\"), header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2[[x for x in hierf_trans_df2 if x.startswith(\"L\")]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put into R (because it can be slow)\n",
    "\n",
    "```R\n",
    "library(hierfstat)\n",
    "data = read.table(\"hierfstat_samtools.txt\", header=T, sep=\"\\t\")\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "saveRDS(res, \"hierfstat_samtools_new.rds\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(gtools)\n",
    "library(ade4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(hierfstat)\n",
    "f = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/hierfstat_samtools.txt\"\n",
    "data = read.table(f, header=T, sep=\"\\t\")\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "bs = basic.stats(data)\n",
    "saveRDS(bs, \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/basic_stats.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/hierfstat_samtools_new.rds\")\n",
    "bs = readRDS(\"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/basic_stats.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_r_series(key):\n",
    "    s = pd.Series(get_r(key))\n",
    "    s.index = get_r(\"names(%s)\" % key)\n",
    "    return s\n",
    "\n",
    "def get_r_df(key):\n",
    "    df = pd.DataFrame(get_r(key))\n",
    "    try:\n",
    "        rname = get_r(\"rownames(%s)\" % key)\n",
    "        df.index = rname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        cname = get_r(\"colnames(%s)\" % key)\n",
    "        df.columns = cname\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_r(key):\n",
    "    return r(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perloc = get_r_df(\"bs$perloc\")\n",
    "Ho = get_r_df(\"bs$Ho\")\n",
    "Hs = get_r_df(\"bs$Hs\")\n",
    "Fis = get_r_df(\"bs$Fis\")\n",
    "overall = get_r_series(\"bs$overall\")\n",
    "n_ind_samp = get_r_df(\"bs$n.ind.samp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('perloc', perloc)\n",
    "hdf.put('Ho', Ho)\n",
    "hdf.put(\"Hs\", Hs)\n",
    "hdf.put(\"Fis\", Fis)\n",
    "hdf.put(\"overall\", overall)\n",
    "hdf.put(\"n_ind_samp\", n_ind_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_df = get_r_df('res$loc')\n",
    "F_df = get_r_df('res$F')\n",
    "overall_df = get_r_df('res$overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Hs = series[0]\n",
    "    Ht = sum(series)\n",
    "    return Hs/Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst = loc_df.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"loci_fst\", loci_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_fst = hdf.get('loci_fst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perloc['Fst'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(loci_fst, bins=50)\n",
    "plt.title(\"n=%d mean=%.4f +/- %.4f [%.4f, %.4f]\" % (len(loci_fst), \n",
    "                                                    np.mean(loci_fst), \n",
    "                                                    np.std(loci_fst),\n",
    "                                                    np.min(loci_fst), \n",
    "                                                    np.max(loci_fst)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df = hdf.get('z12_df_50_perc_polymorphic_maf_fis_dedup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs_final = hdf.get('allele_freqs_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs_final.ix[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf = hdf.get('working_swapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf.ix[:,:5].apply(lambda locus: np.mean([x for x in locus if x != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_maf', pca_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_maf = hdf.get('pca_maf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_maf.to_csv(os.path.join(analysis_dir, \"pca_maf.txt\"), sep=\"\\t\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        #locus_id = int(locus.name[1:])\n",
    "        locus_id = locus.name\n",
    "        freqs = allele_freqs[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = pca_maf.apply(center_and_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std.ix[:,0:5].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std', pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std = hdf.get('pca_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = pca_std.ix[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt_snps_only = hdf.get(\"snp_id_pos_ref_alt_snps_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt_snps_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snp_cols = snp_id_pos_ref_alt_snps_only.index\n",
    "pca_std_data_snps = pca_std_data\n",
    "pca_std_data_snps.shape, len(snp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std_data_snps', pca_std_data_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps = hdf.get('pca_std_data_snps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp = r('prcomp')\n",
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps.to_csv(os.path.join(analysis_dir, \"pca_std_data_snps.txt\"), \n",
    "                         header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp_res = prcomp(pca_std_data_snps, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(summary(prcomp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(pandas2ri.ri2py(prcomp_res.rx2(\"x\")))\n",
    "x.index = prcomp_res.rx2(\"x\").names[0]\n",
    "x.columns = prcomp_res.rx2(\"x\").names[1]\n",
    "joined = x.join(pca_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i prcomp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "file_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed\"\n",
    "missing_df = read.table(paste(file_dir, \"/\", \"missing_df.txt\", sep=\"\"), sep=\"\\t\", header=T)\n",
    "sample_missing = read.table(paste(file_dir, \"/\", \"sample_missing.txt\", sep=\"\"), sep=\"\\t\", header=F, \n",
    "                           row.names=1, col.names=c(\"sample\", \"missing\"))\n",
    "missing_pca = merge(sample_missing, prcomp_res$x, by=0)\n",
    "fit1 = lm(missing~PC1, data=missing_pca)\n",
    "fit2 = lm(missing~PC2, data=missing_pca)\n",
    "print(summary(fit1))\n",
    "print(summary(fit2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('joined', joined)\n",
    "hdf.put('x', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "legend = {}\n",
    "for row in joined.iterrows():\n",
    "    pop = row[1]['population']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.jet(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(row[1].PC1, \n",
    "                row[1].PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(joined), len(pca_std_data.columns)))\n",
    "plt.xlabel(\"PC1 (0.05729)\")\n",
    "plt.ylabel(\"PC2 (0.03193)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TWcalc = r('TWcalc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robjects.globalenv['pca_std_data_snps'] = pandas2ri.py2ri(pca_std_data_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "saveRDS(pca_std_data_snps, file=\"/gpfs_fs/home/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/pca_std_data_snps.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pca_std_data_snps = readRDS(\"/gpfs_fs/home/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle41/pca_std_data_snps.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pca_std_data_snps[1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "tw = TWcalc(as.matrix(pca_std_data_snps),12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_p = r(\"tw[[2]]\")\n",
    "tw_e = r(\"tw[[1]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = 0\n",
    "for i, p in enumerate(tw_p):\n",
    "    print(p)\n",
    "    if p > 0.05:\n",
    "        tw_num = i\n",
    "        break\n",
    "print(\"Tracy-Widom test yields %d axes of pop structure\" % tw_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    8e-09\n",
    "    8e-09\n",
    "    8e-09\n",
    "    8e-09\n",
    "    8e-09\n",
    "    8e-09\n",
    "    5.328e-06\n",
    "    0.000177359\n",
    "    0.000773431\n",
    "    0.509994383\n",
    "    Tracy-Widom test yields 9 axes of pop structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = x.ix[:,0:tw_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_cov', pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno = hdf.get(\"pheno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno['sample_id'] = pheno.apply(lambda x: \"%s_0\" % x.sample_pheno, axis=1)\n",
    "pheno.index = pheno['sample_id']\n",
    "pheno = pheno.drop('sample_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_maf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = pheno.join(pca_cov, how=\"inner\").join(pca_maf.ix[:,:-2], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pca_std_pheno', pca_std_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(pca_std_data.index) - set(pca_std_pheno.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_id_pos_ref_alt_snps_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snps = snp_id_pos_ref_alt_snps_only\n",
    "good_snp_file = os.path.join(analysis_dir, \"goodsnps.vcf\")\n",
    "good_snp_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snps = good_snps.ix[[x for x in pca_maf.columns if x.startswith(\"L\")]]\n",
    "reader = vcf.VCFReader(filename=os.path.join(analysis_dir, analysis_vcf))\n",
    "wrote = 0\n",
    "with open(good_snp_file, \"w\") as o:\n",
    "    writer = vcf.VCFWriter(o, reader)\n",
    "    for rec in reader:\n",
    "        row = good_snps[(good_snps.contig==rec.CHROM) & (good_snps.pos==rec.POS)]\n",
    "#         print row\n",
    "        if len(row):\n",
    "            writer.write_record(rec)\n",
    "            wrote += 1\n",
    "print(\"wrote %d recs to %s\" % (wrote, good_snp_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.put(\"good_snps\", good_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf2 = HDFStoreHelper(\"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/gypsy_samtools12_snps.vcf.gz.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_snps_notimputed = hdf2.get('good_snps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snps_notimputed.shape, good_snps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2\n",
    "venn2([set(good_snps_notimputed.index), set(good_snps.index)], set_labels=[\"not imputed\", \"imputed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inter_snps = set.intersection(*[set(good_snps_notimputed.index), set(good_snps.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inter_snps_df = good_snps.ix[inter_snps,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('inter_snps_df', inter_snps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snp_file_gz = \"%s.gz\" % good_snp_file\n",
    "!$bgzip -c $good_snp_file > $good_snp_file_gz\n",
    "!$tabix $good_snp_file_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_snp_file_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reader = vcf.VCFReader(filename=good_snp_file_gz)\n",
    "finder = vcf.VCFReader(filename=good_snp_file_gz)\n",
    "\n",
    "def get_correct_name(name):\n",
    "    row = translation_df.ix[name,:]\n",
    "    return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "\n",
    "gt_base_data = {}\n",
    "at = 0\n",
    "for rec in reader:\n",
    "    snps = finder.fetch(rec.CHROM, rec.POS-1, rec.POS)\n",
    "    for snp in snps:\n",
    "        snp_id = \"%s_%d\" % (snp.CHROM, snp.POS)\n",
    "        for sample in snp.samples:\n",
    "            if not snp_id in gt_base_data:\n",
    "                gt_base_data[snp_id] = {}\n",
    "            sample_name = get_correct_name(sample.sample)\n",
    "            gt_base_data[snp_id][sample_name] = sample.gt_bases\n",
    "    at += 1\n",
    "    if at % 1000 == 0:\n",
    "        print(at)\n",
    "gt_base_df = pd.DataFrame(gt_base_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in gt_base_df.ix[:,0:30]:\n",
    "    print(col, gt_base_df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.put('gt_base_df', gt_base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df=hdf.get('gt_base_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.to_csv(os.path.join(analysis_dir, \"gt_base_df.csv\"), header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df = pd.read_csv(os.path.join(analysis_dir, \"gt_base_df.csv\"), index_col=0, sep=\"\\t\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(SNPassoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_cols = ['Mass','Pupual Duration','Total Dev Time']\n",
    "pheno_cols.extend(gt_base_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base = pheno.merge(gt_base_df, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base = pheno_gt_base[pheno_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_gt_base', pheno_gt_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca = pheno_gt_base.merge(pca_cov, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.columns = pheno_gt_base_pca.apply(lambda x: x.name.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.ix[:,0:3] = preprocessing.scale(pheno_gt_base_pca.ix[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca.ix[:,0:3].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_gt_base_pca', pheno_gt_base_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca=hdf.get('pheno_gt_base_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def snpassoc_filter(col):\n",
    "    if col.name.startswith(\"L\"):\n",
    "        if len(col.value_counts()) == 3:\n",
    "            return col.fillna(\"NA\")\n",
    "    else:\n",
    "        return col\n",
    "pheno_gt_base_pca_snpassoc = pheno_gt_base_pca.apply(snpassoc_filter).dropna(how=\"all\", axis=1)\n",
    "pheno_gt_base_pca_snpassoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca_snpassoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_gt_base_pca_snpassoc.to_csv(os.path.join(analysis_dir, \"pheno_gt_base_pca_snpassoc.txt\"),\n",
    "                         header=True,\n",
    "                         index=True,\n",
    "                         sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_snpassoc_files(df, input_file, num_pca_axes):\n",
    "    pheno = df.columns[0:3]\n",
    "    out_files = []\n",
    "    for p in pheno:\n",
    "        with open(os.path.join(analysis_dir, \"snpassoc_%s.R\" % p.lower()), \"w\") as o:\n",
    "            print(\"writing %s\" % o.name)\n",
    "            out_files.append(o.name)\n",
    "            text = '''\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('%s', sep=\"\\\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-%d)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-%d):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(%s~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9, data=snp_data, model=\"co\", genotypingRate=5)\n",
    "saveRDS(wg, \"wg_%s_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"wgstats_%s.rds\")\n",
    "''' % (input_file, \n",
    "       num_pca_axes,\n",
    "       num_pca_axes-1,\n",
    "       p, \n",
    "       p.lower(), \n",
    "       p.lower())\n",
    "        \n",
    "            o.write(text)\n",
    "    return out_files\n",
    "\n",
    "snpassoc_files = write_snpassoc_files(pheno_gt_base_pca_snpassoc, \n",
    "                          os.path.join(analysis_dir, \"pheno_gt_base_pca_snpassoc.txt\"),\n",
    "                         9)\n",
    "snpassoc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat {analysis_dir}/snpassoc_mass.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2/pheno_gt_base_pca_snpassoc.txt', sep=\"\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-9)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-8):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(Mass~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9, data=snp_data, model=\"co\", genotypingRate=5)\n",
    "saveRDS(wg, \"wg_mass_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"wgstats_mass.rds\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "wg_mass_co = readRDS(paste(analysis_dir, \"/wg_mass_co.rds\", sep=\"\"))\n",
    "wg_pd_co = readRDS(paste(analysis_dir, \"/wg_pupual_duration_co.rds\", sep=\"\"))\n",
    "wg_tdt_co = readRDS(paste(analysis_dir, \"/wg_total_dev_time_co.rds\", sep=\"\"))\n",
    "\n",
    "wgstats_mass = readRDS(paste(analysis_dir, \"/wgstats_mass.rds\", sep=\"\"))\n",
    "wgstats_pd = readRDS(paste(analysis_dir, \"/wgstats_pupual_duration.rds\", sep=\"\"))\n",
    "wgstats_tdt = readRDS(paste(analysis_dir, \"/wgstats_total_dev_time.rds\", sep=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wgstats_mass = r['wgstats_mass']\n",
    "wgstats_mass_labels = r('labels(wg_mass_co)')\n",
    "\n",
    "wgstats_pd = r['wgstats_pd']\n",
    "wgstats_pd_labels = r('labels(wg_pd_co)')\n",
    "\n",
    "wgstats_tdt = r['wgstats_tdt']\n",
    "wgstats_tdt_labels = r('labels(wg_tdt_co)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = com.convert_robj(wgstats_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in test:\n",
    "    print(pd.DataFrame(test[x]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "com.convert_robj(wgstats_mass_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals = {}\n",
    "\n",
    "wgstats = {\"mass\":[wgstats_mass, wgstats_mass_labels],\n",
    "           \"pd\":[wgstats_pd, wgstats_mass_labels],\n",
    "           \"tdt\":[wgstats_tdt, wgstats_mass_labels]}\n",
    "\n",
    "for key, datalist in list(wgstats.items()):\n",
    "    print(\"converting %s\" % key)\n",
    "    wgstats[key] = [com.convert_robj(x) for x in datalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_alleles(data):\n",
    "    a = set()\n",
    "    for x in data.index:\n",
    "        for elem in x.split(\"/\"):\n",
    "            a.add(elem)\n",
    "    return list(a)  \n",
    "\n",
    "def get_allele_freqs_wg(data, AA, Aa, aa):\n",
    "    total = np.sum(data['n'])*2\n",
    "    A = data.ix[AA, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    a = data.ix[aa, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    return A/total, a/total\n",
    "\n",
    "def get_genotypes(data, alleles):\n",
    "    homos = [\"%s/%s\" % (x,x) for x in alleles]\n",
    "    Aa = \"%s/%s\" % (alleles[0], alleles[1])\n",
    "    if Aa not in data.index:\n",
    "        Aa = Aa[::-1] #reverse it\n",
    "    AA, aa = homos\n",
    "    if data.ix[AA, \"n\"] < data.ix[aa, \"n\"]:\n",
    "        AA, aa = homos[::-1] #reverse it so that major is first\n",
    "    return AA, Aa, aa\n",
    "\n",
    "def get_genotypic_values(data, alleles):\n",
    "    AA, Aa, aa = get_genotypes(data, alleles)\n",
    "    G_AA = float(data.ix[AA, 'me'])\n",
    "    G_aa = float(data.ix[aa, 'me'])\n",
    "    additive = (G_AA-G_aa)/2\n",
    "    G_Aa = float(data.ix[Aa, 'me'])\n",
    "    dominance = G_Aa - ((G_AA+G_aa)/2)\n",
    "    return additive, dominance, AA, Aa, aa\n",
    "    \n",
    "def get_alpha(data):\n",
    "    alleles = get_alleles(data)\n",
    "    additive, dominance, AA, Aa, aa = get_genotypic_values(data, alleles)\n",
    "    p, q = get_allele_freqs_wg(data, AA, Aa, aa)\n",
    "    alpha = additive + (dominance*(q-p))\n",
    "    return alpha, AA, aa, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lt3 = {}\n",
    "errors = {}\n",
    "for p in wgstats:\n",
    "    print(\"running %s\" % p)\n",
    "    df = pd.DataFrame(index=[\"alpha\", \"p-value\", \"AA\", \"aa\", \"p\", \"q\"])\n",
    "    alpha_vals[p] = df\n",
    "    lt3[p] = 0\n",
    "    errors[p] = []\n",
    "    d = wgstats[p][0]\n",
    "    labels = wgstats[p][1]\n",
    "    for i, locus in enumerate(d):\n",
    "        try:\n",
    "            data = pd.DataFrame(d[locus])\n",
    "            snp = labels[i]\n",
    "            genotypes = [g for g in data.index if \"/\" in g]\n",
    "            data = data.ix[genotypes,:]\n",
    "            pvalue = data['p-value'].dropna()[0]\n",
    "            if len(genotypes) == 3:\n",
    "                alpha, AA, aa, p, q = get_alpha(data)\n",
    "                df[snp] = [alpha, pvalue, AA, aa, p, q]\n",
    "            elif len(genotypes) < 3:\n",
    "                lt3[p] += 1\n",
    "        except Exception as e: #needed for genotypes that are skipped b/c of genotyping rate\n",
    "            traceback.print_exc()\n",
    "#             print data\n",
    "#             print labels\n",
    "#             print d\n",
    "            errors[p].append(data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals['mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(alpha_vals['mass'].ix['alpha',:])\n",
    "plt.title(\"mass\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(alpha_vals['pd'].ix['alpha',:])\n",
    "plt.title(\"pd\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(alpha_vals['tdt'].ix['alpha',:])\n",
    "plt.title(\"tdt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write Berg/Coop files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = {}\n",
    "for pop, data in pca_maf.groupby('population'):\n",
    "    data = data.ix[:,:-2]\n",
    "    pop_allele_freqs[pop] = data.apply(get_allele_freqs, args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = pca_maf.apply(get_percent_missing)\n",
    "missing = DataFrame(missing)\n",
    "missing.columns = [\"missing\"]\n",
    "missing[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_gwas_data_file(df, pheno, outdir):\n",
    "    out = \"%s_gwas_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    df = df.sort_index()\n",
    "    df[['A1', 'A2', 'EFF', 'FRQ']].to_csv(out,\n",
    "                                          header=True, \n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "def write_freqs_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_freqs_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print(out)\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in list(pop_freqs.items()):\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))\n",
    "def write_match_pop_file(df, pheno, pop_freqs, pop, outdir):\n",
    "    out = \"%s_match_pop_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print(out)\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for key, data in list(pop_freqs.items()):\n",
    "            if key == pop:\n",
    "                m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "                m['population'] = pop\n",
    "                m.index.name = 'SNP'\n",
    "                m = m.sort_index()\n",
    "                o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                                 index=True,\n",
    "                                                                 sep=\"\\t\"))\n",
    "                break\n",
    "                \n",
    "def write_full_dataset_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_full_dataset_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print(out)\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in list(pop_freqs.items()):\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))   \n",
    "def write_env_var_data_file(pheno, pop_freqs, outdir):\n",
    "    out = \"%s_env_var_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print(out)\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 0\n",
    "        for pop in pop_freqs:\n",
    "            pop_id += 1\n",
    "            o.write(\"%s\\t%f\\t%d\\n\" % (pop, np.random.randn(), pop_id))\n",
    "                \n",
    "                \n",
    "for p in alpha_vals:\n",
    "    outdir = analysis_dir\n",
    "    full = alpha_vals[p].T\n",
    "    full = full.merge(missing, how=\"inner\", left_index=True, right_index=True)\n",
    "    full = full[(full['missing'] <= 0.2) & (full['missing'] >= 0.1)]\n",
    "    #full = full[(full['missing'] <= 0.3) & (full['missing'] >= 0.2)]\n",
    "    #full = full[(full['missing'] <= 0.3)]\n",
    "    full.index.name = \"SNP\"\n",
    "    full.AA = full.AA.apply(lambda x: x[0])\n",
    "    full.aa = full.aa.apply(lambda x: x[0])\n",
    "    full = full.rename(columns={'alpha':'EFF',\n",
    "                                'AA':'A1',\n",
    "                                'aa':'A2',\n",
    "                                'p': 'FRQ'})\n",
    "    candidates = full[full['p-value']<0.05]\n",
    "    write_gwas_data_file(candidates, p, outdir)\n",
    "    write_freqs_file(candidates, p, pop_allele_freqs, outdir)\n",
    "    write_match_pop_file(full, p, pop_allele_freqs, \"QC32\", outdir)\n",
    "    write_full_dataset_file(full, p, pop_allele_freqs, outdir)\n",
    "    write_env_var_data_file(p, pop_allele_freqs, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squat_dir = \"/home/cfriedline/eckertlab/src/PolygenicAdaptationCode/Scripts/\"\n",
    "def get_squat_vars(pheno):\n",
    "    d = {\"gwas.data.file\":\"'../%s_gwas_data_file.txt'\" % pheno,\n",
    "         \"freqs.file\":\"'../%s_freqs_file.txt'\" % pheno,\n",
    "         \"env.var.data.files\":\"list('../%s_env_var_data_file.txt')\" % pheno,\n",
    "         \"match.pop.file\":\"'../%s_match_pop_file.txt'\" % pheno,\n",
    "         \"full.dataset.file\":\"'../%s_full_dataset_file.txt'\" % pheno,\n",
    "         \"path\":\"'%s'\" % pheno,\n",
    "         \"match.categories\":\"c('MAF')\",\n",
    "         \"match.bins\":\"list(seq(0,0.5,0.02), c(2), seq(0,1000,100))\",\n",
    "         \"cov.SNPs.per.cycle\":5000,\n",
    "         \"cov.cycles\":1,\n",
    "         \"null.phenos.per.cycle\":1000,\n",
    "         \"null.cycles\":1,\n",
    "         \"load.cov.mat\":\"F\",\n",
    "         \"sim.null\":\"T\",\n",
    "         \"check.allele.orientation\":\"F\"}\n",
    "    return ',\\n'.join(\"%s=%s\" % (key,val) for (key,val) in d.items())\n",
    "\n",
    "def create_squat_run_file(pheno):\n",
    "    out_dir = os.path.join(analysis_dir, \"squat\")\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    squat_file = os.path.join(out_dir, \"squat_%s.r\" % pheno)\n",
    "    with open(squat_file, \"w\") as o:\n",
    "        o.write(\"setwd('/home/cfriedline/eckertlab/src/PolygenicAdaptationCode')\\n\")\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"CreateTraitFile.R\"))\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"functions.R\"))\n",
    "        o.write(\"setwd('%s')\\n\" % out_dir)\n",
    "        o.write(\"PolygenicAdaptationFunction(%s)\\n\" % get_squat_vars(pheno))\n",
    "    return squat_file\n",
    "\n",
    "for pheno in alpha_vals:\n",
    "    squat_file = create_squat_run_file(pheno)\n",
    "    print squat_file\n",
    "    !cat $squat_file\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_squat():\n",
    "    for p in [\"mass\", \"pd\",\"tdt\"]:\n",
    "        print \"running %s\" % p\n",
    "        output = os.path.join(analysis_dir,\"squat/%s\" % p)\n",
    "        if os.path.exists(output):\n",
    "            !rm -rf {output}\n",
    "        r('setwd(\"%s\")' % analysis_dir)\n",
    "        print 'source(\"%s/squat/squat_%s.r\")' % (analysis_dir, p)\n",
    "        r('source(\"%s/squat/squat_%s.r\")' % (analysis_dir, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_squat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfiles = !find {analysis_dir}/squat | grep Robj | grep Output\n",
    "bc = {}\n",
    "for f in rfiles:\n",
    "    d = f.split(\"/\")\n",
    "    trait = d[-3]\n",
    "    if not trait in bc:\n",
    "        bc[trait] = []\n",
    "    bc[trait].append(f)\n",
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pheno in bc:\n",
    "    print(pheno)\n",
    "    for obj in bc[pheno]:\n",
    "        r('load(\"%s\")' % obj)\n",
    "    print(r(\"the.stats\"))\n",
    "    print(\"------------\")\n",
    "    print(r(\"p.vals\"))\n",
    "    print(\"XXXXXXXXXXXXXXXXXXXXXXXXXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Run BEAGLE to impute missing genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_col = split_df.index\n",
    "split_df.insert(0, \"id\", id_col)\n",
    "split_df.insert(0, \"I\", \"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_df.to_csv(os.path.join(analysis_dir, \"input.bgl\"), sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "java -Xmx20g -jar /home/cfriedline/eckertlab/src/beagle_3.3.2/beagle.jar \\\n",
    "unphased=input.bgl \\\n",
    "missing='?' \\\n",
    "out=beagle_output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased = pd.read_csv(gzip.open(os.path.join(analysis_dir, \"beagle_output.input.bgl.phased.gz\")), sep=\" \")\n",
    "phased.index = phased['id']\n",
    "phased = phased.drop([\"I\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_dict = phased.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_comb = {}\n",
    "for snp, sample_data in list(phased_dict.items()):\n",
    "    phased_comb[snp] = {}\n",
    "    samples = [x[:-2] for x in sample_data]\n",
    "    for s in samples:\n",
    "        phased_comb[snp][s] = sample_data[\"%s_1\" % s] + \"/\" + sample_data[\"%s_2\" % s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_df = DataFrame(phased_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df_50_perc_polymorphic_maf_fis = hdf.get('z12_df_50_perc_polymorphic_maf_fis')\n",
    "duplicates = z12_df_50_perc_polymorphic_maf_fis[z12_df_50_perc_polymorphic_maf_fis.duplicate==\"1\"]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df = phased_df.drop(duplicates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_z12(locus):\n",
    "    alleles = set()\n",
    "    counts = locus.value_counts()\n",
    "    num_individuals = sum(counts)\n",
    "    c = {}\n",
    "    for i, val in enumerate(counts):\n",
    "        for allele in counts.index[i].split(\"/\"):\n",
    "            if not allele in c:\n",
    "                c[allele] = 0\n",
    "            c[allele] += val\n",
    "    c = sorted(list(c.items()), key=lambda x:x[1], reverse=True)\n",
    "    A = c[0][0]\n",
    "    P = c[0][1]\n",
    "    a = c[1][0]\n",
    "    Q = c[1][1]\n",
    "    total = P+Q*1.0\n",
    "    p = P/total\n",
    "    q = Q/total\n",
    "    hets = [\"%s/%s\" % (A,a),\"%s/%s\" % (A,a)]\n",
    "    PQ = 0\n",
    "    for het in hets:\n",
    "        if het in counts:\n",
    "            PQ += counts[het]\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    af = [A,a,P,Q,p,q,Fis,He,Ho]\n",
    "    trans = {\"%s/%s\" % (A,A): 0,\n",
    "             \"%s/%s\" % (a,a): 2,\n",
    "             \"%s/%s\" % (A,a): 1,\n",
    "             \"%s/%s\" % (a,A): 1}\n",
    "    phased_af[locus.name] = af\n",
    "    z12 = locus.apply(lambda x: trans[x])\n",
    "    return z12\n",
    "\n",
    "phased_af = DataFrame(index=[\"A\",\"a\",\"P\",\"Q\",\"p\",\"q\",\"Fis\",\"He\",\"Ho\"], \n",
    "                      columns=phased_df.columns)\n",
    "phased_z12 = phased_df.apply(convert_to_z12)\n",
    "phased_z12[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_af[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_df', phased_df)\n",
    "hdf.put('phased_af', phased_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_af.T['q'], bins=100)\n",
    "plt.title(\"MAF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_af.T[['Fis','Ho','He','p','q']].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_maf_drop = phased_af.T[phased_af.T['q']<0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf = phased_z12.drop(phased_maf_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_Fis_drop = phased_af.T[(phased_af.T['Fis'] < -0.5) | (phased_af.T['Fis'] > 0.5)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis = phased_z12_maf.drop(phased_Fis_drop.intersection(phased_z12_maf.columns), \n",
    "                                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_monomorphic = phased_z12_maf_fis.apply(is_monomorphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_monomorphic[phased_monomorphic==True] #none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_hierf_trans2(series):\n",
    "    return series.apply(lambda x: hierf_trans[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf = phased_z12_maf_fis.apply(apply_hierf_trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
    "response = urllib.request.urlopen(url)\n",
    "pheno = pd.read_excel(response, \"Males-forGenomics-final\")\n",
    "pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
    "for x in pheno.index:\n",
    "    pheno.ix[x, 'sample_pheno'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno['sample_id'] = pheno.apply(lambda x: \"%s_0\" % x.sample_pheno, axis=1)\n",
    "pheno.index = pheno['sample_id']\n",
    "pheno = pheno.drop('sample_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno', pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf['population'] = phased_hierf.apply(lambda row: row.name.split(\"_\")[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf2 = phased_hierf.apply(assign_popid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_cols = ['popid']\n",
    "hierf_cols.extend(sorted(phased_hierf2.columns[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf3 = phased_hierf2.reindex(columns=hierf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_hierf3[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf2.ix[0:5,[\"L10\",\"L100047\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_hierf3.popid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_hierf3.to_csv(os.path.join(analysis_dir, \"hierfstat_phased.txt\"), header=True, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```R\n",
    "library(hierfstat)\n",
    "data = read.table(\"hierfstat_phased.txt\", header=T, sep=\"\\t\")\n",
    "levels = data.frame(data$popid)\n",
    "loci = data[,2:ncol(data)]\n",
    "res = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "saveRDS(res, \"hierfstat_phased.rds\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "res = readRDS(paste(analysis_dir, \"hierfstat_phased.rds\", sep=\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = com.convert_robj(robjects.r('res'))\n",
    "loc_df = res['loc']\n",
    "F_df = res['F']\n",
    "overall_df = res['overall']\n",
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_fst = loc_df.apply(compute_fst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_fst', phased_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_fst, bins=50)\n",
    "plt.title(\"$n=%d \\ \\mu=%.2f \\pm %.2f \\ [%.2f, %.2f]$\" % (len(phased_fst), \n",
    "                                                    np.mean(phased_fst), \n",
    "                                                    np.std(phased_fst),\n",
    "                                                    np.min(phased_fst), \n",
    "                                                    np.max(phased_fst)))\n",
    "plt.xlim(0, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(phased_af.T.Fis, bins=50)\n",
    "d = phased_af.T.Fis\n",
    "plt.title(\"$\\mu=%.4f \\pm %.4f \\ [%.2f, %.2f]$ \" % (np.mean(d), \n",
    "                                                 np.std(d),\n",
    "                                                np.min(d),\n",
    "                                                np.max(d)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.in_store(\"phased_af\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_phased(locus):\n",
    "    if locus.name.startswith(\"L\"):\n",
    "        maf = phased_af.ix['q',locus.name]\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis_std = phased_z12_maf_fis.apply(center_and_standardize_phased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_z12_maf_fis_std[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prcomp_phased = prcomp(phased_z12_maf_fis_std, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print((summary(prcomp_phased)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_x = com.convert_robj(prcomp_phased.rx2(\"x\"))\n",
    "phased_x.index = phased_z12_maf_fis_std.index\n",
    "phased_joined = phased_x.join(phased_z12_maf_fis)\n",
    "phased_joined['population'] = phased_joined.apply(lambda row: row.name.split(\"_\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))\n",
    "legend = {}\n",
    "for row in phased_joined.iterrows():\n",
    "    pop = row[1]['population']\n",
    "    n = norm(pop_id[pop])\n",
    "    color = cm.hsv(n)\n",
    "    legend[pop] = color\n",
    "    plt.scatter(row[1].PC1, \n",
    "                row[1].PC2, \n",
    "                s=50, \n",
    "                c=color)\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "cmap = plt.get_cmap()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.title(\"PCA of n=%d samples on %d loci\" % (len(phased_joined), \n",
    "                                              len(phased_z12_maf_fis.columns)))\n",
    "plt.xlabel(\"PC1 (4.716%)\")\n",
    "plt.ylabel(\"PC2 (2.645%)\")\n",
    "\n",
    "handles = []\n",
    "for pop in sorted(legend):\n",
    "    handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "plt.legend(handles=sorted(handles))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TWcalc = r('TWcalc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw = TWcalc(phased_z12_maf_fis_std.values, 15)\n",
    "print(phased_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw_p = com.convert_robj(phased_tw.rx2(2))\n",
    "phased_tw_e = com.convert_robj(phased_tw.rx2(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_tw_num = 0\n",
    "for i, p in enumerate(phased_tw_p):\n",
    "    print(p)\n",
    "    if p > 0.05:\n",
    "        phased_tw_num = i\n",
    "        break\n",
    "print(\"Tracy-Widom test yields %d axes of pop structure\" % phased_tw_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "8e-09\n",
    "7.9e-08\n",
    "0.000142452\n",
    "0.007395547\n",
    "0.134556018\n",
    "Tracy-Widom test yields 10 axes of pop structure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_pca_cov = phased_x.ix[:,0:phased_tw_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_pca_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_pca_cov', phased_pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_pca_phased_z12_maf_fis = pheno.join(phased_pca_cov, how='inner').join(phased_z12_maf_fis, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df_filtered = phased_df.ix[phased_z12_maf_fis.index, phased_z12_maf_fis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_cols = ['Mass','Pupual Duration','Total Dev Time']\n",
    "pheno_cols.extend(phased_df_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered = pheno.join(phased_df_filtered, how='inner')\n",
    "pheno_phased_df_filtered = pheno_phased_df_filtered[pheno_cols]\n",
    "pheno_phased_df_filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered.ix[:,0:3] = preprocessing.scale(pheno_phased_df_filtered.ix[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered_pca_cov = pheno_phased_df_filtered.join(phased_pca_cov, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_phased_df_filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.put('pheno_phased_df_filtered_pca_cov', pheno_phased_df_filtered_pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc = pheno_phased_df_filtered_pca_cov.apply(snpassoc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phased_snpassoc = phased_snpassoc.dropna(how=\"all\", axis=1)\n",
    "phased_snpassoc.columns = [x.replace(\" \", \"_\") for x in phased_snpassoc.columns]\n",
    "phased_snpassoc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put('phased_snpassoc', phased_snpassoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc.to_csv(os.path.join(analysis_dir, \"phased_snpassoc.txt\"),\n",
    "                     header=True,\n",
    "                     index=True,\n",
    "                     sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_phased_snpassoc_files(df, input_file, num_pca_axes):\n",
    "    pheno = df.columns[0:3]\n",
    "    out_files = []\n",
    "    for p in pheno:\n",
    "        with open(os.path.join(analysis_dir, \"snpassoc_%s_phased.R\" % p.lower()), \"w\") as o:\n",
    "            print(\"writing %s\" % o.name)\n",
    "            out_files.append(o.name)\n",
    "            text = '''\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('%s', sep=\"\\\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-%d)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-%d):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(%s~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10, data=snp_data, model=\"co\")\n",
    "\n",
    "saveRDS(wg, \"phased_wg_%s_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"phased_wgstats_%s.rds\")\n",
    "''' % (input_file, \n",
    "       num_pca_axes,\n",
    "       num_pca_axes-1,\n",
    "       p, \n",
    "       p.lower(), \n",
    "       p.lower())\n",
    "        \n",
    "            o.write(text)\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phased_snpassoc_files = write_phased_snpassoc_files(phased_snpassoc,\n",
    "                                                    os.path.join(analysis_dir, \"phased_snpassoc.txt\"),\n",
    "                                                    10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat {analysis_dir}/snpassoc_mass_phased.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2/phased_snpassoc.txt', sep=\"\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 4:(ncol(d)-10)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-9):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(Mass~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10, data=snp_data, model=\"co\")\n",
    "\n",
    "saveRDS(wg, \"phased_wg_mass_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"phased_wgstats_mass.rds\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
