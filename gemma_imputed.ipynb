{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import dill\n",
    "import random\n",
    "import vcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%load_ext rpy2.ipython\n",
    "r = ro.r\n",
    "%matplotlib inline\n",
    "from utils import save_df, read_df\n",
    "from IPython.display import display\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\"\n",
    "snp_file_gz = \"isect_snps.recode.vcf.gz_sorted.vcf.gz\"\n",
    "tabix = \"/home/cfriedline/g/src/htslib-1.3/tabix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write GEMMA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = read_df(analysis_dir, 'pca_std_pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno = pca_std_pheno[[\"Population\",\n",
    "                              \"Number\",\n",
    "                              \"Mass\",\n",
    "                              \"Pupual Duration\",\n",
    "                              \"Total Dev Time\"]]\n",
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, 'gemma_pheno', gemma_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_x = read_df(analysis_dir, 'pca_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno = gemma_pheno.join(pca_x, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno_pca = pca_std_pheno[[x for x in pca_std_pheno if \"PC\" in x or 'Mass' in x or 'Pupual' in x or 'Total Dev' in x]]\n",
    "gemma_pheno_pca.columns = [x.replace(\" \", \"_\") for x in gemma_pheno_pca.columns]\n",
    "gemma_pheno_pca.index = [x for x in gemma_pheno_pca.index]\n",
    "phenos = [\"Mass\", \"Pupual_Duration\", \"Total_Dev_Time\"]\n",
    "for p in phenos:\n",
    "    mod = smf.ols(formula=\"%s~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13+PC14+PC15\" % p, data=gemma_pheno_pca)\n",
    "    res = mod.fit()\n",
    "    col = \"%s_resid\" % p\n",
    "    col = col.lower()\n",
    "    gemma_pheno[col] = res.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = read_df(analysis_dir, 'z12_swapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df = read_df(analysis_dir, 'z12_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_base_df = read_df(analysis_dir, \"gt_base_df\")\n",
    "gt_ref_alt_df = read_df(analysis_dir, 'gt_ref_alt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df_swapped = read_df(analysis_dir, \"gt_base_df_swapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_ref_alt_minor_major = read_df(analysis_dirlysis_dir, \"gt_ref_alt_minor_major\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gemma_gt = read_df(analysis_dirlysis_dir, \"_pimass_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gemma_pheno = read_df(analysis_dir, \"_pimass_pheno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"_gemma_gt\", gemma_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(analysis_dir, \"_gemma_pheno\", gemma_pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gemma_dir = os.path.join(analysis_dir, \"gemma_run\")\n",
    "if not os.path.exists(gemma_dir):\n",
    "    os.mkdir(gemma_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_pheno.massx.to_csv(os.path.join(gemma_dir, \"gemma_mass.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.tdtx.to_csv(os.path.join(gemma_dir, \"gemma_tdt.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.pdx.to_csv(os.path.join(gemma_dir, \"gemma_pd.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_pheno.to_csv(os.path.join(gemma_dir, \"gemma_pheno.txt\"),\n",
    "                                     index=True,\n",
    "                                     header=True)\n",
    "gemma_pheno[['massx', 'pdx', 'tdtx']].to_csv(os.path.join(gemma_dir, \"gemma_all_pheno.txt\"),\n",
    "                                     index=False,\n",
    "                                     header=False)\n",
    "gemma_gt.to_csv(os.path.join(gemma_dir, \"gemma_gt.txt\"),\n",
    "                index=True,\n",
    "                header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_contigs = {}\n",
    "with open(os.path.join(gemma_dir, \"gemma_loc.txt\"), \"w\") as o:    \n",
    "    for x in gemma_gt.index:\n",
    "        data = x.split(\"_\")\n",
    "        contig = \"_\".join(data[0:-1])\n",
    "        pos = data[-1]\n",
    "        if not contig in gemma_contigs:\n",
    "            gemma_contigs[contig] = []\n",
    "        gemma_contigs[contig].append(pos)\n",
    "    \n",
    "    chrom_id = 1\n",
    "    for contig, positions in list(gemma_contigs.items()):\n",
    "        for p in positions:\n",
    "            o.write(\"%s_%s\\t%s\\t%d\\n\" % (contig, p, p, chrom_id))\n",
    "        chrom_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GEMMA commands for Gypsy Moth\n",
    "\n",
    "## Estimate Relatedness Matrix from Genotypes\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -gk [num] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-gk 1 -o gm\n",
    "```\n",
    "\n",
    "## Perform Eigen-Decomposition of the Relatedness Matrix\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -k [filename] -eigen -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-k output/gm.cXX.txt -eigen -o gm\n",
    "```\n",
    "\n",
    "## Association Tests with Univariate Linear Mixed Models\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -lmm [num] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-n 1 -a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -o mass_lmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-n 2 -a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -o pd_lmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-n 3 -a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -o tdt_lmm\n",
    "```\n",
    "\n",
    "## Association Tests with Multivariate Linear Mixed Models\n",
    "\n",
    "For this test, all three phenotype files were combined into a single file, with 3 columns in this order: mass, pd, tdt.\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -lmm [num] -n [num1] [num2] [num3] -o [prefix]`\n",
    "\n",
    "```bash\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -n 1 2 -o mass_pd_mlmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -n 1 3 -o mass_tdt_mlmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -n 2 3 -o pd_tdt_mlmm\n",
    "\n",
    "~/g/src/gemma-0.94.1/gemma -g gemma_gt.txt -p gemma_all_pheno.txt \\\n",
    "-a gemma_loc.txt -k output/gm.cXX.txt -lmm 4 -n 1 2 3 -o mass_pd_tdt_mlmm\n",
    "```\n",
    "## Fit a Bayesian Sparse Linear Mixed Model\n",
    "\n",
    "First, set up a qsub script: `bslmm.sh` and `chmod +x` it\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#$ -N BSLMM\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -j y\n",
    "#$ -l mem_free=20G\n",
    "$HOME/g/src/gemma-0.94.1/gemma -g $1 -p $2 -a $3 -k $4 -bslmm $5 -o $6\n",
    "```\n",
    "\n",
    "Now, the scripts:\n",
    "\n",
    "`./gemma -g [filename] -p [filename] -a [filename] -k [filename] -bslmm [num] -o [prefix]`\n",
    "\n",
    "### Standard BSLMM (4 chains)\n",
    "\n",
    "```bash \n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"mass_bslmm_std \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"pd_bslmm_std \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"tdt_bslmm_std \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "```bash \n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"mass_bslmm_std_1 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"pd_bslmm_std_1 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"tdt_bslmm_std_1 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "```bash \n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"mass_bslmm_std_2 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"pd_bslmm_std_2 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"tdt_bslmm_std_2 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "```bash \n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_mass.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"mass_bslmm_std_3 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_pd.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"pd_bslmm_std_3 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "qsub bslmm.sh \"gemma_gt.txt\" \"gemma_tdt.txt\" \"gemma_loc.txt\" \\\n",
    "\"output/gm.cXX.txt\" \"1\" \"tdt_bslmm_std_3 \\\n",
    "-w 1000000 -s 100000000 -smin 1 -smax 300 -hmin 0.01 -hmax 0.9 -pmin -3 -pmax 0 -rpace 1000\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze and process GEMMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "assembly = \"/home/cfriedline/eckertlab/projects/gypsy_moth/assemblies/masurca3/CA/10-gapclose/genome.ctg.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "filedir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/gemma_run/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bslmm = !ls {filedir}/*bslmm*.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(bslmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(coda)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_mcmc = r('plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makehash():\n",
    "    return collections.defaultdict(makehash)\n",
    "\n",
    "def split_bslmm_by_pheno(bslmm):\n",
    "    h = makehash()\n",
    "    for f in bslmm:\n",
    "        d = os.path.basename(f).split(\"_\")\n",
    "        pheno = d[0]\n",
    "        o = d[-1].split(\".\")\n",
    "        out = o[1]\n",
    "        num = o[0]\n",
    "        if num == 'std':\n",
    "            num = 0\n",
    "        h[pheno][out][num] = f\n",
    "    return h\n",
    "bslmm_dict = split_bslmm_by_pheno(bslmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_files(key):\n",
    "    d = defaultdict(list)\n",
    "    for pheno, data in bslmm_dict.items():\n",
    "        for n in data[key]:\n",
    "            d[pheno].append(data[key][n])\n",
    "    return d\n",
    "    \n",
    "hyp_files = collect_files(\"hyp\")\n",
    "param_files = collect_files(\"param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyp_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r('eff_size=list()')\n",
    "r('mcmc_summary=list()')\n",
    "r('mcmc_lists=list()')\n",
    "for pheno, files in hyp_files.items():\n",
    "    print(pheno)\n",
    "    r(\"m_list=list()\")\n",
    "    %R -i pheno\n",
    "    for i, hyp_file in enumerate(files):\n",
    "        lines = open(hyp_file).readlines()\n",
    "        if len(lines) < 10:\n",
    "            continue\n",
    "        data = []\n",
    "        for l in lines:\n",
    "            l = l.strip().split(\"\\t\")\n",
    "            data.append(l)\n",
    "        hyp = pd.DataFrame(data[1:], columns=data[0], dtype=float)\n",
    "        hyp.columns = [x.strip() for x in hyp.columns]\n",
    "        hyp.to_csv(hyp_file, sep=\"\\t\", header=True, index=False)\n",
    "        %R -i hyp_file\n",
    "        r(\"m = mcmc(fread('%s', sep='\\t', , header=T, data.table=F), thin=1000)\" % hyp_file)\n",
    "        r(\"m_list$%s = m\" % os.path.basename(hyp_file))\n",
    "    r(\"mcmc_list = mcmc.list(m_list)\")\n",
    "    r(\"mcmc_lists$%s = mcmc_list\" % pheno) \n",
    "    r(\"eff_size$%s = effectiveSize(mcmc_list)\" % pheno)\n",
    "    r(\"mcmc_summary$%s = summary(mcmc_list)\" % pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i filedir\n",
    "r(\"saveRDS(mcmc_lists, file='%s')\" % os.path.join(filedir, \"mcmc_lists.rds\"));\n",
    "r(\"saveRDS(mcmc_summary, file='%s')\" % os.path.join(filedir, \"mcmc_summary.rds\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(r('eff_size'))\n",
    "print(r('mcmc_summary'))\n",
    "for pheno in hyp_files:\n",
    "    print(pheno, r('gelman.diag(mcmc_lists$%s, autoburnin=F)' % pheno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "eff_size$mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls {filedir}/*.mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "print(\"mass\")\n",
    "mcmc_lists = readRDS(paste(filedir, '/mcmc_lists.rds', sep=''))\n",
    "plot(mcmc_lists$mass)\n",
    "print(\"pd\")\n",
    "plot(mcmc_lists$pd)\n",
    "print(\"tdt\")\n",
    "plot(mcmc_lists$tdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_param_dfs(files):\n",
    "    dfs = {}\n",
    "    for pheno, filelist in files.items():\n",
    "        dfs[pheno] = pd.DataFrame()\n",
    "        df = None\n",
    "        for f in filelist:\n",
    "            fdata = os.path.basename(f).split(\".\")[0].split(\"_\")\n",
    "            num = 0\n",
    "            \n",
    "            if len(fdata) > 3:\n",
    "                num = int(fdata[-1])\n",
    "            \n",
    "            if num == 0:\n",
    "                df = pd.read_csv(f, sep=\"\\t\", index_col=1)\n",
    "            else:\n",
    "                df = df.join(pd.read_csv(f, sep=\"\\t\", index_col=1), rsuffix=\"_%d\" % num)\n",
    "        df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "        dfs[pheno] = df\n",
    "    return dfs\n",
    "param_dfs = get_param_dfs(param_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hyp_dfs(files):\n",
    "    dfs = {}\n",
    "    for pheno, filelist in files.items():\n",
    "        df = None\n",
    "        for f in filelist:\n",
    "            fdata = os.path.basename(f).split(\".\")[0].split(\"_\")\n",
    "            num = 0\n",
    "            \n",
    "            if len(fdata) > 3:\n",
    "                num = int(fdata[-1])\n",
    "            \n",
    "            if num == 0:\n",
    "                df = pd.read_csv(f, sep=\"\\t\")\n",
    "            else:\n",
    "                df = df.join(pd.read_csv(f, sep=\"\\t\"), rsuffix=\"_%d\" % num)\n",
    "        df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "        dfs[pheno] = df\n",
    "    return dfs\n",
    "hyp_dfs = get_hyp_dfs(hyp_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hmean_row(row):\n",
    "    try:\n",
    "        return sp.stats.hmean(row)\n",
    "    except ValueError as e:\n",
    "        return np.nan   \n",
    "\n",
    "def get_hmean(param):\n",
    "    d = {}\n",
    "    for pheno in param_dfs:\n",
    "        df = param_dfs[pheno]\n",
    "        g = pd.DataFrame(df[[x for x in df if param in x]])\n",
    "        #m = g.apply(get_hmean_row, axis=1)\n",
    "        m = g.apply(np.mean, axis=1)\n",
    "        g['%s_hmean' % param] = m\n",
    "        d[pheno] = g\n",
    "    return d\n",
    "\n",
    "gamma_dfs = get_hmean('gamma')\n",
    "beta_dfs = get_hmean('beta')\n",
    "alpha_dfs = get_hmean('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_dfs = {}\n",
    "for pheno in gamma_dfs:\n",
    "    a = alpha_dfs[pheno]['alpha_hmean']\n",
    "    b = beta_dfs[pheno]['beta_hmean']\n",
    "    g = gamma_dfs[pheno]['gamma_hmean']\n",
    "    t = pd.concat((a, b, g), axis=1)\n",
    "    plt.scatter(t['alpha_hmean'], t['beta_hmean'])\n",
    "    plt.xlim(np.min(a), np.max(a))\n",
    "    plt.ylim(np.min(b), np.max(b))\n",
    "    plt.ylabel(\"beta mean\")\n",
    "    plt.xlabel(\"alpha mean\")\n",
    "    plt.title(pheno)\n",
    "    plt.show()\n",
    "    t = np.abs(t)\n",
    "    t['total_effect'] = t.apply(lambda x: x.alpha_hmean + x.beta_hmean, axis=1)\n",
    "    combined_dfs[pheno] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in combined_dfs:\n",
    "    print(pheno)\n",
    "    display(combined_dfs[pheno].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_unweighted, venn3_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps = {}\n",
    "for pheno in combined_dfs:\n",
    "    d = combined_dfs[pheno]\n",
    "    x = 'gamma_hmean'\n",
    "    for q in [0.995, 0.999]:\n",
    "        x99_cutoff = d[x].quantile(q)\n",
    "        xvals = d[x][d[x] >= x99_cutoff] \n",
    "        for y in ['alpha_hmean', 'beta_hmean', 'total_effect']:\n",
    "            y99_cutoff = d[y].quantile(q)\n",
    "            yvals = d[y][d[y] >= y99_cutoff]\n",
    "            isect = set(xvals.index).intersection(set(yvals.index))\n",
    "            effect_snps[pheno, x, y, q] = isect\n",
    "            print(pheno, x, y, q, len(isect))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(filedir, \"effect_snps.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(effect_snps, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in effect_snps:\n",
    "    k = [str(x) for x in key]\n",
    "    out = os.path.join(filedir, \"%s_effect.txt\" % \"-\".join(k))\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"\\n\".join(effect_snps[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(filedir, \"combined_dfs.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(combined_dfs, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "venn_data = {}\n",
    "for pheno in combined_dfs:\n",
    "    d = combined_dfs[pheno]\n",
    "    x = 'gamma_hmean'\n",
    "    venn_data[pheno] = {}\n",
    "    for q in [0.995, 0.999]:\n",
    "        venn_data[pheno][q] = []\n",
    "        x99_cutoff = d[x].quantile(q)\n",
    "        xvals = d[x][d[x] >= x99_cutoff] \n",
    "        venn_data[pheno][q].append(set(xvals.index))\n",
    "        for y in ['alpha_hmean', 'beta_hmean']:\n",
    "            y99_cutoff = d[y].quantile(q)\n",
    "            yvals = d[y][d[y] >= y99_cutoff]\n",
    "            venn_data[pheno][q].append(set(yvals.index))\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "for pheno, d in venn_data.items():\n",
    "    for q in d:\n",
    "        venn3(d[q], (\"gamma\", \"alpha\", \"beta\"))\n",
    "        plt.title(\"%s_%.3f\" % (pheno, q))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in combined_dfs:\n",
    "    d = combined_dfs[pheno]\n",
    "    x = 'gamma_hmean'\n",
    "    y = 'total_effect'\n",
    "    sns.lmplot(x, y, d)\n",
    "    plt.xlim(np.min(d[x]), np.max(d[x]))\n",
    "    plt.ylim(np.min(d[y]), np.max(d[y]))\n",
    "    plt.title(pheno)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_fst = read_df(analysis_dir, \"loci_fst\")\n",
    "loci_fst.columns = [\"Fst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in combined_dfs:\n",
    "    d = combined_dfs[pheno]\n",
    "    j = d.join(loci_fst, how=\"inner\")\n",
    "    x = 'Fst'\n",
    "    y = 'total_effect'\n",
    "    sns.lmplot(x, y, j)\n",
    "    plt.xlim(np.min(j[x]), np.max(j[x]))\n",
    "    plt.ylim(np.min(j[y]), np.max(j[y]))\n",
    "    plt.title(pheno)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
