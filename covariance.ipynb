{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os, sys\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import vcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "import shutil\n",
    "from utils import read_df, save_df\n",
    "from pathlib import Path, PurePath\n",
    "from ipyparallel import Client\n",
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "from scipy.stats import mannwhitneyu, ks_2samp, f_oneway\n",
    "import tables\n",
    "import ujson\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gemma_dir = os.path.join(analysis_dir, \"gemma_run\")\n",
    "gemma_dir = os.path.join(gemma_imputed.ipynba_dir, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ni_data = read_df(\"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni\", \"z12_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_missing(snp):\n",
    "    c = snp.value_counts()\n",
    "    if not -1 in c:\n",
    "        return 0\n",
    "    return c[-1]/np.sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing = ni_data.apply(percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenos = [\"mass\", \"tdt\", \"pd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_dfs = pickle.load(open(os.path.join(gemma_dir, \"combined_dfs.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps = pickle.load(open(os.path.join(gemma_dir, \"effect_snps.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df = read_df(analysis_dir, 'gt_base_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = sorted(set([x.split(\"_\")[0] for x in gt_base_df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_genotypes(snp):\n",
    "    counts = Counter()\n",
    "    for gt in snp:\n",
    "        try:\n",
    "            float(gt) #if gt is nan\n",
    "        except:\n",
    "            counts[gt[0]]+=1\n",
    "            counts[gt[-1]]+=1\n",
    "    return sorted(counts.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df['population'] = gt_base_df.apply(lambda x: x.name.split(\"_\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_data = {}\n",
    "\n",
    "def add_allele_freq(gt_list):\n",
    "    data = gt_list\n",
    "    ret = OrderedDict()\n",
    "    if len(gt_list) == 2:\n",
    "        total = data[0][1]+data[1][1]\n",
    "        ret[data[0][0]] = [data[0][1], data[0][1]/total]\n",
    "        ret[data[1][0]] = [data[1][1], data[1][1]/total]\n",
    "    else:\n",
    "        ret[data[0][0]] = [data[0][1], 1.0]\n",
    "    return ret\n",
    "\n",
    "for group, data in gt_base_df.groupby('population'):\n",
    "    data = data.drop('population', axis=1)\n",
    "    print(group, data.shape)\n",
    "    gt = data.apply(count_genotypes).apply(add_allele_freq)\n",
    "    pop_allele_data[group] = gt.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt = read_df(analysis_dir, '_gemma_gt').replace(\"NA\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pop_allele_data['VA1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_counts = gt_base_df.apply(count_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af = gt_counts.apply(add_allele_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['gemma_gt'] = gemma_gt\n",
    "\n",
    "dview['pops'] = pops\n",
    "\n",
    "dview['analysis_dir'] = analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "import os, pickle, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"pop_allele_data.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(pop_allele_data, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "if not 'pop_allele_data' in dir():\n",
    "    pop_allele_data = pickle.load(open(os.path.join(analysis_dir, \"pop_allele_data.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_obs_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    for gt in snp:\n",
    "        if gt[0] != gt[-1]:\n",
    "            het += 1\n",
    "        if gt[1] == \"/\" or gt[1] == \"|\":\n",
    "            total += 1\n",
    "    return het/total\n",
    "\n",
    "def compute_exp_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    c = Counter()\n",
    "    for gt in snp:\n",
    "        c[gt[0]] += 1\n",
    "        c[gt[-1]] += 1\n",
    "    total = np.sum(list(c.values()))\n",
    "    He = 2\n",
    "    for a in c:\n",
    "        He *= (c[a]/total)\n",
    "    return He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "het_bins = np.linspace(0,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "He = gt_base_df.drop(\"population\", axis=1).apply(compute_exp_heterozygosity)\n",
    "He = pd.DataFrame(He, columns=[\"He\"])\n",
    "He['rs'] = He.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ho = gt_base_df.drop(\"population\", axis=1).apply(compute_obs_heterozygosity)\n",
    "Ho = pd.DataFrame(Ho, columns=[\"Ho\"])\n",
    "Ho['rs'] = Ho.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "He.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho = combined_dfs['tdt'].join(Ho, how=\"inner\")\n",
    "mass_ho = combined_dfs['mass'].join(Ho, how=\"inner\")\n",
    "pd_ho = combined_dfs['pd'].join(Ho, how=\"inner\")\n",
    "\n",
    "tdt_he = combined_dfs['tdt'].join(He, how=\"inner\")\n",
    "mass_he = combined_dfs['mass'].join(He, how=\"inner\")\n",
    "pd_he = combined_dfs['pd'].join(He, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho['het_bin'] = np.digitize(tdt_ho.Ho, het_bins)\n",
    "mass_ho['het_bin'] = np.digitize(mass_ho.Ho, het_bins)\n",
    "pd_ho['het_bin'] = np.digitize(pd_ho.Ho, het_bins)\n",
    "\n",
    "tdt_he['het_bin'] = np.digitize(tdt_he.He, het_bins)\n",
    "mass_he['het_bin'] = np.digitize(mass_he.He, het_bins)\n",
    "pd_he['het_bin'] = np.digitize(pd_he.He, het_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PhenoContainer = namedtuple(\"PhenoContainer\", [\"He\", \"Ho\", \"hmean\", \"sig\", \"relaxed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PC = {\"mass\": PhenoContainer(mass_he, mass_ho, combined_dfs['mass'], \n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"pd\":PhenoContainer(pd_he, pd_ho, combined_dfs['pd'],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"tdt\":PhenoContainer(tdt_he, tdt_ho, combined_dfs['tdt'],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.995)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].He.gamma_hmean, PC[pheno].He.He)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{exp}$\")\n",
    "    plt.title(\"TDT\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].Ho.gamma_hmean, PC[pheno].Ho.Ho)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{obs}$\")\n",
    "    plt.title(pheno.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_snp = 'ctg7180005039298_50'\n",
    "test_minor = gemma_gt.ix[test_snp, \"minor\"]\n",
    "print(test_minor)\n",
    "for p in pop_allele_data:\n",
    "    if test_minor in pop_allele_data[p][test_snp]:\n",
    "        print(pop_allele_data[p][test_snp][test_minor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts = Counter()\n",
    "for col in gemma_gt.columns[2:]:\n",
    "    pop_counts[col.split(\"_\")[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts_alleles = Counter()\n",
    "for p in pop_allele_data:\n",
    "    for snp in pop_allele_data[p]:\n",
    "        for allele in pop_allele_data[p][snp]:\n",
    "            pop_counts_alleles[p] += pop_allele_data[p][snp][allele][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_counts_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ind = np.sum(list(pop_counts.values()))\n",
    "total_alleles = np.sum(list(pop_counts_alleles.values()))\n",
    "for p in pop_counts:\n",
    "    print(p, pop_counts[p]/total_ind, pop_counts_alleles[p]/total_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele_freqs = read_df(analysis_dir, \"allele_freqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs = allele_freqs.apply(lambda x: np.min((x.p, x.q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['pop_counts_alleles'] = pop_counts_alleles\n",
    "dview['pop_counts'] = pop_counts\n",
    "dview['allele_freqs'] = allele_freqs\n",
    "dview['mafs'] = mafs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Storz and Kelley (2008), Eqn 2\n",
    "\n",
    "# $D_{ij} = \\bigg(\\sum_{k}\\frac{n_k}{n}D_{ij,k}\\bigg) + \\bigg(\\sum_{k}\\frac{n_k}{n}(q_{i,k}q_{j,k} - q_iq_j)\\bigg)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@lview.remote()\n",
    "def do_pairwise_storey(sig_list):\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "    ret = {}\n",
    "    n = np.sum(list(pop_counts_alleles.values()))\n",
    "    for i, snp in enumerate(sig_list):\n",
    "        snp_i = snp\n",
    "        minor_allele_i = gemma_gt.ix[snp_i, \"minor\"]\n",
    "        qi = mafs[snp_i]\n",
    "        for j in range(i):\n",
    "            snp_j = sig_list[j]\n",
    "            minor_allele_j = gemma_gt.ix[snp_j, \"minor\"]\n",
    "            qj = mafs[snp_j]\n",
    "            \n",
    "            k_sum = 0\n",
    "            for p in pops:\n",
    "                nk = pop_counts_alleles[p]\n",
    "                \n",
    "                qik = qjk = 0.0\n",
    "                \n",
    "                if minor_allele_i in pop_allele_data[p][snp_i]:\n",
    "                    qik = pop_allele_data[p][snp_i][minor_allele_i][1]\n",
    "                    \n",
    "                if minor_allele_j in pop_allele_data[p][snp_j]:\n",
    "                    qjk = pop_allele_data[p][snp_j][minor_allele_j][1]\n",
    "                \n",
    "                k_sum += ((nk/n) * ((qik*qjk)-(qi*qj)))\n",
    "                \n",
    "            ret[snp_i, snp_j] = k_sum  \n",
    "    return ret\n",
    "\n",
    "\n",
    "@lview.remote()\n",
    "def do_pairwise_eckert(sig_list):\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "    ret = {}\n",
    "    for i, snp in enumerate(sig_list):\n",
    "        snp_i = snp\n",
    "        minor_allele_i = gemma_gt.ix[snp_i, \"minor\"]\n",
    "        for j in range(i):\n",
    "            snp_j = sig_list[j]\n",
    "            minor_allele_j = gemma_gt.ix[snp_j, \"minor\"]\n",
    "            in_prods = []\n",
    "            freqs = {snp_i: [], snp_j: []}\n",
    "            for p in pops:\n",
    "                paf_i = paf_j = 0.0\n",
    "                \n",
    "                if minor_allele_i in pop_allele_data[p][snp_i]:\n",
    "                    paf_i = pop_allele_data[p][snp_i][minor_allele_i][1]\n",
    "                    \n",
    "                if minor_allele_j in pop_allele_data[p][snp_j]:\n",
    "                    paf_j = pop_allele_data[p][snp_j][minor_allele_j][1]\n",
    "                \n",
    "                freqs[snp_i].append(paf_i)\n",
    "                freqs[snp_j].append(paf_j)\n",
    "                in_prods.append(paf_i * paf_j)\n",
    "            avg_in_prod = np.mean(in_prods)\n",
    "            freqs_avg = {k: np.mean(freqs[k]) for k in freqs}\n",
    "            across_freqs = list(freqs_avg.values())\n",
    "            across_prod = across_freqs[0] * across_freqs[1]\n",
    "            ret[snp_i, snp_j] = (avg_in_prod-across_prod)\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    sig = list(PC[pheno].sig)\n",
    "    storey = do_pairwise_storey(sig)\n",
    "    eckert = do_pairwise_eckert(sig)\n",
    "\n",
    "    storey_vals = []\n",
    "    eckert_vals = []\n",
    "    for pair in storey:\n",
    "        storey_vals.append(storey[pair])\n",
    "        eckert_vals.append(eckert[pair])\n",
    "        \n",
    "    sns.distplot(storey_vals, label=\"storey\")\n",
    "    sns.distplot(eckert_vals, label=\"eckert\")\n",
    "    plt.xlabel(\"pairwise D\")\n",
    "    plt.title(pheno)\n",
    "    plt.legend()\n",
    "    f, p = f_oneway(storey_vals, eckert_vals)\n",
    "    plt.text(0.02, 61, r\"$F = %.3f, p = %.3f$\" % (f, p))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nulls_by_het(n, sig_df, df):\n",
    "    unassoc = df.drop(sig_df.index)\n",
    "    het_bin_counts = df.ix[sig_df.index]['het_bin'].value_counts()\n",
    "    het_bins = het_bin_counts.index.tolist()\n",
    "    unassoc = unassoc[unassoc.het_bin.isin(het_bins)]\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        inner = []\n",
    "        for het_bin, het_count in het_bin_counts.iteritems():\n",
    "            inner.extend(unassoc[unassoc.het_bin == het_bin].rs.sample(het_count).tolist())\n",
    "        data.append(inner)\n",
    "    return data, het_bins\n",
    "\n",
    "def get_nulls_naive(n, sig_df, df):\n",
    "    unassoc = df.drop(sig_df.index)\n",
    "    return [unassoc.rs.sample(len(sig_df)).tolist() for x in range(n)], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_nulls = get_nulls_by_het\n",
    "dview['get_nulls_naive'] = get_nulls_naive\n",
    "dview['get_nulls'] = get_nulls\n",
    "dview['get_nulls_by_het'] = get_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_pairwise(n):\n",
    "    return ((n*n)/2)-(n/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gwas_D = {}\n",
    "for pheno in PC:\n",
    "    sig = list(PC[pheno].sig)\n",
    "    res = do_pairwise_storey(sig).r\n",
    "    gwas_D[pheno] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulls = {}\n",
    "sig_het_bins = {}\n",
    "for pheno in PC:\n",
    "    sig = PC[pheno].hmean.ix[PC[pheno].sig]\n",
    "    nulls[pheno], sig_het_bins[pheno] = get_nulls_by_het(1000, sig, PC[pheno].He)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nulls['tdt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nulls_D = {}\n",
    "for pheno in PC:\n",
    "    nulls_D[pheno] = []\n",
    "    for i, null_list in enumerate(nulls[pheno]):\n",
    "        nulls_D[pheno].append(do_pairwise(null_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    nulls_D[pheno] = [np.abs(x.r) for x in nulls_D[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    d = gwas_D[pheno]\n",
    "    sns.distplot(d, label=\"sig\")\n",
    "    plt.xlabel(\"Pairwise D\")\n",
    "    plt.title(\"%s (n=%d, pairwise=%d)\" % (pheno.upper(), len(list(PC[pheno].sig)), len(d)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_medians = {}\n",
    "for pheno in PC:\n",
    "    null_medians[pheno] = []\n",
    "    for l in nulls_D[pheno]:\n",
    "        null_medians[pheno].append(np.median(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    d = nulls_D[pheno][0]\n",
    "    sns.distplot(d)\n",
    "    plt.title(\"nulls %s \" % pheno)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "for pheno in PC:\n",
    "    n = pd.Series(null_medians[pheno])\n",
    "    d = pd.Series(gwas_D[pheno])\n",
    "    sns.distplot(n, label=\"null\")\n",
    "    sns.distplot(d, label=\"observed\")\n",
    "    plt.title(\"%s (n = %d)\" % (pheno, len(PC[pheno].sig)))\n",
    "    plt.axvline(x=n.quantile(0.95), c=\"red\", zorder=0, label=\"null 95th\")\n",
    "    plt.axvline(x=np.median(d), c=\"blue\", zorder=0, label=\"obs. median\")\n",
    "    plt.axvline(x=d.quantile(0.95), c=\"green\", zorder=0, label=\"obs. 95th\")\n",
    "    plt.xlabel(\"D\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
