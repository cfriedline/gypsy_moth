{
 "metadata": {
  "name": "",
  "signature": "sha256:56a6cc1ce12c0d67fdafc60b6f43ef4ed8b426bdb8dd6596b6184cbc6efc4bac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, vcf\n",
      "from IPython.parallel import Client\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "from __future__ import division\n",
      "os.environ['R_HOME'] = '/home/cfriedline/R3/lib64/R'\n",
      "os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s\" % (os.environ['R_HOME'], os.environ['LD_LIBRARY_PATH'])\n",
      "import rpy2.robjects as robjects\n",
      "%load_ext rpy2.ipython\n",
      "%load_ext autoreload\n",
      "import pandas.rpy.common as com\n",
      "import gspread\n",
      "import scipy.stats as stats\n",
      "import statsmodels.formula.api as smf\n",
      "import statsmodels.api as sm\n",
      "from multiprocessing import Pool\n",
      "from scipy.stats.stats import pearsonr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "store = pd.HDFStore(\"store.h5\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = Client(profile='sge')\n",
      "dview = rc[:]\n",
      "lview = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcftools = \"~/data7/src/vcftools_0.1.12a/bin/vcftools\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    /home/cfriedline/data7/src/freebayes/bin/freebayes -L /data7/eckertlab/gypsy_indiv/bamlist.txt -f /home/cfriedline/data7/assemblies/gypsy/masurca/CA/10-gapclose/genome.ctg.fasta -v /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#vcf called from freebayes\n",
      "fb_vcf = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --vcf $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    After filtering, kept 86785 out of a possible 86785 Sites\n",
      "    Run Time = 3.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Outputs the allele frequency for each site in a file with the suffix \".frq\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --freq --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --freq\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Frequency Statistics...\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 43.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Outputs the raw allele counts for each site in a file with the suffix \".frq.count\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --counts --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --counts\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Frequency Statistics...\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 41.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "Calculates a measure of heterozygosity on a per-individual basis. Specfically, the inbreeding coefficient, F, is estimated for each individual using a method of moments. The resulting file has the suffix \".het\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --het --remove-indels --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --het\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Outputting Individual Heterozygosity\n",
      "        Individual Heterozygosity: Only using fully diploid SNPs.\n",
      "        Individual Heterozygosity: Only using biallelic SNPs.\n",
      "    After filtering, kept 79761 out of a possible 86785 Sites\n",
      "    Run Time = 40.00 seconds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "\n",
      "Reports a p-value for each site from a Hardy-Weinberg Equilibrium test (as defined by Wigginton, Cutler and Abecasis (2005)). The resulting file (with suffix \".hwe\") also contains the Observed numbers of Homozygotes and Heterozygotes and the corresponding Expected numbers under HWE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --hardy --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "This option outputs the genotypes as a large matrix. Three files are produced. The first, with suffix \".012\", contains the genotypes of each individual on a separate line. Genotypes are represented as 0, 1 and 2, where the number represent that number of non-reference alleles. Missing genotypes are represented by -1. The second file, with suffix \".012.indv\" details the individuals included in the main file. The third file, with suffix \".012.pos\" details the site locations included in the main file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!$vcftools --remove-indels --min-alleles 2 --max-alleles 2 --mac 1 --remove-filtered-all --012 --vcf $fb_vcf --out $fb_vcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    VCFtools - v0.1.12a\n",
      "    (C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "    Parameters as interpreted:\n",
      "        --vcf /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --mac 1\n",
      "        --max-alleles 2\n",
      "        --min-alleles 2\n",
      "        --012\n",
      "        --out /data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf\n",
      "        --remove-filtered-all\n",
      "        --remove-indels\n",
      "\n",
      "    After filtering, kept 192 out of 192 Individuals\n",
      "    Writing 012 matrix files ... Done.\n",
      "    After filtering, kept 30791 out of a possible 86785 Sites\n",
      "    Run Time = 55.00 seconds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snp_quals = []\n",
      "snp_dp = []\n",
      "for i, rec in enumerate(vcf.Reader(open(fb_vcf))):\n",
      "    if rec.INFO['TYPE'][0] == 'snp':\n",
      "        snp_quals.append(rec.QUAL)\n",
      "        snp_dp.append(rec.INFO['DP'])\n",
      "    if i % 5000 == 0:\n",
      "        print \"at %d\" % i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(snp_quals, bins=100)\n",
      "plt.title(\"%.2f +/- %.2f [%d, %d]\" % (np.mean(snp_quals), np.std(snp_quals), np.min(snp_quals), np.max(snp_quals)))\n",
      "plt.xlabel(\"QUAL\")\n",
      "plt.xlim(0, 10000)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(snp_dp, bins=100)\n",
      "plt.title(\"%.2f +/- %.2f [%d, %d]\" % (np.mean(snp_dp), np.std(snp_dp), np.min(snp_dp), np.max(snp_dp)))\n",
      "plt.xlabel(\"DP\")\n",
      "plt.xlim((0,700))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "##Create file for afsource"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_missing(rec):\n",
      "    missing = 0.0\n",
      "    for sample in rec.samples:\n",
      "        if not sample.data.AO:\n",
      "            missing += 1\n",
      "    return missing\n",
      "\n",
      "def is_valid_snp(rec, min_qual, missing_prob):\n",
      "    if rec.QUAL < min_qual:\n",
      "        return False\n",
      "    t = rec.INFO['TYPE']\n",
      "    if len(t) > 1:\n",
      "        return False\n",
      "    if t[0] != 'snp':\n",
      "        return False\n",
      "    if get_missing(rec)/len(rec.samples) >= missing_prob:\n",
      "        return False\n",
      "    return True    \n",
      "\n",
      "afsource_file = \"%s.afsource_missing_0.5\" % fb_vcf\n",
      "with open(afsource_file, \"w\") as o:\n",
      "    for i, rec in enumerate(vcf.Reader(open(fb_vcf))):\n",
      "        if is_valid_snp(rec, 20, 0.5):\n",
      "            o.write(\"%s\\n\" % \"locus %s pos %d %g\" % (rec.CHROM, rec.POS, 1/rec.QUAL))\n",
      "            for sample in rec.samples:\n",
      "                ref = 0\n",
      "                alt = 0\n",
      "                if sample.data.RO:\n",
      "                    ref = sample.data.RO\n",
      "                if sample.data.AO:\n",
      "                    alt = sample.data.AO\n",
      "                try:\n",
      "                    o.write(\"%s\\n\" % \"%d %d\" % (ref, alt))\n",
      "                except:\n",
      "                    print rec.INFO\n",
      "                    print sample.data\n",
      "        if i % 5000 == 0:\n",
      "            print \"at %d\" % i\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "##Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hardy_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.hwe\"\n",
      "het_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.het\"\n",
      "freq_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.frq\"\n",
      "counts_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.frq.count\"\n",
      "z12_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012\"\n",
      "pos_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012.pos\"\n",
      "indv_file = \"/data7/eckertlab/gypsy_indiv/gypsy_freebayes_out.vcf.012.indv\"\n",
      "trans_table = \"translation_table.csv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Read in 012 file from vcf tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z12_df = pd.read_csv(z12_file, header=None, sep=\"\\t\")\n",
      "z12_df = z12_df.drop(0, axis=1)\n",
      "z12_df.columns = pd.Series(z12_df.columns)-1\n",
      "pos_df = pd.read_csv(pos_file, header=None, sep=\"\\t\", names=[\"contig\", \"pos\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Get SNP F_is"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_allele_counts(series, filter_missing=True):\n",
      "    P = 0.0\n",
      "    Q = 0.0\n",
      "    PQ = 0.0\n",
      "    missing = 0.0\n",
      "    c = series.value_counts()\n",
      "    if 0 in c:\n",
      "        P = c[0]\n",
      "    if 2 in c:\n",
      "        Q = c[2]\n",
      "    if 1 in c:\n",
      "        PQ = c[1]\n",
      "    if -1 in c:\n",
      "        missing = c[-1]\n",
      "    missing_perc = missing/len(series)\n",
      "    if filter_missing and missing_perc > 0.5:\n",
      "#         print \"too much missing data %g\" % missing_perc\n",
      "        P = PQ = Q = 0.0\n",
      "    return (P, PQ, Q)\n",
      "\n",
      "def get_correction(n):\n",
      "    #for finite sample size\n",
      "    return (2*n)/(2*n-1)\n",
      "\n",
      "def get_allele_freqs(series, filter_missing=True):\n",
      "    c = get_allele_counts(series, filter_missing)\n",
      "    if c:\n",
      "        if sum(c) == 0:\n",
      "            return 0.0, 0.0, c\n",
      "        else:\n",
      "            P = 2*c[0] + c[1]\n",
      "            Q = 2*c[2] + c[1]\n",
      "            total = P + Q\n",
      "            p = P/total\n",
      "            q = Q/total\n",
      "            return p, q, c\n",
      "        \n",
      "def get_he(series):\n",
      "    p, q, c = get_allele_freqs(series)\n",
      "    if p:\n",
      "        He = 2 * p * q * get_correction(sum(c))\n",
      "        return He\n",
      "    return None\n",
      "\n",
      "def get_ho(series):\n",
      "    c = get_allele_counts(series)\n",
      "    if c:\n",
      "        if sum(c) == 0:\n",
      "            return 0.0\n",
      "        else:\n",
      "            Ho = c[1]/(sum(c))\n",
      "            return Ho\n",
      "    return None\n",
      "    \n",
      "def get_Fis(df):\n",
      "#     df = df.ix[:,0:10]\n",
      "    obs = df.apply(get_ho)\n",
      "    exp = df.apply(get_he)\n",
      "    Fis = 1 - obs/exp\n",
      "    return obs, exp, Fis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs, exp, Fis = get_Fis(z12_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = Fis.replace([np.inf, -np.inf], np.nan).dropna()\n",
      "plt.hist(x, bins=12)\n",
      "plt.title(\"n=%d\" % len(x))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Remove based on F_is outliers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Fis_filter_fis = Fis[(Fis >= -0.5) & (Fis <= 0.5)] # by Fis value\n",
      "print \"removed\", (len(Fis)-len(Fis_filter_fis))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    removed 19551"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Remove based on MAF < 0.01"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rare = []\n",
      "for snp_index in Fis_filter_fis.index:\n",
      "    p, q, c = get_allele_freqs(z12_df[snp_index])\n",
      "    if min([p,q]) < 0.01:\n",
      "        rare.append(snp_index)\n",
      "print len(rare)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    219"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Fis_filter_fis_rare = Fis_filter_fis.drop(rare)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Put filtered data back with sample/pop"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trans_df = pd.read_csv(trans_table, header=0, index_col=0, sep=\"\\t\")\n",
      "for i, line in enumerate(open(indv_file)):\n",
      "    line = line.strip()\n",
      "    trans = trans_df.ix[line]\n",
      "    z12_df.ix[i, 'sample'] = \"%s_%d\" % (trans['pop'], trans['indiv'])\n",
      "    z12_df.ix[i, 'pop'] = trans['pop']\n",
      "    z12_df.ix[i, 'dupl'] = trans['dup']\n",
      "df = z12_df[z12_df['dupl']==0]\n",
      "df = df.drop('dupl', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pop_id = {}\n",
      "i = 0\n",
      "for p in sorted(z12_df['pop'].unique()):\n",
      "    pop_id[p] = i\n",
      "    i+=1\n",
      "pop_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hierf_trans = {0:11, 1:12, 2:22, -1:'NA'}\n",
      "def apply_hierf_trans(series):\n",
      "    return [hierf_trans[x] if x in hierf_trans else x for x in series]\n",
      "df = df.apply(apply_hierf_trans)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def assign_popid(series):\n",
      "    series['popid'] = pop_id[series['pop']]\n",
      "    return series\n",
      "df = df.apply(assign_popid, axis=1)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numbers\n",
      "hierfcols = ['sample', 'popid']\n",
      "# hierfcols.extend(df.columns.values[0:-3])\n",
      "hierfcols.extend(Fis_filter_fis_rare.index)\n",
      "hierf = df[hierfcols].sort('popid')\n",
      "cols = [None]*len(hierf.columns)\n",
      "for i, x in enumerate(hierf.columns):\n",
      "    if isinstance(x, numbers.Number):\n",
      "        cols[i] = \"L%d\" % x\n",
      "    else:\n",
      "        cols[i] = x\n",
      "hierf.columns = pd.Index(cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hierf.to_csv(\"hierfstat.txt\", header=True, index=False, sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(hierfstat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "data = read.table(\"hierfstat.txt\", header=T, sep=\"\\t\")\n",
      "levels = data.frame(data$popid)\n",
      "loci = data[,3:ncol(data)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "res = varcomp.glob(levels=levels, loci=loci, diploid=T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "saveRDS(res, \"hierfstat.rds\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "res = readRDS(\"hierfstat.rds\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = com.convert_robj(robjects.r('res'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "loc_df = res['loc']\n",
      "F_df = res['F']\n",
      "overall_df = res['overall']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def compute_fst(series):\n",
      "    Hs = series[0]\n",
      "    Ht = sum(series)\n",
      "    return (Ht-Hs)/Ht"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loci_fst = loc_df.apply(compute_fst, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(loci_fst, bins=20)\n",
      "plt.title(\"n=%d (%.2f, %.2f)\" % (len(loci_fst), np.min(loci_fst), np.max(loci_fst)))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "###Setup for PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_cols = Fis_filter_fis_rare.index.tolist()\n",
      "filtered_cols.extend(['sample', 'pop','dupl'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_data = z12_df[filtered_cols]\n",
      "pca_data = pca_data[pca_data['dupl']==0]\n",
      "cols = [None]*len(pca_data.columns)\n",
      "for i, x in enumerate(pca_data.columns):\n",
      "    if isinstance(x, numbers.Number):\n",
      "        cols[i] = \"L%d\" % x\n",
      "    else:\n",
      "        cols[i] = x\n",
      "pca_data.columns = pd.Index(cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def center_and_standardize_value(val, u, var):\n",
      "    if val == -1:\n",
      "        return 0.0\n",
      "    return (val-u)/var\n",
      "\n",
      "def center_and_standardize(series):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    if series.name.startswith(\"L\"):\n",
      "        p,q,c = get_allele_freqs(series, filter_missing=False)\n",
      "        u = sum([i*x for i, x in enumerate(c)])/sum(c)\n",
      "        var = np.sqrt(q*(1-q))\n",
      "        return series.apply(center_and_standardize_value, args=(u, var))\n",
      "    return series\n",
      "\n",
      "dview['center_and_standardize'] = center_and_standardize\n",
      "dview['center_and_standardize_value'] = center_and_standardize_value\n",
      "dview['get_allele_counts'] = get_allele_counts\n",
      "dview['get_allele_freqs'] = get_allele_freqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_std = (lview.map_async(center_and_standardize, [pca_data[col] for col in pca_data]))\n",
      "pca_std = pd.concat(pca_std.get(), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_std_data = pca_std.ix[:,0:-3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_std_data.ix[0:5,0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in xrange(5):\n",
      "    print stats.describe(pca_std_data.ix[:,x])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    (189, (-5.326002287485462, 0.3631365196012814), -4.9930665128644604e-17, 0.96703296703296737, -5.0601555392337305, 24.615812379110285)\n",
      "    (189, (-2.9223601977332487, 0.61885274775527588), 1.2688263138573217e-16, 0.99083295608872646, -2.3202852381812895, 4.218675042832709)\n",
      "    (189, (-0.90472803567305171, 4.4212181365909506), 3.2895497025930562e-17, 1.6971739187716721, 1.4131782304108376, 1.4440108406907584)\n",
      "    (189, (-0.97949456052391681, 4.0837388600304836), 4.3469049641408243e-17, 1.9040155573405144, 1.2661764318540107, 0.8520939179042637)\n",
      "    (189, (-3.0162956114555941, 1.3261299671054765), -3.2895497025930562e-17, 2.0486707522333969, -0.7492305837150625, -0.407422319541066)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = robjects.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prcomp = r('prcomp')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prcomp_res = prcomp(pca_std_data, scale=False, center=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = com.convert_robj(prcomp_res.rx2(\"x\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(x.PC1, x.PC2)\n",
      "fig = plt.gcf()\n",
      "fig.set_size_inches(10,8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.index = pd.Index([int(i) for i in x.index])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joined = x.join(pca_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_missing_perc(series):\n",
      "    missing = 0\n",
      "    total = 0\n",
      "    for x in series.index:\n",
      "        if x.startswith(\"L\"):\n",
      "            if series[x] == -1:\n",
      "                missing += 1\n",
      "            total +=1\n",
      "    return missing/total\n",
      "    \n",
      "missing_perc = joined.apply(compute_missing_perc, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joined['missing_perc'] = missing_perc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(joined.missing_perc, joined.PC1)\n",
      "plt.xlabel(\"missing perc\")\n",
      "plt.ylabel(\"PC1\")\n",
      "fig = plt.gcf()\n",
      "fig.set_size_inches(10,8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://docs.google.com/uc?export=download&id=0B4xHxBFoPCoWT0NneHJadUI0OHM'\n",
      "response = urllib2.urlopen(url)\n",
      "pheno = pd.read_excel(response, \"Males-forGenomics-final\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno=pheno[['Population', 'Number', 'Mass', 'Pupual Duration', 'Total Dev Time']]\n",
      "for x in pheno.index:\n",
      "    pheno.ix[x, 'sample'] = \"%s_%d\" % (pheno.ix[x, 'Population'], pheno.ix[x, 'Number'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno_index = []\n",
      "missing = []\n",
      "for x in pheno.index:\n",
      "    sample = pheno.ix[x]['sample']\n",
      "    target = joined[joined['sample']==sample]\n",
      "    if len(target.index):\n",
      "        i = target.index.tolist()[0]\n",
      "        pheno_index.append(i)\n",
      "    else:\n",
      "        missing.append(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno = pheno.drop(missing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno = pheno.set_index(pd.Index(pheno_index))\n",
      "pheno = pheno.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jp=pd.concat([joined,pheno], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jp=jp.drop(jp[np.isnan(jp['Mass'])].index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___\n",
      "###PCA Price et al. 2006"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R \n",
      "source('TWtest.R')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_data2 = jp[[x for x in jp.columns if x.startswith(\"L\")]]\n",
      "pca_data2_std = pca_data2.apply(center_and_standardize)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_data2_std.columns = [x.replace(\"L\", \"S\") for x in pca_data2_std.columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview.push({'pheno':pheno,\n",
      "            'pca_data2':pca_data2, \n",
      "            'pca_data2_std':pca_data2_std})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S0 = pca_data2_std.drop('S0', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prcomp = r('prcomp')\n",
      "twtest = r('twtest')\n",
      "pca_S0 = prcomp(S0, center=False, scale=False) #don't need scaling/centering b/c done above"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_S0 = com.convert_robj((pca_S0.rx2('x')))\n",
      "x_S0.index = S0.index #because the R index is dumb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = pd.concat([pca_data2_std, pca_data2, x_S0, pheno], axis=1, join=\"inner\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p_model = smf.ols(formula=\"Mass ~ PC1\", data=m)\n",
      "p_fit = p_model.fit()\n",
      "p_fit.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g_model = smf.ols(formula=\"S0 ~ PC1\", data=m)\n",
      "g_fit = g_model.fit()\n",
      "g_fit.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pearsonr(p_fit.resid, g_fit.resid)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}