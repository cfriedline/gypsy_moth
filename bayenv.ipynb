{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import cyvcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir_notimp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/\"\n",
    "analysis_dir_imp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/\"\n",
    "hdf_notimp = HDFStoreHelper(os.path.join(analysis_dir_notimp, \"isect.hd5\"))\n",
    "hdf_imp = HDFStoreHelper(os.path.join(analysis_dir_imp, \"isect.hd5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = [analysis_dir_notimp, analysis_dir_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "hdfs = [hdf_notimp, hdf_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = []\n",
    "for d in analysis_dir:\n",
    "    infile = os.path.join(d, \"pop_allele_freqs.dill\")\n",
    "    paf = dill.load(open(infile))\n",
    "    pop_allele_freqs.append(paf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsfile_df = []\n",
    "for i, paf in enumerate(pop_allele_freqs):\n",
    "    pops = sorted(paf)\n",
    "    paf_data = defaultdict(defaultdict)\n",
    "    for popn in pops:\n",
    "        af = paf[popn]\n",
    "        for snp in af:\n",
    "            paf_data[\"%s_1\" % snp][popn] = af.ix[\"P\",snp]\n",
    "            paf_data[\"%s_2\" % snp][popn] = af.ix[\"Q\",snp]  \n",
    "    df = pd.DataFrame(paf_data).T\n",
    "    df['blank'] = \"\"\n",
    "    snpsfile_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environ_cols = snpsfile_df[0].columns.drop(\"blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bioclim = [x['bioclim'] for x in hdfs]\n",
    "bioclim = [x[[y for y in x if 'BIO' in y]] for x in bioclim]\n",
    "bioclim = [x.T for x in bioclim]\n",
    "bioclim = [x[environ_cols] for x in bioclim]\n",
    "bioclim = [x.astype(float) for x in bioclim]\n",
    "bioclim = [x.apply(preprocessing.scale, axis=1) for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim = [x.assign(blank=lambda x: \"\") for x in bioclim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,snps in enumerate(snpsfile_df):\n",
    "    snp_outfile = os.path.join(analysis_dir[i], \"snpsfile\")\n",
    "    env_outfile = os.path.join(analysis_dir[i], \"environfile\")\n",
    "    snps.to_csv(snp_outfile, sep=\"\\t\", header=False, index=False)\n",
    "    envs = bioclim[i]\n",
    "    envs.to_csv(env_outfile, sep=\"\\t\", header=False, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "~/g/src/bayenv2_public/bayenv2 -i snpsfile -p 6 -k 100000 -r 187564 > matrix.out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcov = []\n",
    "for d in analysis_dir:    \n",
    "    vcovs = []\n",
    "    current = None\n",
    "    for line in open(os.path.join(d, \"matrix.out\")):\n",
    "        if \"VAR-COVAR\" in line:\n",
    "            current = []\n",
    "            vcovs.append(current)\n",
    "        if isinstance(current, list):\n",
    "            current.append(line.strip().split(\"\\t\"))\n",
    "    vcov.append(vcovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcov_dfs = []\n",
    "for v in vcov:\n",
    "    vcov_dfs_temp = []\n",
    "    for i, elem in enumerate(v):\n",
    "        vcov_dfs_temp.append(pd.DataFrame(elem[1:]).T)\n",
    "    vcov_dfs.append(vcov_dfs_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_correlations = []\n",
    "for vcov_df in vcov_dfs:\n",
    "    temp = []\n",
    "    for i in xrange(len(vcov_df)):\n",
    "        for j in xrange(len(vcov_df)):\n",
    "            if j == (i + 1):\n",
    "                idf = vcov_df[i]\n",
    "                jdf = vcov_df[j]\n",
    "                idf = idf.ix[:,:len(idf)-1]\n",
    "                jdf = jdf.ix[:,:len(jdf)-1]\n",
    "                idf = [float(x) for x in idf.values.flatten()]\n",
    "                jdf = [float(x) for x in jdf.values.flatten()]\n",
    "                assert len(idf) == len(jdf)\n",
    "                temp.append(sp.stats.pearsonr(idf, jdf)[0])\n",
    "    matrix_correlations.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for matrix_correlation in matrix_correlations:\n",
    "    plt.plot(range(len(matrix_correlation)),matrix_correlation)\n",
    "    plt.title(\"Pearson correlations among %d adjacent VCOV matrices\" % len(matrix_correlation))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate(analysis_dir):\n",
    "    out_matrix = os.path.join(d, \"matrix_last.out\")\n",
    "    matrix = vcov_dfs[i][-1]\n",
    "    matrix.to_csv(out_matrix, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_indv = [x.drop(\"blank\", axis=1) for x in snpsfile_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in snp_indv:\n",
    "    s['snp_name'] = s.apply(lambda x: \"_\".join(x.name.split(\"_\")[0:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv = []\n",
    "for i, s in enumerate(snp_indv):\n",
    "    temp = []\n",
    "    bayenv.append(temp)\n",
    "    outdir = os.path.join(analysis_dir[i], \"bayenv\")\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    for group, data in s.groupby(\"snp_name\"):\n",
    "        bayenv_file = os.path.join(outdir, \"%s.txt\" % group)\n",
    "        temp.append(bayenv_file)\n",
    "        data = pd.DataFrame(data)\n",
    "        data['blank'] = \"\"\n",
    "        data = data.drop(\"snp_name\", axis=1)\n",
    "        data.to_csv(bayenv_file, index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_exe = \"/home/cfriedline/g/src/bayenv2_public/bayenv2\"\n",
    "bayenv_opt = \"-i snpfile -m matrixfile -e environfile -p 6 -k 100000 -n 19 -t -X -c -f -r rand\"\n",
    "\n",
    "for i, bayenv_files in enumerate(bayenv):\n",
    "    cpu = 0\n",
    "    max_cpu = 30\n",
    "    thedir = analysis_dir[i]\n",
    "    shutil.copy(os.path.join(thedir, \"matrix_last.out\"), os.path.dirname(bayenv_files[0]))\n",
    "    shutil.copy(os.path.join(thedir, \"environfile\"), os.path.dirname(bayenv_files[0]))\n",
    "    with open(os.path.join(os.path.dirname(bayenv_files[0]), \"bayenv_parallel\"), \"w\") as o:\n",
    "        for bayenv_file in bayenv_files:\n",
    "            bayenv_cmd = \" \".join([bayenv_exe, bayenv_opt]).split()\n",
    "            if cpu == max_cpu:\n",
    "                cpu = 0\n",
    "            \n",
    "            bayenv_cmd[2] = os.path.basename(bayenv_file)\n",
    "            bayenv_cmd[4] = \"matrix_last.out\"\n",
    "            bayenv_cmd[6] = \"environfile\"\n",
    "            bayenv_cmd[-1] = int(random.getrandbits(16))\n",
    "            bayenv_cmd.insert(0, \"taskset -c %d\" % cpu)\n",
    "            o.write(\"%s\\n\" % \" \".join([str(x) for x in bayenv_cmd]))\n",
    "            \n",
    "            cpu += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bayenv jobs\n",
    "\n",
    "```bash\n",
    "cat bayenv_parallel | parallel -j 30 --eta --\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vartypes = ['bf', 'r', 'p']\n",
    "bf_cols = []\n",
    "for b in bioclim[0].index:\n",
    "    for v in vartypes:\n",
    "        bf_cols.append(\"%s_%s\" % (b, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtxs = []\n",
    "bfs = []\n",
    "for i, dir_name in enumerate(analysis_dir):\n",
    "    xtx = os.path.join(os.path.join(dir_name, \"bayenv\"), \"XtX_out.environfile\")\n",
    "    bf = os.path.join(os.path.join(dir_name, \"bayenv\"), \"bf_environ.environfile\")\n",
    "    xtx_df = pd.read_csv(xtx, sep=\"\\t\", header = None, index_col=0, names=['XtX'])\n",
    "    xtx_df.index.name = \"snp\"\n",
    "    xtx_df.index = [x.replace(\".txt\", \"\") for x in xtx_df.index]\n",
    "    bf_df = pd.read_csv(bf, sep=\"\\t\", header=None, index_col=0)\n",
    "    bf_df = bf_df.drop(bf_df.columns[-1], axis=1)\n",
    "    bf_df.index = [x.replace(\".txt\", \"\") for x in bf_df.index]\n",
    "    bf_df.index.name = \"snp\"\n",
    "    bf_df.columns = bf_cols\n",
    "    bfs.append(bf_df)\n",
    "    xtxs.append(xtx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impute_status = [\"notimputed\", \"imputed\"]\n",
    "for i, dir_name in enumerate(analysis_dir):\n",
    "    bf_out = os.path.join(dir_name, \"bayenv_bf_%s.txt\" % impute_status[i])\n",
    "    xtx_out = os.path.join(dir_name, \"bayenv_xtx_%s.txt\" % impute_status[i])\n",
    "    bfs[i].to_csv(bf_out, sep=\"\\t\", index=True, header=True)\n",
    "    xtxs[i].to_csv(xtx_out, sep=\"\\t\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = []\n",
    "for i, dir_name in enumerate(analysis_dir):\n",
    "    bayenv_out = os.path.join(dir_name, \"bayenv_results_%s.txt\" % impute_status[i])\n",
    "    j = xtxs[i].join(bfs[i])\n",
    "    j.to_csv(bayenv_out, sep=\"\\t\", header=True, index=True)\n",
    "    joined.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(joined):\n",
    "    sns.distplot(data.XtX)\n",
    "    plt.title(impute_status[i])\n",
    "    plt.xlim(4.5,8.5)\n",
    "    plt.ylim(0,1.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.load_dataset(\"tips\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_bf_vs_xtx(df, imputed, dir_name):\n",
    "    num_figs = len(df.columns)-1\n",
    "    plt.gcf().set_size_inches(20,20)\n",
    "    for i in xrange(num_figs):\n",
    "        if i > 0:\n",
    "            plt.subplot(5,4,i)\n",
    "            plt.title(\"%s (%s)\" % (df.columns[i].split(\"_\")[0], imputed))\n",
    "            plt.xlabel(\"BF\")\n",
    "            plt.ylabel(df.columns[0])\n",
    "            plt.scatter(df.ix[:,i],test.ix[:,0])\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "                    wspace=.5, hspace=.5)\n",
    "    plt.savefig(\"%s.pdf\" % os.path.join(dir_name, \"bf_vs_xtx_%s\" % imputed))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, res in enumerate(joined):\n",
    "    df = pd.DataFrame(res['XtX']).join(res[[x for x in res if 'bf' in x]])\n",
    "    plot_bf_vs_xtx(df, impute_status[i], analysis_dir[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = []\n",
    "for i, res in enumerate(joined):\n",
    "    XtX = res.XtX\n",
    "    M = np.median(XtX)    \n",
    "    MAD = sm.robust.mad(XtX)\n",
    "    lower_cutoff = M-(3*MAD)\n",
    "    upper_cutoff = M+(3*MAD)\n",
    "    o = pd.DataFrame([impute_status[i], \n",
    "                      M,\n",
    "                      MAD,\n",
    "                      lower_cutoff, \n",
    "                      upper_cutoff, \n",
    "                      len(XtX[XtX<lower_cutoff]), len(XtX[XtX>upper_cutoff])]).T\n",
    "    o.columns = ['state', 'median_XtX', 'MAD', 'lower_cutoff', 'upper_cutoff', 'n_lower', 'n_upper']\n",
    "    outliers.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??sm.robust.mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
