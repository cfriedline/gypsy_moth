{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import cyvcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir_notimp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/\"\n",
    "analysis_dir_imp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/\"\n",
    "hdf_notimp = HDFStoreHelper(os.path.join(analysis_dir_notimp, \"isect.hd5\"))\n",
    "hdf_imp = HDFStoreHelper(os.path.join(analysis_dir_imp, \"isect.hd5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdf_notimp['z12_swapped'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = [analysis_dir_notimp, analysis_dir_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs = [hdf_notimp, hdf_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdfs[0].get_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps = {'QC32':[47.2509807, -79.4060515],\n",
    "      'QC93': [46.9089631, -70.8061075],\n",
    "      'NC': [36.449125, -76.024672],\n",
    "      'NY': [42.897768, -74.094761],\n",
    "      'VA1': [38.657615, -77.463603],\n",
    "      'VA2': [38.857470, -77.695003]}\n",
    "gps_df = pd.DataFrame(gps).T\n",
    "gps_df.columns = ['lat','lon']\n",
    "\n",
    "latlon = pandas2ri.py2ri(gps_df[['lon', 'lat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster = r(\"raster\")\n",
    "extract = r(\"extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim_dir = \"/home/cfriedline/eckertlab/bioclim\"\n",
    "bioclim = !ls {bioclim_dir}/*.bil\n",
    "bioclim = sorted(bioclim)\n",
    "bioclim_df = pd.DataFrame(gps_df)\n",
    "for b in bioclim:\n",
    "    rast = raster(b)\n",
    "    bio = os.path.basename(b).replace(\".bil\", \"\").replace(\"_\", \"\").upper()\n",
    "    vals = pd.DataFrame(pandas2ri.ri2py(extract(rast, latlon)))\n",
    "    vals.index = bioclim_df.index\n",
    "    vals.columns = [bio]\n",
    "    bioclim_df = bioclim_df.join(vals)\n",
    "bioclim_df = bioclim_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hdf in hdfs:\n",
    "    hdf['bioclim'] = bioclim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_id = 1\n",
    "for popname in bioclim_df.index:\n",
    "    bioclim_df.ix[popname, 'region'] = region_id\n",
    "    region_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bioclim_env_files = []\n",
    "for bio in bioclim_df[[x for x in bioclim_df if 'BIO' in x]]:\n",
    "    bio_temp = bioclim_df[[bio, 'region']]\n",
    "    bio_temp.index.name = \"CLST\"\n",
    "    bio_temp.columns = [\"ENV\", \"REG\"]\n",
    "    bio_out = os.path.join(analysis_dir[0], \"../%s.txt\" % bio)\n",
    "    bioclim_env_files.append(bio_out)\n",
    "    bio_temp.to_csv(bio_out, sep=\"\\t\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = [x['z12_swapped'] for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = [x.ix[:,:-2].apply(get_allele_freqs, args=(False,)) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, af in enumerate(allele_freqs):\n",
    "    hdfs[i]['allele_freqs_swapped'] = af\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = []\n",
    "for z12 in z12_swapped:\n",
    "    paf = {}\n",
    "    pop_allele_freqs.append(paf)\n",
    "    for pop, data in z12.groupby('population'):\n",
    "        data = data.ix[:,:-2]\n",
    "        paf[pop] = data.apply(get_allele_freqs, args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, paf in enumerate(pop_allele_freqs):\n",
    "    outfile = os.path.join(analysis_dir[i], \"pop_allele_freqs.dill\")\n",
    "    dill.dump(paf, open(outfile, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_gt = [x['pimass_gt'].replace(\"NA\", np.nan) for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "def get_translated_name(n):\n",
    "    n = n.strip()\n",
    "    if n in translation_df.index:\n",
    "        row = translation_df.ix[n.strip()]\n",
    "        return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in pimass_gt:\n",
    "    p.columns = [get_translated_name(x) for x in p.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdfs[0]['pimass_pheno'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = [x['pimass_pheno'][['mass_resid', 'pupual_duration_resid', 'total_dev_time_resid']] for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for i, pheno_df in enumerate(phenos):\n",
    "    alphas.append({})\n",
    "    data = pheno_df.join(pimass_gt[i].T.ix[2:,])\n",
    "    data.columns = [x.replace(\" \", \"_\") for x in data.columns]\n",
    "    data = data.astype(float)\n",
    "    for pheno in data.columns[0:3]:\n",
    "        alphas[i][pheno] = {}\n",
    "        print i, pheno\n",
    "        for snp in data.columns[3:]:\n",
    "            model = sm.OLS(data[pheno], data[snp], missing='drop')\n",
    "            fit = model.fit()\n",
    "            alphas[i][pheno][snp] = fit.params.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_df = [pd.DataFrame(x) for x in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_names = phenos[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sig_pheno_name(col):\n",
    "    return {'mass_resid': 'mass',\n",
    "           'pupual_duration_resid': 'pd',\n",
    "           'total_dev_time_resid': 'tdt'}[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_freqs_file(df, paf, outdir, pheno, imputed, key, sig_key):\n",
    "    df = df.copy()\n",
    "    outfile = os.path.join(outdir, \"freqs.file.%s.%s.%s.%s.txt\" % (sig_key, key, pheno, imputed))\n",
    "    df.index.name = \"SNP\"\n",
    "    dfs = []\n",
    "    for pop in paf:\n",
    "        df2 = df.join(paf[pop].T)\n",
    "        df2['CLST'] = pop\n",
    "        df2['POS'] = df2.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "        df2['CHR'] = df2.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "        df2 = df2[['CLST', 'minor', 'major', 'q', 'POS', 'CHR']]\n",
    "        df2.columns = ['CLST', 'A1', 'A2', 'FRQ', 'POS', 'CHR']\n",
    "        dfs.append(df2)\n",
    "    combined = pd.concat(dfs)\n",
    "    combined.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile, combined['CLST'].unique()\n",
    "\n",
    "def write_gwas_data_file(df, outdir, pheno, imputed, sig_key):\n",
    "    df = df.copy()\n",
    "    outfile = os.path.join(outdir, \"gwas.data.file.%s.%s.%s.txt\" % (sig_key, pheno, imputed))\n",
    "    df.index.name = \"SNP\"\n",
    "    df = df[['minor', 'major', 'alpha', 'maf']]\n",
    "    df.columns = [\"A1\", \"A2\", \"EFF\", \"FRQ\"]\n",
    "    df.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile\n",
    "    \n",
    "def write_env_var_data_files(paf, pops, outdir, imputed, pheno, sig_key):\n",
    "    outfiles = []\n",
    "    outfile = os.path.join(outdir, \"env.var.data.file.%s.%s.%s.txt\" % (sig_key, pheno, imputed))\n",
    "    outfiles.append(outfile)\n",
    "    with open(outfile, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 1\n",
    "        for pop in sorted(paf):\n",
    "            if pop in pops:\n",
    "                o.write(\"%s\\t%g\\t%d\\n\" % (pop, np.random.randn(), pop_id))\n",
    "            pop_id += 1\n",
    "    return outfiles\n",
    "  \n",
    "def write_match_pop_file(df, paf, outdir, imputed, matchpop, pheno, sig_key):\n",
    "    outfile = os.path.join(outdir, \"match.pop.file.%s.%s.%s.%s.txt\" % (sig_key, pheno, matchpop, imputed))\n",
    "    df2 = df.join(paf[matchpop].T)\n",
    "    df2.index.name=\"SNP\"\n",
    "    df2['CLST'] = matchpop\n",
    "    df2['POS'] = df2.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "    df2['CHR'] = df2.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "    df2 = df2[['CLST', 'minor', 'major', 'q', 'POS', 'CHR']]\n",
    "    df2.columns = ['CLST', 'A1', 'A2', 'FRQ', 'POS', 'CHR']\n",
    "    df2.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile\n",
    "\n",
    "def get_squat_vars(pheno,\n",
    "                   gwas_data_file, \n",
    "                  gwas_freqs_file, \n",
    "                  env_var_files,\n",
    "                  match_pop_file,\n",
    "                  full_freqs_file):\n",
    "    d = {\"gwas.data.file\": \"'%s'\" % gwas_data_file,\n",
    "         \"freqs.file\": \"'%s'\" % gwas_freqs_file,\n",
    "         \"env.var.data.files\": \"list(%s)\" % ','.join([\"'%s'\" % x for x in env_var_files]),\n",
    "         \"match.pop.file\": \"'%s'\" % match_pop_file,\n",
    "         \"full.dataset.file\": \"'%s'\" % full_freqs_file,\n",
    "         \"path\":\"'%s'\" % pheno,\n",
    "         \"match.categories\":\"c('FRQ')\",\n",
    "         \"match.bins\":\"list(seq(0,0.5,0.02), c(2), seq(0,1000,100))\",\n",
    "         \"cov.SNPs.per.cycle\":5000,\n",
    "         \"cov.cycles\":1,\n",
    "         \"null.phenos.per.cycle\":1000,\n",
    "         \"null.cycles\":1,\n",
    "         \"load.cov.mat\":\"F\",\n",
    "         \"sim.null\":\"T\",\n",
    "         \"check.allele.orientation\":\"T\"}\n",
    "    return ',\\n'.join(\"%s=%s\" % (key,val) for (key,val) in d.items())\n",
    "\n",
    "def create_squat_run_file(pheno, outdir, squat_vars, sig_key):\n",
    "    squat_dir = \"/home/cfriedline/eckertlab/src/PolygenicAdaptationCode/Scripts/\"\n",
    "    out_dir = os.path.join(outdir, \"squat_%s\" % sig_key)\n",
    "    res_dir = os.path.join(out_dir, pheno)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        os.symlink(squat_dir, os.path.join(out_dir, \"Scripts\"))\n",
    "    squat_file = os.path.join(out_dir, \"squat_%s.%s.r\" % (sig_key, pheno))\n",
    "    with open(squat_file, \"w\") as o:\n",
    "        o.write(\"system('rm -rf %s')\\n\" % res_dir)\n",
    "        o.write(\"setwd('/home/cfriedline/eckertlab/src/PolygenicAdaptationCode')\\n\")\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"CreateTraitFile.R\"))\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"functions.R\"))\n",
    "        o.write(\"setwd('%s')\\n\" % out_dir)\n",
    "        o.write(\"PolygenicAdaptationFunction(%s)\\n\" % squat_vars)\n",
    "    return squat_file\n",
    "\n",
    "squat_files = []\n",
    "\n",
    "for i, hdf in enumerate(hdfs):\n",
    "    outdir = analysis_dir[i]\n",
    "    for name in pheno_names:\n",
    "        paf = pop_allele_freqs[i]\n",
    "        pheno_hdf = get_sig_pheno_name(name)\n",
    "        for sig_key, sig in {\"relaxed\": hdf['relaxed_sig_snps_%s' % pheno_hdf],\n",
    "                            \"sig\": hdf['sig_snps_%s' % pheno_hdf]}.items():\n",
    "            print sig_key, name, pheno_hdf, len(sig)\n",
    "            full = hdf['mcmc_%s_hmean' % pheno_hdf]\n",
    "            full.index = full.rs\n",
    "            full.index.name=\"%s_%d\" % (name, i)\n",
    "            alpha = alphas[i][name]\n",
    "            full['alpha'] = full.apply(lambda x: alpha[x.name], axis=1)       \n",
    "            full = full.drop(\"rs\", axis=1)\n",
    "            full = full.join(pimass_gt[i][['minor', 'major']])\n",
    "            af = hdfs[i]['allele_freqs_swapped']\n",
    "            full['maf'] = full.apply(lambda x: af[x.name]['q'], axis=1)\n",
    "\n",
    "            # write files\n",
    "            gwas_data_file = write_gwas_data_file(full.ix[sig.rs], outdir, name, i, sig_key)\n",
    "            gwas_freqs_file, gwas_pops = write_freqs_file(full.ix[sig.rs], paf, outdir, name, i, \"gwas\", sig_key)\n",
    "            #env_var_files = write_env_var_data_files(paf, gwas_pops, outdir, i, name, sig_key)\n",
    "            match_pop_file = write_match_pop_file(full, paf, outdir, i, \"QC32\", name, sig_key)\n",
    "            full_freqs_file, full_pops = write_freqs_file(full, paf, outdir, name, i, \"full\", sig_key)\n",
    "            squat_vars = get_squat_vars(name, gwas_data_file,\n",
    "                          gwas_freqs_file, \n",
    "                          bioclim_env_files,\n",
    "                          match_pop_file,\n",
    "                          full_freqs_file)\n",
    "            squat_file = create_squat_run_file(name, outdir, squat_vars, sig_key)\n",
    "            print \"wrote %s\" % squat_file\n",
    "            squat_files.append(squat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "setwd(\"~/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for squat_file in squat_files:\n",
    "    print squat_file\n",
    "    r(\"source('%s')\" % squat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.dirname(os.path.dirname(analysis_dir_imp)), \"squat_results.txt\"), \"w\") as o:  \n",
    "    o.write(\"%s\\n\" % \"\\t\".join([\"significance\", \"phenotype\", \"imputation\", \"Qx\", \"Pr(Qx)\", \n",
    "                               \"Fst\", \"Pr(Fst)\", \"LD\", \"Pr(LD)\"]))\n",
    "    for squat_file in squat_files:\n",
    "        squat_dir = os.path.dirname(squat_file)\n",
    "        datatype = os.path.basename(os.path.dirname(squat_dir))\n",
    "        pheno = os.path.basename(squat_file).split(\".\")[1]\n",
    "        pheno_dir = os.path.join(squat_dir, pheno)\n",
    "        output_dir = os.path.join(pheno_dir, \"Output\")\n",
    "        assert os.path.exists(output_dir)\n",
    "\n",
    "        for obj in os.listdir(output_dir):\n",
    "            obj = os.path.join(output_dir, obj)\n",
    "            r(\"load('%s')\" % obj)\n",
    "            \n",
    "        res = \"\\t\".join([str(x) for x in [os.path.basename(squat_dir),\n",
    "                                          pheno,\n",
    "                                          datatype,\n",
    "                                          r('the.stats$Qx')[0],\n",
    "                                          r('p.vals$Qx')[0],\n",
    "                                          r('the.stats$Fst.comp')[0],\n",
    "                                          r('p.vals$Fst.comp')[0],\n",
    "                                          r('the.stats$LD.comp')[0],\n",
    "                                          r('p.vals$LD.comp')[0]]])\n",
    "        print res\n",
    "        o.write(\"%s\\n\" % res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "the.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
