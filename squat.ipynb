{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import cyvcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir_notimp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/notimputed/\"\n",
    "analysis_dir_imp = \"/home/cfriedline/eckertlab/gypsy_indiv/masked/analysis/samtools1.2_no_otis/beagle40/\"\n",
    "hdf_notimp = HDFStoreHelper(os.path.join(analysis_dir_notimp, \"isect.hd5\"))\n",
    "hdf_imp = HDFStoreHelper(os.path.join(analysis_dir_imp, \"isect.hd5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = [analysis_dir_notimp, analysis_dir_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdfs[0].get_group_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs = [hdf_notimp, hdf_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_swapped = [x['z12_swapped'] for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = [x.ix[:,:-2].apply(get_allele_freqs, args=(False,)) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, af in enumerate(allele_freqs):\n",
    "    hdfs[i]['allele_freqs_swapped'] = af\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = []\n",
    "for z12 in z12_swapped:\n",
    "    paf = {}\n",
    "    pop_allele_freqs.append(paf)\n",
    "    for pop, data in z12.groupby('population'):\n",
    "        data = data.ix[:,:-2]\n",
    "        paf[pop] = data.apply(get_allele_freqs, args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pimass_gt = [x['pimass_gt'].replace(\"NA\", np.nan) for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translation_df = pd.read_csv(\"translation_table.csv\", sep=\"\\t\", index_col=0)\n",
    "def get_translated_name(n):\n",
    "    n = n.strip()\n",
    "    if n in translation_df.index:\n",
    "        row = translation_df.ix[n.strip()]\n",
    "        return \"%s_%d_%d\" % (row['pop'], row.indiv, row.dup)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in pimass_gt:\n",
    "    p.columns = [get_translated_name(x) for x in p.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdfs[0]['pimass_pheno'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenos = [x['pimass_pheno'][['mass_resid', 'pupual_duration_resid', 'total_dev_time_resid']] for x in hdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for i, pheno_df in enumerate(phenos):\n",
    "    alphas.append({})\n",
    "    data = pheno_df.join(pimass_gt[i].T.ix[2:,])\n",
    "    data.columns = [x.replace(\" \", \"_\") for x in data.columns]\n",
    "    data = data.astype(float)\n",
    "    for pheno in data.columns[0:3]:\n",
    "        alphas[i][pheno] = {}\n",
    "        print i, pheno\n",
    "        for snp in data.columns[3:]:\n",
    "            model = sm.OLS(data[pheno], data[snp], missing='drop')\n",
    "            fit = model.fit()\n",
    "            alphas[i][pheno][snp] = fit.params.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_df = [pd.DataFrame(x) for x in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_gwas_data_file(df, pheno, outdir):\n",
    "    out = \"%s_gwas_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    df = df.sort_index()\n",
    "    df[['A1', 'A2', 'EFF', 'FRQ']].to_csv(out,\n",
    "                                          header=True, \n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")\n",
    "    print out\n",
    "    return out\n",
    "\n",
    "def write_freqs_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_freqs_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))\n",
    "def write_match_pop_file(df, pheno, pop_freqs, pop, outdir):\n",
    "    out = \"%s_match_pop_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for key, data in pop_freqs.items():\n",
    "            if key == pop:\n",
    "                m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "                m['population'] = pop\n",
    "                m.index.name = 'SNP'\n",
    "                m = m.sort_index()\n",
    "                o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                                 index=True,\n",
    "                                                                 sep=\"\\t\"))\n",
    "                break\n",
    "                \n",
    "def write_full_dataset_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_full_dataset_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))   \n",
    "def write_env_var_data_file(pheno, pop_freqs, outdir):\n",
    "    out = \"%s_env_var_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 0\n",
    "        for pop in pop_freqs:\n",
    "            pop_id += 1\n",
    "            o.write(\"%s\\t%f\\t%d\\n\" % (pop, np.random.randn(), pop_id))\n",
    "                \n",
    "                \n",
    "for p in alpha_vals:\n",
    "    outdir = analysis_dir\n",
    "    full = alpha_vals[p].T\n",
    "    full = full.merge(missing, how=\"inner\", left_index=True, right_index=True)\n",
    "    full = full[(full['missing'] <= 0.2) & (full['missing'] >= 0.1)]\n",
    "    #full = full[(full['missing'] <= 0.3) & (full['missing'] >= 0.2)]\n",
    "    #full = full[(full['missing'] <= 0.3)]\n",
    "    full.index.name = \"SNP\"\n",
    "    full.AA = full.AA.apply(lambda x: x[0])\n",
    "    full.aa = full.aa.apply(lambda x: x[0])\n",
    "    full = full.rename(columns={'alpha':'EFF',\n",
    "                                'AA':'A1',\n",
    "                                'aa':'A2',\n",
    "                                'p': 'FRQ'})\n",
    "    candidates = full[full['p-value']<0.05]\n",
    "    write_gwas_data_file(candidates, p, outdir)\n",
    "    write_freqs_file(candidates, p, pop_allele_freqs, outdir)\n",
    "    write_match_pop_file(full, p, pop_allele_freqs, \"QC32\", outdir)\n",
    "    write_full_dataset_file(full, p, pop_allele_freqs, outdir)\n",
    "    write_env_var_data_file(p, pop_allele_freqs, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_names = phenos[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sig_pheno_name(col):\n",
    "    return {'mass_resid': 'mass',\n",
    "           'pupual_duration_resid': 'pd',\n",
    "           'total_dev_time_resid': 'tdt'}[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_freqs_file(df, paf, outdir, pheno, imputed, key):\n",
    "    df = df.copy()\n",
    "    outfile = os.path.join(outdir, \"freqs.file.%s.%s.%s.txt\" % (key, pheno, imputed))\n",
    "    df.index.name = \"SNP\"\n",
    "    for pop in paf:\n",
    "        df2 = df.join(paf[pop].T)\n",
    "        df2['CLST'] = pop\n",
    "        df2['POS'] = df2.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "        df2['CHR'] = df2.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "        df2 = df2[['CLST', 'minor', 'major', 'q', 'POS', 'CHR']]\n",
    "        df2.columns = ['CLST', 'A1', 'A2', 'FRQ', 'POS', 'CHR']\n",
    "        df2.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile, df2['CLST'].values\n",
    "\n",
    "def write_gwas_data_file(df, outdir, pheno, imputed):\n",
    "    df = df.copy()\n",
    "    outfile = os.path.join(outdir, \"gwas.data.file.%s.%s.txt\" % (pheno, imputed))\n",
    "    df.index.name = \"SNP\"\n",
    "    df = df[['minor', 'major', 'alpha', 'maf']]\n",
    "    df.columns = [\"A1\", \"A2\", \"EFF\", \"FRQ\"]\n",
    "    df.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile\n",
    "    \n",
    "def write_env_var_data_files(paf, pops, outdir, imputed):\n",
    "    outfiles = []\n",
    "    outfile = os.path.join(outdir, \"env.var.data.file.%s.txt\" % (imputed))\n",
    "    outfiles.append(outfile)\n",
    "    with open(outfile, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 1\n",
    "        for pop in sorted(paf):\n",
    "            if pop in pops:\n",
    "                o.write(\"%s\\t%g\\t%d\\n\" % (pop, np.random.randn(), pop_id))\n",
    "            pop_id += 1\n",
    "    return outfiles\n",
    "  \n",
    "def write_match_pop_file(df, paf, outdir, imputed, matchpop):\n",
    "    outfile = os.path.join(outdir, \"match.pop.file.%s.%s.txt\" % (matchpop, imputed))\n",
    "    df2 = df.join(paf[matchpop].T)\n",
    "    df2.index.name=\"SNP\"\n",
    "    df2['CLST'] = matchpop\n",
    "    df2['POS'] = df2.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "    df2['CHR'] = df2.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "    df2 = df2[['CLST', 'minor', 'major', 'q', 'POS', 'CHR']]\n",
    "    df2.columns = ['CLST', 'A1', 'A2', 'FRQ', 'POS', 'CHR']\n",
    "    df2.to_csv(outfile, header=True, index=True, sep=\"\\t\")\n",
    "    return outfile\n",
    "\n",
    "def get_squat_vars(pheno,\n",
    "                   gwas_data_file, \n",
    "                  gwas_freqs_file, \n",
    "                  env_var_files,\n",
    "                  match_pop_file,\n",
    "                  full_freqs_file):\n",
    "    d = {\"gwas.data.file\": \"'%s'\" % gwas_data_file,\n",
    "         \"freqs.file\": \"'%s'\" % gwas_freqs_file,\n",
    "         \"env.var.data.files\": \"list('%s')\" % ','.join(env_var_files),\n",
    "         \"match.pop.file\": \"'%s'\" % match_pop_file,\n",
    "         \"full.dataset.file\": \"'%s'\" % full_freqs_file,\n",
    "         \"path\":\"'%s'\" % pheno,\n",
    "         \"match.categories\":\"c('FRQ')\",\n",
    "         \"match.bins\":\"list(seq(0,0.5,0.02), c(2), seq(0,1000,100))\",\n",
    "         \"cov.SNPs.per.cycle\":5000,\n",
    "         \"cov.cycles\":1,\n",
    "         \"null.phenos.per.cycle\":1000,\n",
    "         \"null.cycles\":1,\n",
    "         \"load.cov.mat\":\"F\",\n",
    "         \"sim.null\":\"T\",\n",
    "         \"check.allele.orientation\":\"T\"}\n",
    "    return ',\\n'.join(\"%s=%s\" % (key,val) for (key,val) in d.items())\n",
    "\n",
    "def create_squat_run_file(pheno, outdir, squat_vars):\n",
    "    squat_dir = \"/home/cfriedline/eckertlab/src/PolygenicAdaptationCode/Scripts/\"\n",
    "    out_dir = os.path.join(outdir, \"squat\")\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    squat_file = os.path.join(out_dir, \"squat_%s.r\" % pheno)\n",
    "    with open(squat_file, \"w\") as o:\n",
    "        o.write(\"rm(list=ls())\\n\")\n",
    "        o.write(\"setwd('/home/cfriedline/eckertlab/src/PolygenicAdaptationCode')\\n\")\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"CreateTraitFile.R\"))\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_dir, \"functions.R\"))\n",
    "        o.write(\"setwd('%s')\\n\" % out_dir)\n",
    "        o.write(\"PolygenicAdaptationFunction(%s)\\n\" % squat_vars)\n",
    "    return squat_file\n",
    "\n",
    "for i, hdf in enumerate(hdfs):\n",
    "    outdir = analysis_dir[i]\n",
    "    for name in pheno_names:\n",
    "        paf = pop_allele_freqs[i]\n",
    "        pheno_hdf = get_sig_pheno_name(name)\n",
    "        sig = hdf['sig_snps_%s' % pheno_hdf]\n",
    "        full = hdf['mcmc_%s_hmean' % pheno_hdf]\n",
    "        full.index = full.rs\n",
    "        full.index.name=\"%s_%d\" % (name, i)\n",
    "        alpha = alphas[i][name]\n",
    "        full['alpha'] = full.apply(lambda x: alpha[x.name], axis=1)       \n",
    "        full = full.drop(\"rs\", axis=1)\n",
    "        full = full.join(pimass_gt[i][['minor', 'major']])\n",
    "        af = hdfs[i]['allele_freqs_swapped']\n",
    "        full['maf'] = full.apply(lambda x: af[x.name]['q'], axis=1)\n",
    "        gwas_data_file = write_gwas_data_file(full.ix[sig.rs], outdir, name, i)\n",
    "        gwas_freqs_file, gwas_pops = write_freqs_file(full.ix[sig.rs], paf, outdir, name, i, \"gwas\")\n",
    "        env_var_files = write_env_var_data_files(paf, gwas_pops, outdir, i)\n",
    "        match_pop_file = write_match_pop_file(full, paf, outdir, i, \"QC32\")\n",
    "        full_freqs_file, full_pops = write_freqs_file(full, paf, outdir, name, i, \"full\")\n",
    "        squat_vars = get_squat_vars(name, gwas_data_file,\n",
    "                      gwas_freqs_file, \n",
    "                      env_var_files,\n",
    "                      match_pop_file,\n",
    "                      full_freqs_file)\n",
    "        squat_file = create_squat_run_file(name, outdir, squat_vars)\n",
    "        print \"wrote %s\" % squat_file\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_squat():\n",
    "    for p in [\"mass\", \"pd\",\"tdt\"]:\n",
    "        print \"running %s\" % p\n",
    "        output = os.path.join(analysis_dir,\"squat/%s\" % p)\n",
    "        if os.path.exists(output):\n",
    "            !rm -rf {output}\n",
    "        r('setwd(\"%s\")' % analysis_dir)\n",
    "        print 'source(\"%s/squat/squat_%s.r\")' % (analysis_dir, p)\n",
    "        r('source(\"%s/squat/squat_%s.r\")' % (analysis_dir, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
