{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scandir\n",
    "import os, sys\n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "import random\n",
    "import vcf\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import operator\n",
    "import traceback\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri as p2r\n",
    "p2r.activate()\n",
    "r = ro.r\n",
    "import shutil\n",
    "from utils import read_df, save_df\n",
    "from pathlib import Path, PurePath\n",
    "from ipyparallel import Client\n",
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "from scipy.stats import mannwhitneyu, ks_2samp, f_oneway\n",
    "import tables\n",
    "import ujson\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/beagle40/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gemma_dir = os.path.join(analysis_dir, \"gemma_run\")\n",
    "gemma_dir = os.path.join(gemma_imputed.ipynba_dir, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ni_data = read_df(\"/home/cfriedline/eckertlab/gypsy_indiv/raw_demult/analysis/samtools1.3_masurca3/ni\", \"z12_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_missing(snp):\n",
    "    c = snp.value_counts()\n",
    "    if not -1 in c:\n",
    "        return 0\n",
    "    return c[-1]/np.sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing = ni_data.apply(percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenos = [\"mass\", \"tdt\", \"pd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_dfs = pickle.load(open(os.path.join(gemma_dir, \"combined_dfs.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps = pickle.load(open(os.path.join(gemma_dir, \"effect_snps.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "effect_snps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df = read_df(analysis_dir, 'gt_base_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = sorted(set([x.split(\"_\")[0] for x in gt_base_df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_genotypes(snp):\n",
    "    counts = Counter()\n",
    "    for gt in snp:\n",
    "        try:\n",
    "            float(gt) #if gt is nan\n",
    "        except:\n",
    "            counts[gt[0]]+=1\n",
    "            counts[gt[-1]]+=1\n",
    "    return sorted(counts.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_base_df['population'] = gt_base_df.apply(lambda x: x.name.split(\"_\")[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_data = {}\n",
    "\n",
    "def add_allele_freq(gt_list):\n",
    "    data = gt_list\n",
    "    ret = OrderedDict()\n",
    "    if len(gt_list) == 2:\n",
    "        total = data[0][1]+data[1][1]\n",
    "        ret[data[0][0]] = [data[0][1], data[0][1]/total]\n",
    "        ret[data[1][0]] = [data[1][1], data[1][1]/total]\n",
    "    else:\n",
    "        ret[data[0][0]] = [data[0][1], 1.0]\n",
    "    return ret\n",
    "\n",
    "for group, data in gt_base_df.groupby('population'):\n",
    "    data = data.drop('population', axis=1)\n",
    "    print(group, data.shape)\n",
    "    gt = data.apply(count_genotypes).apply(add_allele_freq)\n",
    "    pop_allele_data[group] = gt.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt = read_df(analysis_dir, '_gemma_gt').replace(\"NA\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pop_allele_data['VA1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_counts = gt_base_df.apply(count_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af = gt_counts.apply(add_allele_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_counts_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gemma_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['gemma_gt'] = gemma_gt\n",
    "\n",
    "dview['pops'] = pops\n",
    "\n",
    "dview['analysis_dir'] = analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "import os, pickle, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"pop_allele_data.pkl\"), \"wb\") as o:\n",
    "    pickle.dump(pop_allele_data, o, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "if not 'pop_allele_data' in dir():\n",
    "    pop_allele_data = pickle.load(open(os.path.join(analysis_dir, \"pop_allele_data.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_obs_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    for gt in snp:\n",
    "        if gt[0] != gt[-1]:\n",
    "            het += 1\n",
    "        if gt[1] == \"/\" or gt[1] == \"|\":\n",
    "            total += 1\n",
    "    return het/total\n",
    "\n",
    "def compute_exp_heterozygosity(snp):\n",
    "    het = 0\n",
    "    total = 0\n",
    "    c = Counter()\n",
    "    for gt in snp:\n",
    "        c[gt[0]] += 1\n",
    "        c[gt[-1]] += 1\n",
    "    total = np.sum(list(c.values()))\n",
    "    He = 2\n",
    "    for a in c:\n",
    "        He *= (c[a]/total)\n",
    "    return He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "het_bins = np.linspace(0,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "He = gt_base_df.drop(\"population\", axis=1).apply(compute_exp_heterozygosity)\n",
    "He = pd.DataFrame(He, columns=[\"He\"])\n",
    "He['rs'] = He.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ho = gt_base_df.drop(\"population\", axis=1).apply(compute_obs_heterozygosity)\n",
    "Ho = pd.DataFrame(Ho, columns=[\"Ho\"])\n",
    "Ho['rs'] = Ho.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "He.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho = combined_dfs['tdt'].join(Ho, how=\"inner\")\n",
    "mass_ho = combined_dfs['mass'].join(Ho, how=\"inner\")\n",
    "pd_ho = combined_dfs['pd'].join(Ho, how=\"inner\")\n",
    "\n",
    "tdt_he = combined_dfs['tdt'].join(He, how=\"inner\")\n",
    "mass_he = combined_dfs['mass'].join(He, how=\"inner\")\n",
    "pd_he = combined_dfs['pd'].join(He, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdt_ho['het_bin'] = np.digitize(tdt_ho.Ho, het_bins)\n",
    "mass_ho['het_bin'] = np.digitize(mass_ho.Ho, het_bins)\n",
    "pd_ho['het_bin'] = np.digitize(pd_ho.Ho, het_bins)\n",
    "\n",
    "tdt_he['het_bin'] = np.digitize(tdt_he.He, het_bins)\n",
    "mass_he['het_bin'] = np.digitize(mass_he.He, het_bins)\n",
    "pd_he['het_bin'] = np.digitize(pd_he.He, het_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PhenoContainer = namedtuple(\"PhenoContainer\", [\"He\", \"Ho\", \"hmean\", \"sig\", \"relaxed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PC = {\"mass\": PhenoContainer(mass_he, mass_ho, combined_dfs['mass'], \n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                             effect_snps[('mass', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"pd\":PhenoContainer(pd_he, pd_ho, combined_dfs['pd'],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                          effect_snps[('pd', 'gamma_hmean', 'total_effect', 0.995)]),\n",
    "      \"tdt\":PhenoContainer(tdt_he, tdt_ho, combined_dfs['tdt'],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.999)],\n",
    "                           effect_snps[('tdt', 'gamma_hmean', 'total_effect', 0.995)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].He.gamma_hmean, PC[pheno].He.He)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{exp}$\")\n",
    "    plt.title(\"TDT\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    plt.scatter(PC[pheno].Ho.gamma_hmean, PC[pheno].Ho.Ho)\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(r\"$H_{obs}$\")\n",
    "    plt.title(pheno.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_snp = 'ctg7180005039298_50'\n",
    "test_minor = gemma_gt.ix[test_snp, \"minor\"]\n",
    "print(test_minor)\n",
    "for p in pop_allele_data:\n",
    "    if test_minor in pop_allele_data[p][test_snp]:\n",
    "        print(pop_allele_data[p][test_snp][test_minor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@lview.remote()\n",
    "def do_pairwise(sig_list):\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "    ret = []\n",
    "    for i, snp in enumerate(sig_list):\n",
    "        snp_i = snp\n",
    "        minor_allele_i = gemma_gt.ix[snp_i, \"minor\"]\n",
    "        for j in range(i):\n",
    "            snp_j = sig_list[j]\n",
    "            minor_allele_j = gemma_gt.ix[snp_j, \"minor\"]\n",
    "            in_prods = []\n",
    "            freqs = {snp_i: [], snp_j: []}\n",
    "            for p in pops:\n",
    "                paf_i = paf_j = 0.0\n",
    "                \n",
    "                if minor_allele_i in pop_allele_data[p][snp]:\n",
    "                    paf_i = pop_allele_data[p][snp][minor_allele_i][1]\n",
    "                    \n",
    "                if minor_allele_j in pop_allele_data[p][snp_j]:\n",
    "                    paf_j = pop_allele_data[p][snp_j][minor_allele_j][1]\n",
    "                \n",
    "                freqs[snp_i].append(paf_i)\n",
    "                freqs[snp_j].append(paf_j)\n",
    "                in_prods.append(paf_i * paf_j)\n",
    "                avg_in_prod = np.mean(in_prods)\n",
    "                freqs_avg = {k: np.mean(freqs[k]) for k in freqs}\n",
    "                across_freqs = list(freqs_avg.values())\n",
    "                across_prod = across_freqs[0] * across_freqs[1]\n",
    "                ret.append(avg_in_prod-across_prod)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nulls_by_het(n, sig_df, df):\n",
    "    unassoc = df.drop(sig_df.index)\n",
    "    het_bin_counts = df.ix[sig_df.index]['het_bin'].value_counts()\n",
    "    het_bins = het_bin_counts.index.tolist()\n",
    "    unassoc = unassoc[unassoc.het_bin.isin(het_bins)]\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        inner = []\n",
    "        for het_bin, het_count in het_bin_counts.iteritems():\n",
    "            inner.extend(unassoc[unassoc.het_bin == het_bin].rs.sample(het_count).tolist())\n",
    "        data.append(inner)\n",
    "    return data, het_bins\n",
    "\n",
    "def get_nulls_naive(n, sig_df, df):\n",
    "    unassoc = df.drop(sig_df.index)\n",
    "    return [unassoc.rs.sample(len(sig_df)).tolist() for x in range(n)], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_nulls = get_nulls_by_het\n",
    "dview['get_nulls_naive'] = get_nulls_naive\n",
    "dview['get_nulls'] = get_nulls\n",
    "dview['get_nulls_by_het'] = get_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gwas_upper_D = {}\n",
    "for pheno in PC:\n",
    "    gwas_upper_D[pheno] = np.abs(do_pairwise(list(PC[pheno].sig)).r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nulls_upper = {}\n",
    "upper_sig_het_bins = {}\n",
    "nulls_lower = {}\n",
    "lower_sig_het_bins = {}\n",
    "for pheno in PC:\n",
    "    nulls_upper[pheno], upper_sig_het_bins[pheno] = get_nulls(1000, PC[pheno].upper20, PC[pheno].He)\n",
    "    nulls_lower[pheno], lower_sig_het_bins[pheno] = get_nulls(1000, PC[pheno].lower20, PC[pheno].He)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nulls_upper_D = {}\n",
    "nulls_lower_D = {}\n",
    "for pheno in PC:\n",
    "    nulls_upper_D[pheno] = []\n",
    "    nulls_lower_D[pheno] = []\n",
    "    \n",
    "    for i, null_list in enumerate(nulls_upper[pheno]):\n",
    "        nulls_upper_D[pheno].append(do_pairwise(null_list))\n",
    "    \n",
    "    for i, null_list in enumerate(nulls_lower[pheno]):\n",
    "        nulls_lower_D[pheno].append(do_pairwise(null_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    nulls_upper_D[pheno] = [np.abs(x.r) for x in nulls_upper_D[pheno]]\n",
    "    nulls_lower_D[pheno] = [np.abs(x.r) for x in nulls_lower_D[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    sns.distplot(gwas_upper_D[pheno], label=\"upper tail\")\n",
    "    sns.distplot(gwas_lower_D[pheno], label=\"lower tail\")\n",
    "    plt.xlabel(\"Pairwise D\")\n",
    "    plt.title(pheno.upper())\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(nulls_upper_D['mass'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_boxdata = {}\n",
    "for pheno in PC:\n",
    "    boxdata = {\"Upper tail\":[], \"Lower tail\": [], \"Random Upper\": [], \"Random Lower\": []}\n",
    "    minpoints = np.min((len(gwas_lower_D[pheno]), len(gwas_upper_D[pheno]), len(nulls_upper_D[pheno]), len(nulls_lower_D[pheno])))\n",
    "    minpoints = len(gwas_lower_D[pheno])\n",
    "    for d in gwas_lower_D[pheno][0:minpoints]:\n",
    "        boxdata['Lower tail'].append(d)\n",
    "\n",
    "    for d in gwas_upper_D[pheno][0:minpoints]:\n",
    "        boxdata['Upper tail'].append(d)\n",
    "\n",
    "    for d in nulls_upper_D[pheno][100][0:minpoints]:\n",
    "        boxdata[\"Random Upper\"].append(np.abs(d))\n",
    "\n",
    "    for d in nulls_lower_D[pheno][100][0:minpoints]:\n",
    "        boxdata[\"Random Lower\"].append(np.abs(d))\n",
    "    pheno_boxdata[pheno] = boxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_missing = pd.DataFrame(percent_missing, columns=[\"missing\"])\n",
    "\n",
    "percent_missing['rs'] = percent_missing.index\n",
    "\n",
    "percent_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_missing = {}\n",
    "lower_missing = {}\n",
    "\n",
    "for pheno in PC:\n",
    "    upper_missing[pheno] = PC[pheno].upper20.join(percent_missing, on=\"rs\", rsuffix=\"_pm\", how=\"inner\")\n",
    "    lower_missing[pheno] = PC[pheno].lower20.join(percent_missing, on=\"rs\", rsuffix=\"_pm\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    print(pheno, f_oneway(upper_missing[pheno].missing, lower_missing[pheno].missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    bd = pd.DataFrame(pheno_boxdata[pheno])\n",
    "    ax = sns.boxplot(data=bd)\n",
    "    plt.ylabel(\"log D\")\n",
    "    ax.set_yscale(\"log\", basey=10)\n",
    "    plt.xlabel(\"n = %d\" % len(bd))\n",
    "    plt.title(pheno.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "@lview.remote()\n",
    "def ks_test(arr1, arr2):\n",
    "    from scipy.stats import ks_2samp\n",
    "    return ks_2samp(arr1, arr2)\n",
    "\n",
    "@lview.remote()\n",
    "def mwu_test(arr1, arr2):\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    return mannwhitneyu(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks_upper = {}\n",
    "ks_lower = {}\n",
    "for pheno in PC:\n",
    "    ks_upper[pheno] = [ks_test(gwas_upper_D[pheno], x) for x in nulls_upper_D[pheno]]\n",
    "    ks_lower[pheno] = [ks_test(gwas_lower_D[pheno], x) for x in nulls_lower_D[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "gwas_null_ks_upper = {}\n",
    "gwas_null_ks_lower = {}\n",
    "for pheno in PC:\n",
    "    gwas_null_ks_upper[pheno] = [x.r for x in ks_upper[pheno]]\n",
    "    gwas_null_ks_lower[pheno] = [x.r for x in ks_lower[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gwas_null_pvals_upper = {}\n",
    "gwas_null_pvals_lower = {}\n",
    "\n",
    "for pheno in PC:    \n",
    "    u = []\n",
    "    l = []\n",
    "    gwas_null_pvals_upper[pheno] = u\n",
    "    gwas_null_pvals_lower[pheno] = l\n",
    "    \n",
    "    for stat, pval in gwas_null_ks_upper[pheno]:\n",
    "        u.append(pval)\n",
    "\n",
    "    for stat, pval in gwas_null_ks_lower[pheno]:\n",
    "        l.append(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulls2_upper = nulls3_upper = nulls2_lower = nulls3_lower = {}\n",
    "\n",
    "for pheno in PC:\n",
    "    print(pheno)\n",
    "\n",
    "    nulls2_upper[pheno] = get_nulls(1000, PC[pheno].upper20, PC[pheno].He)\n",
    "    nulls3_upper[pheno] = get_nulls(1000, PC[pheno].upper20, PC[pheno].He)\n",
    "\n",
    "    nulls2_lower[pheno] = get_nulls(1000, PC[pheno].lower20, PC[pheno].He)\n",
    "    nulls3_lower[pheno] = get_nulls(1000, PC[pheno].lower20, PC[pheno].He)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n2_upper = n3_upper = n2_lower = n3_lower = {}\n",
    "\n",
    "for pheno in PC:    \n",
    "    n2_upper[pheno] = [do_pairwise(x) for x in nulls2_upper[pheno][0]]\n",
    "    n3_upper[pheno] = [do_pairwise(x) for x in nulls3_upper[pheno][0]]\n",
    "\n",
    "    n2_lower[pheno] = [do_pairwise(x) for x in nulls2_lower[pheno][0]]\n",
    "    n3_lower[pheno] = [do_pairwise(x) for x in nulls3_lower[pheno][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "n2_r_upper = n2_r_lower = n3_r_upper = n3_r_lower = {}\n",
    "\n",
    "for pheno in PC:\n",
    "    n2_r_upper[pheno] = [x.r for x in n2_upper[pheno]]\n",
    "    n3_r_upper[pheno] = [x.r for x in n3_upper[pheno]]\n",
    "\n",
    "    n2_r_lower[pheno] = [x.r for x in n2_lower[pheno]]\n",
    "    n3_r_lower[pheno] = [x.r for x in n3_lower[pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_null_pvals_upper = null_null_pvals_lower = {}\n",
    "\n",
    "for pheno in PC:\n",
    "    null_null_pvals_upper[pheno] = []\n",
    "    for x, y in zip(n2_r_upper[pheno], n3_r_upper[pheno]):\n",
    "        stat, p = ks_2samp(x, y)\n",
    "        null_null_pvals_upper[pheno].append(p)\n",
    "\n",
    "    null_null_pvals_lower[pheno] = []\n",
    "    for x, y in zip(n2_r_lower[pheno], n3_r_lower[pheno]):\n",
    "        stat, p = ks_2samp(x, y)\n",
    "        null_null_pvals_lower[pheno].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    print(\"upper\", pheno, ks_2samp(gwas_null_pvals_upper[pheno], null_null_pvals_upper[pheno]))\n",
    "    print(\"loser\", pheno, ks_2samp(gwas_null_pvals_lower[pheno], null_null_pvals_lower[pheno]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    He = PC[pheno].He\n",
    "    plt.scatter(He.ix[PC[pheno].lower20.index].postrb_hmean, He.ix[PC[pheno].lower20.index].He)\n",
    "    plt.title(pheno.upper() + \" lower 20\")\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(\"Hexp\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pheno in PC:\n",
    "    He = PC[pheno].He\n",
    "    plt.scatter(He.ix[PC[pheno].upper20.index].postrb_hmean, He.ix[PC[pheno].upper20.index].He)\n",
    "    plt.title(pheno.upper() + \" upper 20\")\n",
    "    plt.xlabel(\"PIP\")\n",
    "    plt.ylabel(\"Hexp\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
